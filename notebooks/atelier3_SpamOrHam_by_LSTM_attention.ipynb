{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "introLstmAttention.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyPNUKflNjuKGEyDkhZMlIIb"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mTuuSwd9xG4_"
      },
      "source": [
        "# RNN et compagnie\n",
        "\n",
        "Nous allons voir ce qu'est un réseau de neurones récurrent, en quoi il est utile et quelles sont les applications possibles.\n",
        "Face à un GROS problème des RNN, nous verrons un autre type de RNN moins naif : le Long-Short Term Memory. Enfin, face à encore une autre limitation des LSTM, nous verrons une dernière amélioration qui ouvre la porte à l'état de l'art : le mécanisme d'attention.\n",
        "\n",
        "On arrête pas le progrès.\n",
        "\n",
        "Teaser: s'il reste un peu de temps, je peux vous présenter rapidement -et superficiellement- les Transformers/Bert et/ou GPT 3, deux des derniers états de l'art en NLP."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BdzCjRdSx_K-"
      },
      "source": [
        "#1. RNN- LSTM : théorie et applications\n",
        "\n",
        "Jusqu'à present, nous avons vu comment traiter des donnees qui se comportent bien :\n",
        "  - Des tableaux de chiffres\n",
        "  - Des variables catégorielles pouvant être discretisées\n",
        "  - Des images, qui sont de belles matrices de chiffres\n",
        "\n",
        "Mais comment faire avec des données un peu plus punk ?\n",
        "ex: les séries temporelles, des enregistrements audio ou des textes de journaux.\n",
        "\n",
        "Le point commun de tous ces types de données est qu'on trouve des durées variables à l'intérieur d'un même dataset: des phrases plus ou moins longues, des enregitrements de quelques secondes vs quelques minutes, etc. De plus, l'information à date $t$ dépend souvent de l'information à $t-1$: le mot d'après dépend du mot d'avant dans une phrase, le prix d'une action dépend de son prix il y a trois heures. A cette fin, on utilise un réseau de neurones récurrent, ou RNN.\n",
        "\n",
        "##a. RNN \"vanilla\"\n",
        "\n",
        "L'idée du RNN a été proposée en 1986, quand les auteurs de [1] ont réussi à réaliser la backpropagation d'un tel réseau. De nombreuses variantes existent, mais nous présentons ici un RNN relativement agnostique à toutes ces petites variations.\n",
        "\n",
        "![rnn unfolded](https://drive.google.com/uc?id=1cJjqpuBYDjFdcq-voRzfsRslWUuftNlC)\n",
        "\n",
        "Un RNN est donc un réseau de neurones qui prend en compte des données séquentielles. Le but est de prendre en compte le passé pour donner du sens au présent, et de prendre en compte tous les mots d'une phrase par exemple, dans la représentation finale.\n",
        "\n",
        "Soit une séquence de données $x$=$x_1, x_2, ...x_T$. On va entrainer le même réseau $T$ fois, soit autant que de mots dans la phrase. Chaque input sera un mélange de nouvelle information (un nouveau $x_t$) et de la connaissance passée (stockée dans l'output précédent $h_t$)\n",
        "\n",
        "Pour les états cachés, on a donc les équations suivantes (en omettant les biais) pour la passe en avant:\n",
        "\\begin{eqnarray}\n",
        "h_t = \\theta \\left( W \\cdot \\left[ x_t, h_{t-1}\\right] \\right)\n",
        "& =\\theta \\left( W_X x_t + W_H h_{t-1}\\right)\n",
        "\\end{eqnarray}\n",
        "où\n",
        "- $\\theta$ est $tanh$, ou n'importe quelle fonction d'activation\n",
        "- W une matrice de poids\n",
        "- $x_t$ l'input à date t\n",
        "- $h_{t-1}$ l'état précédent du RNN\n",
        "\n",
        "\\begin{equation}\n",
        "y_t = F(W_Yh_t)\n",
        "\\end{equation}\n",
        "où\n",
        "- $y_t$ est l'output du réseau pour une date $t$\n",
        "- $W_Y$ est une matrice de poids\n",
        "- $F()$ est une fonction d'activation, originellement juste l'identité\n",
        "- $h_t$ est l'état caché du réseau pour une date $t$\n",
        " \n",
        "\n",
        "\n",
        "On peut réécrire ces équations plus formellement avec :\n",
        "$h_t = \\begin{pmatrix} h_{t1} & h_{t2} & \\dots & h_{tH} \\end{pmatrix} ^\\intercal$,  $y_t = \\begin{pmatrix} y_{t1} & y_{t2} & \\dots & y_{tN} \\end{pmatrix}^\\intercal$ et $x_t = \\begin{pmatrix} x_{t1} & x_{t2} & \\dots & x_{tI} \\end{pmatrix}^\\intercal$\n",
        "\n",
        "et en passant la notation de temps en exposant pour plus de lisibilité :\n",
        "$h_{k}^t = \\sum_{i=1}^I w_{ik}x_i^t + \\sum_{d=1}^H w_{dk}b_{d}^{t-1}$\n",
        "\n",
        "$b_h^t = \\theta_h \\left( h_k^t \\right)$\n",
        "\n",
        "$y_h^t = \\sum_{h'=1}^H w_{h'k}b_h^t$\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "Pour plus de détails + source de l'image :\n",
        "https://karpathy.github.io/2015/05/21/rnn-effectiveness/\n",
        "\n",
        "[1] Rumelhart, D., Hinton, G. & Williams, R. Learning representations by back-propagating errors. Nature 323, 533–536 (1986). https://doi.org/10.1038/323533a0\n",
        "\n",
        "##b.LSTM\n",
        "\n",
        "Un RNN basique prend donc en compte ce qui se passe l'étape d'avant pour décider de l'étape d'après. Mais souvent, on a besoin d'apprendre plus loin que l'étape précédente, et de prendre en compte tout le passé, ou du moins le plus pertinent. \n",
        "\n",
        "Si vous voyez un individu s'avancer vers vous avec un couteau, vous allez surement courir. Sauf si vous vous souvenez que c'est votre ami Jérémy qui vous rend le couteau de votre grand-père que vous lui aviez prété.\n",
        "Mais le fait que c'est le couteau de votre grand-père a peu d'importance comparé au fait que vous avez convaincu son-sa fiancé-e de convoler avec vous la veille de leur mariage. Tout l'enjeu d'un LSTM est de se souvenir des faits les plus saillants pour obtenir les meilleures représentations des situations.\n",
        "\n",
        "Un réseau Long-Short Term Memory est un RNN avec des portes, qui gèrent l'oubli des valeurs précédentes. Dans sa version la plus courante, celle de [2], une cellule LSTM possède trois portes, que nous allons décomposer.\n",
        "\n",
        "![lstm cell](https://drive.google.com/uc?id=1LfOd1ZkJf25tEQGo8AYqADYoYm_VNyt4)\n",
        "![lstm cell](https://drive.google.com/uc?id=1Ho4pj0ybUHAUzAlyEssuF8VXc7II6vqp)\n",
        "\n",
        "Premièrement, une \"cellule\" LSTM est comme une \"cellule\" de RNN, on lui passe un état caché et un input $x_t$ et il calcule des choses. L'état interne n'est plus l'état caché ni un simple produit suivi d'une multiplication, mais il reste simple : c'est la ligne du haut dans la cellule, $C_t^l$\n",
        "\n",
        "Les trois portes sont trois sigmoides, qui donnent des valeurs entre 0 et 1, 0 signifiant \"on laisse rien passer\"/\"on oublie tout\" et 1 signifiant \"on laisse passer toute l'information\".\n",
        "\n",
        "1. La première porte, $f_t$, s'appelle \"forget gate layer\" (la porte de l'oubli). Elle regarde l'état caché précédent, la nouvelle valeur, et décide de garder ou pas l'ancienne mémoire.\n",
        "$$f_t = \\sigma\\left( W \\cdot \\left[ x_t, h_{t-1}\\right] + b_f \\right)$$\n",
        "Cette équation ne vous rapelle pas quelque chose ?\n",
        "\n",
        "2. La deuxième porte $i_t$ est l'\"input gate layer\"(la porte de l'entrée/la contribution). Elle décide quelles valeurs vont être modifiées/mises à jour.\n",
        "En parallèle, une autre couche tanh crée de nouvelles valeurs candidates: quelles seraient les valeurs si on pouvait toutes les mettre à jour. Quand on combine les deux, cela nous donne les nouvelles valeurs à garder en mémoire.\n",
        "$$i_t = \\sigma \\left( W_i \\cdot [x_t, h_{t-1}] +b_i \\right)$$\n",
        "$$\\tilde{C}_t = tanh \\left( W_C \\cdot[x_t, h_{t-1}] +b_C \\right)$$\n",
        "\n",
        "et donc :\n",
        "$$\\hat{C}_t = i_t * \\tilde{C}_t $$\n",
        "\n",
        "Ces deux portes apportent des modifications à l'état interne de la cellule, en décidant d'à quel point on retient le passé, et comment modifier l'état interne de la cellulle pour prendre en compte les nouvelles valeurs.\n",
        "\n",
        "$$C_t = f_t * C_{t-1} + \\hat{C}_t = f_t * C_{t-1} + i_t * \\tilde{C}_t$$\n",
        "\n",
        "3. La dernière porte est l'\"output gate\" (la porte de sortie). Elle ne touche plus à la mémoire de la cellule, toutes les modifications ont déjà été faites. Elle se contente de filtrer ce qu'il y a en mémoire pour donner une sortie. On prend l'état courant, que l'on fait passer par tanh (pour normaliser). En parallèle, une couche sigmoide décide de quelles valeurs on va donner en sortie. Comme pour l'input, la multiplication des 2 donne les valeurs de l'ouput.\n",
        "\n",
        "$$o_t = \\sigma \\left( W_o [x_t, h_{t-1}] +b_o \\right)$$\n",
        "$$h_t = o_t * tanh \\left( C_t \\right)$$\n",
        "\n",
        "---\n",
        "\n",
        "Un exemple filé : prédire un mot plausible après dans la phrase \"Mon frère est avocat, ma soeur est _____\".\n",
        "- La première porte de l'oubli permet par exemple d'oublier l'information sur le genre: nous avions un genre masculin, mais le fait d'avoir vu un nouveau sujet féminin, 'soeur', nous indique que maintenant le sujet est féminin. Quand on voit un nouveau sujet, on veut oublier le genre de l'ancien.\n",
        "- La deuxième porte de l'entrée, elle, va permettre de mettre dans l'état interne (ie, en mémoire), que le sujet courant est de genre féminin.\n",
        "- La porte de sortie, va elle, voir que nous avions un verbe, elle va donc surement donner de l'information concernant un nom, car souvent un nom vient apres un verbe. Il va donc donner le genre et le nombre du sujet, la conjugaison du verbe, pour accorder le nom qui vient.\n",
        "\n",
        "Les LSTM ont été un énorme pas dans ce que l'on peut faire avec les RNN. Y a-t-il eu d'autres grands pas derrière ? Oui, il y a un consensus pour dire que le grand pas d'après a été l'attention. Ce n'est pas le seul, mais il est à la base d'un modèle qui fut état-de-l'art jusqu'en juillet 2020.\n",
        "\n",
        "Plus de détails +source de l'image :\n",
        "http://colah.github.io/posts/2015-08-Understanding-LSTMs/\n",
        "\n",
        "[2] Hochreiter, Sepp & Schmidhuber, Jürgen. (1997). Long Short-term Memory. Neural computation. 9. 1735-80. 10.1162/neco.1997.9.8.1735. \n",
        "\n",
        "\n",
        "##c. Méchanisme d'attention\n",
        "\n",
        "###1. Modèle seq2seq : motivation pour l'attention\n",
        "\n",
        "Historiquement, seq2seq est un modèle qui permet de faire de la traduction: on donne une séquence, le modèle sort une nouvelle séquence.\n",
        "\n",
        "La mécanique basique est consitué de deux LSTM l'un après l'autre : le premier, appelé encodeur, encode toute la séquence dans le dernier état caché $h_T$. \n",
        "Le deuxième LSTM, le décodeur, prend en entrée cet encoding de la séquence et le premier mot (un token \\<START\\>), et sort un premier output. A chaque étape, il prend l'état caché $h'_t$ précédent et l'output qu'il vient de faire (le dernier mot prédit) pour faire une prédiction. On continue comme ça jusqu'à prédire un token de fin (\\<END\\>)\n",
        "\n",
        "![lstm cell](https://drive.google.com/uc?id=13fmMDB3on4a9ZYnuYSCqpORBsxB-ESyb)\n",
        "\n",
        "Le problème se trouve dans l'état du milieu, le fameux $c$, qui doit contenir toute l'information de la phrase. En réalité, si ce dernier output d'un LSTM est souvent suffisant pour encoder un thème, un sentiment, un topic général de la phrase, il n'est pas suffisant pour retenir toute l'information nécéssaire à une traduction. Il lui manque un élément crucial, le contexte.\n",
        "\n",
        "###2.Attention générale\n",
        "\n",
        "C'est là qu'apparait l'attention.\n",
        "L'attention, de façon très générale, est une couche d'un réseau de neurones qui est en charge de quantifier les interdependences entre les inputs/outputs (attention générale) ou entre les inputs eux-mêmes (self-attention). Nous parlerons ici d'attention générale.\n",
        "\n",
        "Il existe deux méthodes d'attention principales, globale\\/ soft\\/ Bahdanau ou local\\/ hard\\/ Luong du nom des deux chercheurs ayant développé ces deux attentions.\n",
        "\n",
        "Le premier morceau reste le même, un LSTM classique avec ses inputs, ses états cachés et internes $h_t$ et $C_t$.\n",
        "\n",
        "Lors du décodage, au lieu de passer dans la cellule le dernier $y_t$ et uniquement le dernier état caché $h_t$, on concatène au dernier état caché un vecteur de contexte. Ce vecteur de contexte cherche à montrer à quel point le dernier état caché du décodeur s'aligne avec tout les états cachés de l'encodeur.\n",
        "\n",
        "$h_1, h_2...$ = états cachés du décodeur, \n",
        "$\\bar{h}_1, \\bar{h}_2, ...$ = états cachés de l'encodeur. \n",
        "\n",
        "On choisit d'abord un score d'alignement entre les $h$ et les $\\bar{h}$. Le choix de ce score est ce qui fait la différence entre Bahdanau et Luong.\n",
        "\n",
        "$$score$$\n",
        "\n",
        "\n",
        "https://machinelearningmastery.com/attention-long-short-term-memory-recurrent-neural-networks/\n",
        "\n",
        "https://blog.floydhub.com/attention-mechanism/\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "a5pHxTrO9Gs7"
      },
      "source": [
        "#2. Données de travail : spam or ham ?\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GmmGMFRo9OPr"
      },
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import nltk\n",
        "import matplotlib.pyplot as plt\n",
        "from tensorflow.keras.preprocessing import text\n",
        "from tensorflow.keras.preprocessing import sequence\n",
        "import re\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "from tensorflow.keras.layers import Input, SimpleRNN, Dense, Embedding, LSTM, Masking, Concatenate\n",
        "from tensorflow.keras import Model\n",
        "from tensorflow.keras.optimizers import SGD, Adam\n",
        "from keras.callbacks import LambdaCallback, History\n",
        "\n",
        "from sklearn.model_selection import train_test_split, KFold, GridSearchCV\n",
        "from sklearn.metrics import confusion_matrix, classification_report, accuracy_score\n",
        "import itertools"
      ],
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bbVOY6MA9YX-",
        "outputId": "ce859f8a-daa9-4e20-ae06-1dd208888eb0",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 175
        }
      },
      "source": [
        "#Import the data, check it\n",
        "data = pd.read_csv(\"https://raw.githubusercontent.com/CMallart/ateliers-NN/main/data/spamorham/SPAM%20text%20message%2020170820%20-%20Data.csv\")\n",
        "data.head()\n",
        "data.describe()"
      ],
      "execution_count": 36,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Category</th>\n",
              "      <th>Message</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>count</th>\n",
              "      <td>5572</td>\n",
              "      <td>5572</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>unique</th>\n",
              "      <td>2</td>\n",
              "      <td>5157</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>top</th>\n",
              "      <td>ham</td>\n",
              "      <td>Sorry, I'll call later</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>freq</th>\n",
              "      <td>4825</td>\n",
              "      <td>30</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "       Category                 Message\n",
              "count      5572                    5572\n",
              "unique        2                    5157\n",
              "top         ham  Sorry, I'll call later\n",
              "freq       4825                      30"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 36
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_jc-EN8gC8ir",
        "outputId": "bcf6428e-382f-42b8-c896-19e793f81920",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 301
        }
      },
      "source": [
        "cnt_pro = data['Category'].value_counts()\n",
        "plt.figure(figsize=(12,4))\n",
        "plt.bar(cnt_pro.index, cnt_pro.values, alpha=0.8, color=['blue', 'orange'])\n",
        "plt.ylabel('Number of Occurrences', fontsize=12)\n",
        "plt.xlabel('Category', fontsize=12)\n",
        "plt.xticks(rotation=90)\n",
        "plt.show();"
      ],
      "execution_count": 37,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 864x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "puVXsg0097Ly",
        "outputId": "31c4d561-1e3a-4d52-bc15-812874119b3b",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "# What kind of language is used, what kind of cleanup is necessary\n",
        "def see_message(ind):\n",
        "  mess=data.iloc[ind][\"Message\"]\n",
        "  print(mess)\n",
        "  return(mess)\n",
        "for message in [0,15,25,35,50]:\n",
        "  see_message(message)"
      ],
      "execution_count": 38,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Go until jurong point, crazy.. Available only in bugis n great world la e buffet... Cine there got amore wat...\n",
            "XXXMobileMovieClub: To use your credit, click the WAP link in the next txt message or click here>> http://wap. xxxmobilemovieclub.com?n=QJKGIGHJJGCBL\n",
            "Just forced myself to eat a slice. I'm really not hungry tho. This sucks. Mark is getting worried. He knows I'm sick when I turn down pizza. Lol\n",
            "Yup... Ok i go home look at the timings then i msg ü again... Xuhui going to learn on 2nd may too but her lesson is at 8am\n",
            "What you thinked about me. First time you saw me in class.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QXLK5z3S5Sbm",
        "outputId": "26e41be3-6c59-4e57-d2c1-2d755b4b386e",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "#check if we have empty strings, or punctuation only columns\n",
        "#they are not important here, we remove them\n",
        "to_remove =[]\n",
        "for i, row in data.iterrows():\n",
        "  if re.match(r'.*[A-Za-z]+.*',row[\"Message\"]) is None :\n",
        "    print(row[\"Message\"],\"at line\", i)\n",
        "    to_remove.append(i)\n",
        "data = data.drop(to_remove, axis =0) \n",
        "print(\"Removed the punctuation or numbers-only lines\") "
      ],
      "execution_count": 40,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Removed the punctuation or numbers-ony lines\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Wdmjf3soBTL5",
        "outputId": "74aff0a0-4b18-4019-faef-4c1e07f94d99",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 55
        }
      },
      "source": [
        "#A little cleanup is necessary \n",
        "#I won't bother cleaning up the puctuation as it is done later by keras.preprocessing.tokenizer\n",
        "def clean_text(text):\n",
        "  #remove the https:// stuff\n",
        "  text = re.sub(r\"http\\S+\", \"\", text)\n",
        "  #remove the urls that don't have the http:// => solution = remove all strings that have a [some non-space characters].[two or three letters]/[some non-space characters] or [some non-space characters].[two or three letters]?[some non-space characters]\n",
        "  text = re.sub(r\"[^\\s]*\\.[a-z]{2,3}(\\\\|\\?)*[^\\s]*\", \"\", text)\n",
        "  return(text)\n",
        "\n",
        "clean_text(see_message(15))"
      ],
      "execution_count": 41,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "XXXMobileMovieClub: To use your credit, click the WAP link in the next txt message or click here>> http://wap. xxxmobilemovieclub.com?n=QJKGIGHJJGCBL\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'XXXMobileMovieClub: To use your credit, click the WAP link in the next txt message or click here>>  '"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 41
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "q8Wyf0pSHIj9"
      },
      "source": [
        "<font color='red'>Question 1 : Pourqui dans le code ci-dessous, utilise-t-on keras.preprocessing.pad_sequences ?</font>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ys3PVm2HEPwo"
      },
      "source": [
        "def tokenize_and_encode(text_data):\n",
        "  #fit Tokenizer : from sequences of words to lists of numbers\n",
        "  tokenizer = text.Tokenizer(\n",
        "            filters='!\"#$%&()*+,-./:;<=>?@[\\\\]^_`{|}~\\t\\n',\n",
        "            lower=True,\n",
        "            split=\" \",\n",
        "            oov_token=\"OUT_OF_VOCABULARY\"\n",
        "        )\n",
        "  tokenizer.fit_on_texts(text_data)\n",
        "  sequences = tokenizer.texts_to_sequences(text_data)\n",
        "  print(\"Example of output : \",  sequences[2])\n",
        "  print(\" For the input : \",text_data[2])\n",
        "\n",
        "  #pad the data for input into the RNN \n",
        "  #maxlen = max([len(x) for x in sequences])\n",
        "  padded_sequences = sequence.pad_sequences(sequences, padding=\"post\", maxlen=50)\n",
        "\n",
        "  print('Number of Unique Tokens: %d' % len(tokenizer.word_index))\n",
        "  return(padded_sequences, len(tokenizer.word_index)+1)"
      ],
      "execution_count": 46,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8dx0F5NEHl9N",
        "outputId": "a67be68c-f1ed-4d5d-e438-5e6244cad8f6",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "#encoding the whole dataset\n",
        "#targets\n",
        "#Binarize categories\n",
        "targets = data[\"Category\"].apply(lambda x: 0 if x==\"spam\" else 1).tolist()\n",
        "one_hot_targets = np.eye(2)[targets]\n",
        "#text\n",
        "text_data, vocab_size = tokenize_and_encode(data[\"Message\"].apply(clean_text))"
      ],
      "execution_count": 47,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Example of output :  [47, 480, 9, 20, 5, 783, 941, 3, 178, 1917, 1086, 648, 1918, 2301, 259, 2302, 71, 1917, 3, 1919, 3, 330, 480, 544, 942, 74, 386, 181, 649, 387, 2946]\n",
            " For the input :  Free entry in 2 a wkly comp to win FA Cup final tkts 21st May 2005. Text FA to 87121 to receive entry question(std txt rate)T&C's apply 08452810075over18's\n",
            "Number of Unique Tokens: 8820\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "330prtBWLmFI",
        "outputId": "14b009e3-e1e9-437d-b962-7362ee233a62",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "X_train, X_test, y_train, y_test = train_test_split(text_data, one_hot_targets, test_size=0.33, random_state=17)\n",
        "\n",
        "#Convert those arrays to numpy as it is the desired input to the Keras RNN\n",
        "X_train = np.array(X_train)\n",
        "X_test = np.array(X_test)\n",
        "y_train = np.array(y_train)\n",
        "y_test = np.array(y_test)\n",
        "\n",
        "print(\"Example of encoded train sequence: \", X_train[0])\n",
        "print(\"Example of encoded target: \", y_train[0])"
      ],
      "execution_count": 49,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Example of encoded train sequence:  [   5 1293  277   13  565   65   25 4070    3 1444  184  758   36   32\n",
            "  654  726   26 4071    7 4072  146   35  458    0    0    0    0    0\n",
            "    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
            "    0    0    0    0    0    0    0    0]\n",
            "Example of encoded target:  [0. 1.]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ocam_c9kRj9B"
      },
      "source": [
        "timestep = X_train[0].shape[0] # the length of a sequence (sentence, or time series, etc) is the timestep. It can vary, but we chose to pad to have a fixed length. Why ?\n",
        "n_features = 1 #each input on each timestep only is one number, so it is of size 1"
      ],
      "execution_count": 50,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VkxqKQPNMvsC"
      },
      "source": [
        "Pour les besoins de la démonstration, on se passe ici de cross-validation ou d'autres méthodes de validation et de tuning des hyperparamètres. Ce n'est pas rigoureux dans le cadre du développement d'un vrai modèle, il faudrait ici utiliser une fonction qui crée des sets de validation croisée comme vu dans le TP1"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1qZ1Rmptn0iC"
      },
      "source": [
        "#Fonction outil pour la suite\n",
        "def plot_history(history):\n",
        "    loss_list = [s for s in history.history.keys() if 'loss' in s and 'val' not in s]\n",
        "    val_loss_list = [s for s in history.history.keys() if 'loss' in s and 'val' in s]\n",
        "    acc_list = [s for s in history.history.keys() if 'acc' in s and 'val' not in s]\n",
        "    val_acc_list = [s for s in history.history.keys() if 'acc' in s and 'val' in s]\n",
        "    \n",
        "    if len(loss_list) == 0:\n",
        "        print('Loss is missing in history')\n",
        "        return \n",
        "    \n",
        "    ## As loss always exists\n",
        "    epochs = range(1,len(history.history[loss_list[0]]) + 1)\n",
        "    \n",
        "    ## Loss\n",
        "    plt.figure(1)\n",
        "    for l in loss_list:\n",
        "        plt.plot(epochs, history.history[l], 'b', label='Training loss (' + str(str(format(history.history[l][-1],'.5f'))+')'))\n",
        "    for l in val_loss_list:\n",
        "        plt.plot(epochs, history.history[l], 'g', label='Validation loss (' + str(str(format(history.history[l][-1],'.5f'))+')'))\n",
        "    \n",
        "    plt.title('Loss')\n",
        "    plt.xlabel('Epochs')\n",
        "    plt.ylabel('Loss')\n",
        "    plt.legend()\n",
        "    \n",
        "    ## Accuracy\n",
        "    plt.figure(2)\n",
        "    for l in acc_list:\n",
        "        plt.plot(epochs, history.history[l], 'b', label='Training accuracy (' + str(format(history.history[l][-1],'.5f'))+')')\n",
        "    for l in val_acc_list:    \n",
        "        plt.plot(epochs, history.history[l], 'g', label='Validation accuracy (' + str(format(history.history[l][-1],'.5f'))+')')\n",
        "\n",
        "    plt.title('Accuracy')\n",
        "    plt.xlabel('Epochs')\n",
        "    plt.ylabel('Accuracy')\n",
        "    plt.legend()\n",
        "    plt.show()"
      ],
      "execution_count": 51,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "puFoj8fXoF0J"
      },
      "source": [
        "def plot_confusion_matrix(cm, classes,\n",
        "                          normalize=False,\n",
        "                          cmap=plt.cm.Blues):\n",
        "    \"\"\"\n",
        "    This function prints and plots the confusion matrix.\n",
        "    Normalization can be applied by setting `normalize=True`.\n",
        "    \"\"\"\n",
        "    if normalize:\n",
        "        cm = cm.astype('float') / cm.sum(axis=1)[:, np.newaxis]\n",
        "        title='Normalized confusion matrix'\n",
        "    else:\n",
        "        title='Confusion matrix'\n",
        "\n",
        "    plt.imshow(cm, interpolation='nearest', cmap=cmap)\n",
        "    plt.title(title)\n",
        "    plt.colorbar()\n",
        "    tick_marks = np.arange(len(classes))\n",
        "    plt.xticks(tick_marks, classes, rotation=45)\n",
        "    plt.yticks(tick_marks, classes)\n",
        "\n",
        "    fmt = '.2f' if normalize else 'd'\n",
        "    thresh = cm.max() / 2.\n",
        "    for i, j in itertools.product(range(cm.shape[0]), range(cm.shape[1])):\n",
        "        plt.text(j, i, format(cm[i, j], fmt),\n",
        "                 horizontalalignment=\"center\",\n",
        "                 color=\"white\" if cm[i, j] > thresh else \"black\")\n",
        "\n",
        "    plt.tight_layout()\n",
        "    plt.ylabel('True label')\n",
        "    plt.xlabel('Predicted label')\n",
        "    plt.show()\n",
        "    \n",
        "## multiclass or binary report\n",
        "## If binary (sigmoid output), set binary parameter to True\n",
        "def full_multiclass_report(model,\n",
        "                           x,\n",
        "                           y_true,\n",
        "                           classes,\n",
        "                           batch_size=32,\n",
        "                           binary=False):\n",
        "    \n",
        "    # 2. Predict probabilities and stores in y_pred\n",
        "    y_pred = model.predict(x, batch_size=batch_size)\n",
        "    y_pred = y_pred.argmax(axis=1)\n",
        "    y_true = y_true.argmax(axis=1)\n",
        "    \n",
        "    # 3. Print accuracy score\n",
        "    print(\"Accuracy : \"+ str(accuracy_score(y_true,y_pred)))\n",
        "    \n",
        "    print(\"\")\n",
        "    \n",
        "    # 4. Print classification report\n",
        "    print(\"Classification Report\")\n",
        "    print(classification_report(y_true,y_pred,digits=5))    \n",
        "    \n",
        "    # 5. Plot confusion matrix\n",
        "    cnf_matrix = confusion_matrix(y_true, y_pred)\n",
        "    print(cnf_matrix)\n",
        "    plot_confusion_matrix(cnf_matrix,classes=classes)"
      ],
      "execution_count": 52,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kJ8DLJTgQzsF"
      },
      "source": [
        "#3. Mon premier RNN\n",
        "\n",
        "Il s'agit ici de l'architecture de base d'un RNN comme vu précédemment."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UHDM0e-lPA9o"
      },
      "source": [
        "# Keras' input for any recurrent neural network requires the following shape : (batch_size, timestep, n_features)\n",
        "#batch_size can be None, it will be input at train time, this is a default in Keras if all timesteps are equal\n",
        "#timestep is the length of your sequence\n",
        "#n_features is the number of features on each timestep. Had you done some embedding pre-processing, it would be larger than 1\n",
        "input=Input(shape=(timestep))\n",
        "embedding = Embedding(input_dim=vocab_size, output_dim=200, mask_zero=True, embeddings_initializer=\"zeros\")(input)\n",
        "rnn_layer = SimpleRNN(units = 24, activation = \"sigmoid\", recurrent_initializer= \"random_normal\")(embedding) #in : size (None, timesteps, 64), out : size (None, units)\n",
        "dense_layer=Dense(2, activation = \"softmax\")(rnn_layer) #in : size(None, units), out : size(None,1)\n",
        "model_rnn=Model(input,dense_layer)"
      ],
      "execution_count": 53,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "D6jjNj0XTmXV"
      },
      "source": [
        "<font color='red'> Questions : <ul>\n",
        "<li>Avez-vous vu que la dernière couche dense_layer est exactement la même chose qu'une classification logit ?</li>\n",
        "<li>Qu'avons-nous donc apporté comme plus-value avec le SimpleRNN ? </li>\n",
        "<li>Et donc, en quoi avons-nous fait du \"representation learning\" ici ?</li>\n",
        "</ul>\n",
        "</font>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8hKcSh19U5g4",
        "outputId": "ec44c1de-ceb6-4071-8e30-838e48ba0a15",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "#Output the model skeleton, and compile\n",
        "model_rnn.summary()"
      ],
      "execution_count": 54,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"functional_9\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "input_5 (InputLayer)         [(None, 50)]              0         \n",
            "_________________________________________________________________\n",
            "embedding_4 (Embedding)      (None, 50, 200)           1764200   \n",
            "_________________________________________________________________\n",
            "simple_rnn_1 (SimpleRNN)     (None, 24)                5400      \n",
            "_________________________________________________________________\n",
            "dense_4 (Dense)              (None, 2)                 50        \n",
            "=================================================================\n",
            "Total params: 1,769,650\n",
            "Trainable params: 1,769,650\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JEdcp6o7WRPE",
        "outputId": "0b21d176-a816-4915-e964-e40a9877e589",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "epochs = 25\n",
        "batch_size = 16\n",
        "optim = SGD(learning_rate=0.5)\n",
        "model_rnn.compile(optimizer=optim,loss=\"binary_crossentropy\", metrics = [\"binary_accuracy\"])\n",
        "\n",
        "#print_weights = LambdaCallback(on_epoch_end=lambda batch, logs: print(model.layers[1].get_weights())) #affiche les poids de la couche n*1, cad la couche SimpleRNN\n",
        "history = History()\n",
        "\n",
        "history=model_rnn.fit(X_train, y_train, epochs =epochs, batch_size=batch_size, verbose = 1, validation_split=0.2, callbacks = [history])#, print_weights])\n",
        "#watch out, pitfall in the code concerning validation data, documented here https://stackoverflow.com/questions/61706535/keras-validation-loss-and-accuracy-stuck-at-0"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/25\n",
            "187/187 [==============================] - 4s 20ms/step - loss: 0.4287 - binary_accuracy: 0.8546 - val_loss: 0.3791 - val_binary_accuracy: 0.8809\n",
            "Epoch 2/25\n",
            "187/187 [==============================] - 3s 18ms/step - loss: 0.4225 - binary_accuracy: 0.8549 - val_loss: 0.3734 - val_binary_accuracy: 0.8809\n",
            "Epoch 3/25\n",
            "187/187 [==============================] - 3s 18ms/step - loss: 0.3843 - binary_accuracy: 0.8562 - val_loss: 0.2989 - val_binary_accuracy: 0.8969\n",
            "Epoch 4/25\n",
            "187/187 [==============================] - 3s 18ms/step - loss: 0.2670 - binary_accuracy: 0.8938 - val_loss: 0.2850 - val_binary_accuracy: 0.9143\n",
            "Epoch 5/25\n",
            "187/187 [==============================] - 3s 19ms/step - loss: 0.1637 - binary_accuracy: 0.9383 - val_loss: 0.2340 - val_binary_accuracy: 0.9210\n",
            "Epoch 6/25\n",
            "187/187 [==============================] - 3s 18ms/step - loss: 0.0912 - binary_accuracy: 0.9682 - val_loss: 0.4576 - val_binary_accuracy: 0.7938\n",
            "Epoch 7/25\n",
            "187/187 [==============================] - 3s 19ms/step - loss: 0.0621 - binary_accuracy: 0.9786 - val_loss: 0.2154 - val_binary_accuracy: 0.9424\n",
            "Epoch 8/25\n",
            "187/187 [==============================] - 4s 19ms/step - loss: 0.0464 - binary_accuracy: 0.9842 - val_loss: 0.1892 - val_binary_accuracy: 0.9478\n",
            "Epoch 9/25\n",
            "120/187 [==================>...........] - ETA: 1s - loss: 0.0262 - binary_accuracy: 0.9932"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gUWsmK7jjssp"
      },
      "source": [
        "plot_history(history)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2H6PGdOPoNa3"
      },
      "source": [
        "full_multiclass_report(model_rnn, X_test, y_test, [0,1])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jwgO0MTZ8vVx"
      },
      "source": [
        "C'est beau ! Maintenant, enlevez de votre modèle la couche d'embedding. Oh-oh...\n",
        "\n",
        "<font color='red'>Question : Quel est le problème qui vient d'arriver ?</font> (indice : regardez la loss, que devrait-elle faire quand on sur-entraine beaucoup trop ?...). Décommenter la ligne #print_weights, et relancer la cellule. Quel est le diagnostic, que s'est-il passé à votre avis?\n",
        "\n",
        "Ce problème est un problème courant des réseaux de neurones récurrents (mais pas que !), il s'appelle le <font color='red'>Vanishing Gradient</font>, ou la disparition du gradient. Plus de détails ici :\n",
        "https://towardsdatascience.com/the-vanishing-gradient-problem-69bf08b15484"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rZajxdW0G1ks"
      },
      "source": [
        "#4. LSTM, évolution du RNN\n",
        "\n",
        "Des solutions au gradient qui disparait sont:\n",
        "  - changer de fonction d'activation, sigmoid est bien identifié pour poser des problèmes. (pourquoi ?)\n",
        "  - bien initialiser les poids (pourquoi ?)\n",
        "  - ajouter des couches de normalisation (pourquoi ?)\n",
        "  - avec tensorflow, masquer proprement (nous venons de le voir)\n",
        "Dans le cas inverse, un gradient qui explose, souvent, on clippe le gradient.\n",
        "\n",
        "Le LSTM résout plusieurs problèmes liées aux RNN de base, mais surtout celui du gradient qui disparait ou explose. Il permet aussi plus de finesse dans ce dont on se \"souvient\" ou pas dans le réseau.\n",
        "\n",
        "---\n",
        "\n",
        "Nous allons reprendre notre problème initial de classification de messages, mais maintenant avec un LSTM, et des fonctions d'activation plus fines.\n",
        "\n",
        "Pour le LSTM, la documentation Keras est bien faite :\n",
        "https://keras.io/api/layers/recurrent_layers/lstm/ et \n",
        "https://keras.io/api/layers/activations/\n",
        "\n",
        "---\n",
        "\n",
        "Attention, le choix par défaut est quand même un choix ! Soyez au moins conscients d'avoir choisi telle fonction d'activation ou telle initialisation, car nous avons vu que cela peut avoir de grosses conséquences. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nQFBbFafVleX"
      },
      "source": [
        "input=Input(shape=(timestep))\n",
        "embedding = Embedding(input_dim=vocab_size, output_dim=200, mask_zero=True)(input)\n",
        "lstm_layer = LSTM(units = 64, recurrent_activation = \"relu\")(embedding)\n",
        "dense_layer = Dense(2, activation = \"softmax\")(lstm_layer)\n",
        "\n",
        "model_lstm=Model(input,dense_layer)"
      ],
      "execution_count": 28,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3mq03w21WBpM"
      },
      "source": [
        "from keras.utils import plot_model\n",
        "plot_model(model_lstm)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HliccGPkYeIs",
        "outputId": "f77fe725-52ca-4bd2-a4ed-0638e299f976",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "epochs = 20\n",
        "batch_size = 16\n",
        "optim = Adam()\n",
        "model_lstm.compile(optimizer=optim,loss=\"binary_crossentropy\", metrics = [\"binary_accuracy\"])\n",
        "\n",
        "history = History()\n",
        "\n",
        "history=model_lstm.fit(X_train, y_train, epochs =epochs, batch_size=batch_size, verbose = 1, validation_split=0.2, callbacks = [history])"
      ],
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/20\n",
            "187/187 [==============================] - 12s 62ms/step - loss: 0.3901 - binary_accuracy: 0.8570 - val_loss: 0.1813 - val_binary_accuracy: 0.8795\n",
            "Epoch 2/20\n",
            "187/187 [==============================] - 11s 61ms/step - loss: 0.1444 - binary_accuracy: 0.9066 - val_loss: 0.1059 - val_binary_accuracy: 0.9813\n",
            "Epoch 3/20\n",
            "187/187 [==============================] - 11s 61ms/step - loss: 0.0203 - binary_accuracy: 0.9950 - val_loss: 0.0539 - val_binary_accuracy: 0.9853\n",
            "Epoch 4/20\n",
            "187/187 [==============================] - 11s 61ms/step - loss: 0.0046 - binary_accuracy: 0.9987 - val_loss: 0.0557 - val_binary_accuracy: 0.9826\n",
            "Epoch 5/20\n",
            "187/187 [==============================] - 11s 61ms/step - loss: 0.0025 - binary_accuracy: 0.9993 - val_loss: 0.0483 - val_binary_accuracy: 0.9920\n",
            "Epoch 6/20\n",
            "187/187 [==============================] - 12s 62ms/step - loss: 0.0014 - binary_accuracy: 0.9993 - val_loss: 0.0488 - val_binary_accuracy: 0.9920\n",
            "Epoch 7/20\n",
            "187/187 [==============================] - 12s 62ms/step - loss: 0.0012 - binary_accuracy: 0.9997 - val_loss: 0.0506 - val_binary_accuracy: 0.9906\n",
            "Epoch 8/20\n",
            "187/187 [==============================] - 12s 63ms/step - loss: 0.0013 - binary_accuracy: 0.9997 - val_loss: 0.0518 - val_binary_accuracy: 0.9880\n",
            "Epoch 9/20\n",
            "187/187 [==============================] - 12s 64ms/step - loss: 0.0013 - binary_accuracy: 0.9997 - val_loss: 0.0519 - val_binary_accuracy: 0.9893\n",
            "Epoch 10/20\n",
            "187/187 [==============================] - 12s 62ms/step - loss: 9.8870e-04 - binary_accuracy: 1.0000 - val_loss: 0.0532 - val_binary_accuracy: 0.9880\n",
            "Epoch 11/20\n",
            "187/187 [==============================] - 12s 62ms/step - loss: 9.5131e-04 - binary_accuracy: 1.0000 - val_loss: 0.0541 - val_binary_accuracy: 0.9880\n",
            "Epoch 12/20\n",
            "187/187 [==============================] - 15s 78ms/step - loss: 9.0289e-04 - binary_accuracy: 1.0000 - val_loss: 0.0550 - val_binary_accuracy: 0.9880\n",
            "Epoch 13/20\n",
            "187/187 [==============================] - 13s 70ms/step - loss: 7.8212e-04 - binary_accuracy: 1.0000 - val_loss: 0.0564 - val_binary_accuracy: 0.9866\n",
            "Epoch 14/20\n",
            "187/187 [==============================] - 11s 61ms/step - loss: 6.9860e-04 - binary_accuracy: 1.0000 - val_loss: 0.0570 - val_binary_accuracy: 0.9866\n",
            "Epoch 15/20\n",
            "187/187 [==============================] - 11s 61ms/step - loss: 6.8618e-04 - binary_accuracy: 1.0000 - val_loss: 0.0575 - val_binary_accuracy: 0.9866\n",
            "Epoch 16/20\n",
            "187/187 [==============================] - 11s 61ms/step - loss: 6.7786e-04 - binary_accuracy: 1.0000 - val_loss: 0.0579 - val_binary_accuracy: 0.9866\n",
            "Epoch 17/20\n",
            "187/187 [==============================] - 12s 63ms/step - loss: 6.7026e-04 - binary_accuracy: 1.0000 - val_loss: 0.0584 - val_binary_accuracy: 0.9866\n",
            "Epoch 18/20\n",
            "187/187 [==============================] - 11s 60ms/step - loss: 6.6349e-04 - binary_accuracy: 1.0000 - val_loss: 0.0590 - val_binary_accuracy: 0.9866\n",
            "Epoch 19/20\n",
            "187/187 [==============================] - 11s 61ms/step - loss: 6.5695e-04 - binary_accuracy: 1.0000 - val_loss: 0.0596 - val_binary_accuracy: 0.9866\n",
            "Epoch 20/20\n",
            "187/187 [==============================] - 11s 61ms/step - loss: 6.5042e-04 - binary_accuracy: 1.0000 - val_loss: 0.0601 - val_binary_accuracy: 0.9866\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sNwTqSmxn2Wv",
        "outputId": "d4c4b913-51eb-4f24-9235-9355dbed488a",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "plot_history(history)\n",
        "full_multiclass_report(model_lstm, X_test, y_test, [0,1])"
      ],
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        },
        {
          "output_type": "stream",
          "text": [
            "Accuracy : 0.13050570962479607\n",
            "\n",
            "Classification Report\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0    0.13051   1.00000   0.23088       240\n",
            "           1    0.00000   0.00000   0.00000      1599\n",
            "\n",
            "    accuracy                        0.13051      1839\n",
            "   macro avg    0.06525   0.50000   0.11544      1839\n",
            "weighted avg    0.01703   0.13051   0.03013      1839\n",
            "\n",
            "[[ 240    0]\n",
            " [1599    0]]\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/sklearn/metrics/_classification.py:1272: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 2 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QDewXT39UkAU"
      },
      "source": [
        "#5. Attention\n",
        "\n",
        "Code de l'attention repris de ce blog :\n",
        "https://matthewmcateer.me/blog/getting-started-with-attention-for-classification/\n",
        "\n",
        "Keras possède aussi un layer d'Attention selon Luong et d'attention selon Badanau https://keras.io/api/layers/attention_layers/additive_attention/.\n",
        "Je ne l'utilise pas car je n'arrive pas à voir explicitement à quoi correspondent key et value dans les calculs.\n",
        "\n",
        "Cette attention est un many-to-one, prenant donc les outputs d'un LSTM et applicant l'attention pour obtenir seulement le dernier output, car nous faisons de la classification. Pour de la traduction par exemple, la couche serait différente."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nykrNXjmH_YY"
      },
      "source": [
        "#class for Bahnadau attention (additive attention)\n",
        "from tensorflow.keras import Model\n",
        "import tensorflow as tf\n",
        "class AttentionB(Model):\n",
        "    def __init__(self, units, output_dim, name=\"attention\",**kwargs):\n",
        "        super(AttentionB, self).__init__(name=name)\n",
        "        self.W1 = Dense(units)\n",
        "        self.W2 = Dense(units)\n",
        "        self.V = Dense(1)\n",
        "        self.U = Dense(ouput_dim, activation= \"tanh\")\n",
        "\n",
        "    def call(self, h_s_bar, h_t):\n",
        "        #reshape h_t from (batch_size, hidden size) to (batch_size, 1, hidden size)\n",
        "        # we are doing this to perform addition to calculate the score\n",
        "        hidden_with_time_axis = tf.expand_dims(h_t, 1)\n",
        "\n",
        "        # the shape of the score tensor is (batch_size, max_length, units)\n",
        "        #units is the number of hidden units in the encoder LSTM\n",
        "        score_part1 = self.W1(h_s_bar) + self.W2(hidden_with_time_axis)\n",
        "        score = Activation(\"tanh\")(score_part1)\n",
        "        print(\"score:\", score.shape)\n",
        "\n",
        "        # attention_weights shape == (batch_size, max_length, 1)\n",
        "        # we get 1 at the last axis because we are applying score to self.V\n",
        "        attention_weights_part1 = self.V(score)\n",
        "        attention_weights = Activation(\"softmax\")\n",
        "        print(\"attention weights:\", attention_weights.shape)\n",
        "          \n",
        "        # context_vector shape after sum == (batch_size, hidden_size) #hidden_size = size of the hidden vector h_t that we input, not number of units nodes ! so hidden_size = size input in LSTM\n",
        "        context_vector = attention_weights * h_s_bar\n",
        "        print(\"context vector pre-sum:\", context_vector.shape)\n",
        "        context_vector = tf.reduce_sum(context_vector, axis=1)\n",
        "        print(\"context vector\", context_vector.shape)\n",
        "\n",
        "        concat_att_state= tf.concat([context_vector, h_t], 1)\n",
        "        print(\"concat att et ht:\", concat_att_state.shape)\n",
        "        attention_vector = self.U(concat_att_state)\n",
        "        print(\"attention vector:\", attention_vector.shape)\n",
        "        return  attention_vector, attention_weights"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ua39HbKk3ecZ"
      },
      "source": [
        "#class for Luong attention (multiplicative attention)\n",
        "from tensorflow.keras import Model\n",
        "from tensorflow.keras.layers import Dense, Lambda, dot, Activation, concatenate\n",
        "import tensorflow as tf\n",
        "class AttentionL(Model):\n",
        "    def __init__(self, output_dim=128, name=\"attention\",**kwargs):\n",
        "        super(AttentionL, self).__init__(name=name)\n",
        "        self.output_dim =output_dim\n",
        "        self.U = Dense(output_dim, activation =\"tanh\", name=\"attention_vector\", use_bias=False)\n",
        "\n",
        "    def call(self, encoder_hidden_states, h_t):\n",
        "        hidden_size = int(encoder_hidden_states.shape[2])\n",
        "        self.W = Dense(hidden_size)\n",
        "        self.V = Dense(1)\n",
        "        #print(\"encoder_h_s:\", encoder_hidden_states.shape)\n",
        "        #print(\"lst hidden state:\", h_t.shape)\n",
        "\n",
        "        # the shape of the score tensor is (batch_size, max_length, units)\n",
        "        score_first_part = self.W(encoder_hidden_states) #that is the W*h_s_bar in the slides' equations\n",
        "        # (batch_size, time_steps, hidden_size) dot (hidden_size, hidden_size) => (batch_size, time_steps, hidden_size)\n",
        "        #print(\"score part 1:\", score_first_part.shape)\n",
        "\n",
        "        h_t_with_time_axis = tf.expand_dims(h_t, 1)\n",
        "        #print(\"h_t_with_time_axis:\",  h_t_with_time_axis.shape)\n",
        "        score =  dot([score_first_part, h_t_with_time_axis], [2, 2], name='attention_score') # that is the h_t*W*h_s_bar in the slides' equations\n",
        "        # (batch_size, time_steps, hidden_size) dot   (batch_size, hidden_size)  => (batch_size, time_steps)\n",
        "        #print(\"score:\", score.shape)\n",
        "\n",
        "        # attention_weights shape == (batch_size, max_length, 1)\n",
        "        # we get 1 at the last axis because we are applying score to self.V\n",
        "        attention_weights = tf.nn.softmax(self.V(score), axis=1)\n",
        "        #print(\"attention weights:\", attention_weights.shape)\n",
        "          \n",
        "        # context_vector shape after sum == (batch_size, hidden_size) #hidden_size = size of the hidden vector h_t that we input, not number of units nodes ! so hidden_size = size input in LSTM\n",
        "        context_vector = dot()([attention_weights, encoder_hidden_states])\n",
        "        #print(\"context vector :\", context_vector.shape)\n",
        "\n",
        "        concat_att_state= concatenate([context_vector, h_t])\n",
        "        #print(\"concat att et ht:\", concat_att_state.shape)\n",
        "        attention_vector = self.U(concat_att_state)\n",
        "        #print(\"attention vector:\", attention_vector.shape)\n",
        "        return  attention_vector, attention_weights"
      ],
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "27GDBqTRtvKV"
      },
      "source": [
        "#Modele avec attention \n",
        "\n",
        "input=Input(shape=(timestep))\n",
        "embedding = Embedding(input_dim=vocab_size, output_dim=200, mask_zero=True)(input)\n",
        "(lstm_seq, state_h, state_c) = LSTM(units = 64, recurrent_activation = \"relu\", return_sequences=True, return_state=True)(embedding)\n",
        "av, attention_weights = AttentionL(128, name=\"attention\")(lstm_seq, state_h)\n",
        "dense_layer = Dense(2, activation = \"relu\")(av)\n",
        "model_att = Model(inputs=input, outputs=dense_layer)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FXfU0LhQNJQ-",
        "outputId": "01ac540d-e8d0-421a-aacb-f1b94f3fb099",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 192
        }
      },
      "source": [
        "from keras.utils import plot_model\n",
        "plot_model(model_att)"
      ],
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-22-9590f0201912>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mkeras\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mutils\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mplot_model\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mplot_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel_att\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m: name 'model_att' is not defined"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OXqK-kBtNMVn",
        "outputId": "bdf9c20b-2916-42bb-884d-708bd400a6ba",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "model_att.summary()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"functional_57\"\n",
            "__________________________________________________________________________________________________\n",
            "Layer (type)                    Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            "input_49 (InputLayer)           [(None, 50)]         0                                            \n",
            "__________________________________________________________________________________________________\n",
            "embedding_48 (Embedding)        (None, 50, 200)      1764400     input_49[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "lstm_47 (LSTM)                  [(None, 50, 64), (No 67840       embedding_48[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "attention (AttentionL)          ((None, 128), (None, 20546       lstm_47[0][0]                    \n",
            "                                                                 lstm_47[0][1]                    \n",
            "__________________________________________________________________________________________________\n",
            "dense_49 (Dense)                (None, 2)            258         attention[0][0]                  \n",
            "==================================================================================================\n",
            "Total params: 1,853,044\n",
            "Trainable params: 1,853,044\n",
            "Non-trainable params: 0\n",
            "__________________________________________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FeIGdZ4I5U37"
      },
      "source": [
        "#model for attention weights, share the exact same layers as our main model\n",
        "a_w_model = Model(inputs= model_att.inputs, outputs = model_att.get_layer(\"attention\").output)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "boT0oCAZw2QZ"
      },
      "source": [
        "from tensorflow.keras.callbacks import Callback\n",
        "\n",
        "# to visualise, we use the great boutny of keras' functional model.\n",
        "#we create our model that gets trained. And then on the side, we create another model, that shares exactly the same layers, but stops at the attention layer\n",
        "#the first model will train, and because they share layers, the layers of the visu model will also train\n",
        "#it suffices to get the output of the visu model to get the attention weights of the trained model\n",
        "\n",
        "class VisualiseAttentionMap(Callback):\n",
        "    def __init__(self, attention_weights_model, x_test, output_dir=None):\n",
        "        super(Callback, self).__init__()\n",
        "        self.visu_model = attention_weights_model\n",
        "        # best_weights to store the weights at which the minimum loss occurs.\n",
        "        self.x_test = x_test\n",
        "        self.output_dir = output_dir\n",
        "\n",
        "    def on_epoch_end(self, epoch, logs=None):\n",
        "        attention_map = self.visu_model.predict(self.x_test)\n",
        "        #print(attetion_map.shape)\n",
        "        # top is attention map.\n",
        "        # bottom is ground truth.\n",
        "        #plt.imshow(np.concatenate([attention_map, x_test_mask]), cmap='hot')\n",
        "\n",
        "        print(attention_map)\n",
        "\n",
        "        plt.imshow(attention_map, cmap='hot')\n",
        "\n",
        "        iteration_no = str(epoch).zfill(3)\n",
        "        plt.axis('off')\n",
        "        plt.title(f'Iteration {iteration_no} / {max_epoch}')\n",
        "        if self.output_dir is not None :\n",
        "          if not os.path.exists(self.output_dir):\n",
        "            os.makedirs(self.output_dir)\n",
        "          plt.savefig(f'{output_dir}/epoch_{iteration_no}.png')\n",
        "        plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8lURVZE8u5H2",
        "outputId": "3ca2a08c-f906-4fed-d5d2-8632e1a4ae5f",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "epochs = 25\n",
        "batch_size = 16\n",
        "optim = Adam()\n",
        "model_att.compile(optimizer=optim,loss=\"binary_crossentropy\", metrics = [\"binary_accuracy\"])\n",
        "\n",
        "history = History()\n",
        "#attmap = VisualiseAttentionMap(a_w_model, x_test=X_train[0:10])\n",
        "model_att.fit(X_train, y_train, epochs =epochs, batch_size=128, verbose = 1, validation_split=0.2)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/25\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "error",
          "ename": "ValueError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-192-6ea579a60d4c>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0mhistory\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mHistory\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0;31m#attmap = VisualiseAttentionMap(a_w_model, x_test=X_train[0:10])\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 8\u001b[0;31m \u001b[0mmodel_att\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepochs\u001b[0m \u001b[0;34m=\u001b[0m\u001b[0mepochs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m128\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mverbose\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalidation_split\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0.2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/engine/training.py\u001b[0m in \u001b[0;36m_method_wrapper\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    106\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_method_wrapper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    107\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_in_multi_worker_mode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# pylint: disable=protected-access\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 108\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mmethod\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    109\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    110\u001b[0m     \u001b[0;31m# Running inside `run_distribute_coordinator` already.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/engine/training.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[1;32m   1096\u001b[0m                 batch_size=batch_size):\n\u001b[1;32m   1097\u001b[0m               \u001b[0mcallbacks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_train_batch_begin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1098\u001b[0;31m               \u001b[0mtmp_logs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrain_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1099\u001b[0m               \u001b[0;32mif\u001b[0m \u001b[0mdata_handler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshould_sync\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1100\u001b[0m                 \u001b[0mcontext\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0masync_wait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    778\u001b[0m       \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    779\u001b[0m         \u001b[0mcompiler\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"nonXla\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 780\u001b[0;31m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    781\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    782\u001b[0m       \u001b[0mnew_tracing_count\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_tracing_count\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36m_call\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    838\u001b[0m         \u001b[0;31m# Lifting succeeded, so variables are initialized and we can run the\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    839\u001b[0m         \u001b[0;31m# stateless function.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 840\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_stateless_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    841\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    842\u001b[0m       \u001b[0mcanon_args\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcanon_kwds\u001b[0m \u001b[0;34m=\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m\\\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   2826\u001b[0m     \u001b[0;34m\"\"\"Calls a graph function specialized to the inputs.\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2827\u001b[0m     \u001b[0;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_lock\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2828\u001b[0;31m       \u001b[0mgraph_function\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_maybe_define_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2829\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mgraph_function\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_filtered_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# pylint: disable=protected-access\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2830\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m_maybe_define_function\u001b[0;34m(self, args, kwargs)\u001b[0m\n\u001b[1;32m   3211\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3212\u001b[0m       \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_function_cache\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmissed\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madd\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcall_context_key\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3213\u001b[0;31m       \u001b[0mgraph_function\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_create_graph_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3214\u001b[0m       \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_function_cache\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprimary\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mcache_key\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgraph_function\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3215\u001b[0m       \u001b[0;32mreturn\u001b[0m \u001b[0mgraph_function\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m_create_graph_function\u001b[0;34m(self, args, kwargs, override_flat_arg_shapes)\u001b[0m\n\u001b[1;32m   3073\u001b[0m             \u001b[0marg_names\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0marg_names\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3074\u001b[0m             \u001b[0moverride_flat_arg_shapes\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0moverride_flat_arg_shapes\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3075\u001b[0;31m             capture_by_value=self._capture_by_value),\n\u001b[0m\u001b[1;32m   3076\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_function_attributes\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3077\u001b[0m         \u001b[0mfunction_spec\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfunction_spec\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/func_graph.py\u001b[0m in \u001b[0;36mfunc_graph_from_py_func\u001b[0;34m(name, python_func, args, kwargs, signature, func_graph, autograph, autograph_options, add_control_dependencies, arg_names, op_return_value, collections, capture_by_value, override_flat_arg_shapes)\u001b[0m\n\u001b[1;32m    984\u001b[0m         \u001b[0m_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moriginal_func\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf_decorator\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munwrap\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpython_func\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    985\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 986\u001b[0;31m       \u001b[0mfunc_outputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpython_func\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mfunc_args\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mfunc_kwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    987\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    988\u001b[0m       \u001b[0;31m# invariant: `func_outputs` contains only Tensors, CompositeTensors,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36mwrapped_fn\u001b[0;34m(*args, **kwds)\u001b[0m\n\u001b[1;32m    598\u001b[0m         \u001b[0;31m# __wrapped__ allows AutoGraph to swap in a converted function. We give\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    599\u001b[0m         \u001b[0;31m# the function a weak reference to itself to avoid a reference cycle.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 600\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mweak_wrapped_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__wrapped__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    601\u001b[0m     \u001b[0mweak_wrapped_fn\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mweakref\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mref\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mwrapped_fn\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    602\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/func_graph.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    971\u001b[0m           \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# pylint:disable=broad-except\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    972\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mhasattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"ag_error_metadata\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 973\u001b[0;31m               \u001b[0;32mraise\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mag_error_metadata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto_exception\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    974\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    975\u001b[0m               \u001b[0;32mraise\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mValueError\u001b[0m: in user code:\n\n    /usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/engine/training.py:806 train_function  *\n        return step_function(self, iterator)\n    <ipython-input-186-7bd9b4b6a79c>:19 call  *\n        score_first_part = self.W(encoder_hidden_states) #that is the W*h_s_bar in the slides' equations\n    /usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/engine/base_layer.py:982 __call__  **\n        self._maybe_build(inputs)\n    /usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/engine/base_layer.py:2643 _maybe_build\n        self.build(input_shapes)  # pylint:disable=not-callable\n    /usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/layers/core.py:1178 build\n        trainable=True)\n    /usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/engine/base_layer.py:614 add_weight\n        caching_device=caching_device)\n    /usr/local/lib/python3.6/dist-packages/tensorflow/python/training/tracking/base.py:750 _add_variable_with_custom_getter\n        **kwargs_for_getter)\n    /usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/engine/base_layer_utils.py:145 make_variable\n        shape=variable_shape if variable_shape else None)\n    /usr/local/lib/python3.6/dist-packages/tensorflow/python/ops/variables.py:260 __call__\n        return cls._variable_v1_call(*args, **kwargs)\n    /usr/local/lib/python3.6/dist-packages/tensorflow/python/ops/variables.py:221 _variable_v1_call\n        shape=shape)\n    /usr/local/lib/python3.6/dist-packages/tensorflow/python/ops/variables.py:67 getter\n        return captured_getter(captured_previous, **kwargs)\n    /usr/local/lib/python3.6/dist-packages/tensorflow/python/distribute/distribute_lib.py:2857 creator\n        return next_creator(**kwargs)\n    /usr/local/lib/python3.6/dist-packages/tensorflow/python/ops/variables.py:67 getter\n        return captured_getter(captured_previous, **kwargs)\n    /usr/local/lib/python3.6/dist-packages/tensorflow/python/distribute/distribute_lib.py:2857 creator\n        return next_creator(**kwargs)\n    /usr/local/lib/python3.6/dist-packages/tensorflow/python/ops/variables.py:67 getter\n        return captured_getter(captured_previous, **kwargs)\n    /usr/local/lib/python3.6/dist-packages/tensorflow/python/distribute/distribute_lib.py:2857 creator\n        return next_creator(**kwargs)\n    /usr/local/lib/python3.6/dist-packages/tensorflow/python/ops/variables.py:67 getter\n        return captured_getter(captured_previous, **kwargs)\n    /usr/local/lib/python3.6/dist-packages/tensorflow/python/eager/def_function.py:702 invalid_creator_scope\n        \"tf.function-decorated function tried to create \"\n\n    ValueError: tf.function-decorated function tried to create variables on non-first call.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "p-UTD7sg3S58"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}