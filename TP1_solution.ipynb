{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "TP1_solution.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/CMallart/ateliers-NN/blob/main/TP1_solution.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GxDxQxGGjxcE"
      },
      "source": [
        "# Imports"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-TrIDLwh4RT4"
      },
      "source": [
        "import numpy as np\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Dense, Activation\n",
        "from tensorflow.keras.optimizers import Adam, RMSprop, SGD\n",
        "from tensorflow.keras.losses import CategoricalCrossentropy\n",
        "from tensorflow.keras.utils import to_categorical\n",
        "from tensorflow.keras.callbacks import EarlyStopping\n",
        "from sklearn.metrics import balanced_accuracy_score, confusion_matrix\n",
        "from sklearn.datasets import load_wine\n",
        "from sklearn.model_selection import KFold"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iYKA8fbikJUa"
      },
      "source": [
        "# Useful functions"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XivNo8Tf4IQF"
      },
      "source": [
        "def one_hot_encode_database(database, list_id):\n",
        "  \"\"\"One hot encode the columns of the database specified in list_id\n",
        "\n",
        "  return a copy of the database, on hot encoded\n",
        "  \"\"\"\n",
        "  encoded_database = np.empty(shape=(database.shape[0], 0), dtype=float)\n",
        "  for id in range(database.shape[1]):\n",
        "      if id in list_id:\n",
        "          original_column = database[:, id]\n",
        "          encoded_column = to_categorical(original_column.astype(int), num_classes=int(np.max(original_column)+1))\n",
        "          encoded_database = np.column_stack((encoded_database, encoded_column))\n",
        "      else:\n",
        "          original_column = database[:, id]\n",
        "          encoded_database = np.column_stack((encoded_database, original_column))\n",
        "  return encoded_database"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kKsMRYfOk3dw"
      },
      "source": [
        "def normalize_database(database, list_id):\n",
        "  \"\"\"Normalize between 0 and 1 each column of the database specified in list_id.\n",
        "\n",
        "  return a copy of the database, normalized. \n",
        "  \"\"\"\n",
        "  encoded_database = database.copy()\n",
        "  for id in list_id:\n",
        "      encoded_database[:, id] = (encoded_database[:, id] - np.amin(encoded_database[:, id])) / (np.amax(encoded_database[:, id]) - np.amin(encoded_database[:, id]))\n",
        "  return encoded_database"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dL2YKwFuk_e7"
      },
      "source": [
        "def build_NN(layer_list, input_dim, output_dim, lr=0.001):\n",
        "  \"\"\"Construct a layer composed of dense layers, which dimensions are definded in the layer_list argument.\n",
        "\n",
        "  return the constructed and compiled model.\n",
        "  \"\"\"\n",
        "  # Q7: add layers and \"compile\" the model\n",
        "  model = Sequential()\n",
        "  #Add layers\n",
        "  model.add(Dense(layer_list[0], input_dim=input_dim, activation='relu'))\n",
        "  for layer in layer_list[1:]:\n",
        "      model.add(Dense(layer, activation='relu'))\n",
        "  model.add(Dense(output_dim))\n",
        "\n",
        "  #Compile the network\n",
        "  model.compile(loss=CategoricalCrossentropy(from_logits=True), optimizer=Adam(lr), metrics=['accuracy'])\n",
        "  return model"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XoHbcM8Pleny"
      },
      "source": [
        "# Main"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_bSyM50s0dgj"
      },
      "source": [
        "## Hyper-parameters"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nRxqrKRl0dqA"
      },
      "source": [
        "nb_fold = 5\n",
        "layer_list = [50, 50, 20]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BiCpRfVj0pNI"
      },
      "source": [
        "## Initialization"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KE2osmbv0pUc"
      },
      "source": [
        "rng = np.random.default_rng()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "I2OomsrSlj9u"
      },
      "source": [
        "## Prepare data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8Rpz9PlLldry",
        "outputId": "46220b13-2d92-4e4e-901a-05ca49c96645",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "\n",
        "database = load_wine()\n",
        "print('--- original database ---\\n')\n",
        "print(f'{database.data.shape[0]} examples, {database.data.shape[1]} features')\n",
        "for i in [10, 80, 140]:\n",
        "  print(f'label of example {i:3d}: {database.target[i]}')\n",
        "\n",
        "# Q7: one hot encode the class and normalize the features of the database here\n",
        "data = normalize_database(database.data, range(database.data.shape[1]))\n",
        "target = one_hot_encode_database(database.target.reshape([-1,1]), [0])\n",
        "\n",
        "random_indices = np.arange(data.shape[0])\n",
        "rng.shuffle(random_indices)\n",
        "data = data[random_indices,:]\n",
        "target = target[random_indices,:]\n",
        "print('\\n--- after randomization ---\\n')\n",
        "print(f'{data.shape[0]} examples, {data.shape[1]} features')\n",
        "for i in [10, 80, 140]:\n",
        "  print(f'label of example {i:3d}: {target[i]}')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "--- original database ---\n",
            "\n",
            "178 examples, 13 features\n",
            "label of example  10: 0\n",
            "label of example  80: 1\n",
            "label of example 140: 2\n",
            "\n",
            "--- after randomization ---\n",
            "\n",
            "178 examples, 13 features\n",
            "label of example  10: [1. 0. 0.]\n",
            "label of example  80: [1. 0. 0.]\n",
            "label of example 140: [0. 0. 1.]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "u-eK49yzlzqA"
      },
      "source": [
        "## Build / Fit / avaluate (quick check) "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rnabyC7Ylz85",
        "outputId": "3f9ce49e-b86e-4c40-8221-f79265367790",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "# Q10: quick check\n",
        "model = build_NN(layer_list, data.shape[1], target.shape[1], lr=0.1)\n",
        "model.summary()\n",
        "model.fit(data, target, batch_size=16, epochs=100)\n",
        "model.evaluate(data, target)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"sequential\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "dense (Dense)                (None, 50)                700       \n",
            "_________________________________________________________________\n",
            "dense_1 (Dense)              (None, 50)                2550      \n",
            "_________________________________________________________________\n",
            "dense_2 (Dense)              (None, 20)                1020      \n",
            "_________________________________________________________________\n",
            "dense_3 (Dense)              (None, 3)                 63        \n",
            "=================================================================\n",
            "Total params: 4,333\n",
            "Trainable params: 4,333\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "Epoch 1/100\n",
            "12/12 [==============================] - 0s 2ms/step - loss: 1.1218 - accuracy: 0.4719\n",
            "Epoch 2/100\n",
            "12/12 [==============================] - 0s 1ms/step - loss: 0.7480 - accuracy: 0.6461\n",
            "Epoch 3/100\n",
            "12/12 [==============================] - 0s 1ms/step - loss: 0.4430 - accuracy: 0.8258\n",
            "Epoch 4/100\n",
            "12/12 [==============================] - 0s 1ms/step - loss: 0.3328 - accuracy: 0.8483\n",
            "Epoch 5/100\n",
            "12/12 [==============================] - 0s 1ms/step - loss: 0.1989 - accuracy: 0.9382\n",
            "Epoch 6/100\n",
            "12/12 [==============================] - 0s 1ms/step - loss: 0.1138 - accuracy: 0.9607\n",
            "Epoch 7/100\n",
            "12/12 [==============================] - 0s 1ms/step - loss: 0.0478 - accuracy: 0.9944\n",
            "Epoch 8/100\n",
            "12/12 [==============================] - 0s 1ms/step - loss: 0.1351 - accuracy: 0.9551\n",
            "Epoch 9/100\n",
            "12/12 [==============================] - 0s 1ms/step - loss: 0.0738 - accuracy: 0.9831\n",
            "Epoch 10/100\n",
            "12/12 [==============================] - 0s 1ms/step - loss: 0.0561 - accuracy: 0.9888\n",
            "Epoch 11/100\n",
            "12/12 [==============================] - 0s 1ms/step - loss: 0.0701 - accuracy: 0.9719\n",
            "Epoch 12/100\n",
            "12/12 [==============================] - 0s 1ms/step - loss: 0.0994 - accuracy: 0.9663\n",
            "Epoch 13/100\n",
            "12/12 [==============================] - 0s 1ms/step - loss: 0.0481 - accuracy: 0.9888\n",
            "Epoch 14/100\n",
            "12/12 [==============================] - 0s 1ms/step - loss: 0.0670 - accuracy: 0.9719\n",
            "Epoch 15/100\n",
            "12/12 [==============================] - 0s 2ms/step - loss: 0.0189 - accuracy: 1.0000\n",
            "Epoch 16/100\n",
            "12/12 [==============================] - 0s 1ms/step - loss: 0.0046 - accuracy: 1.0000\n",
            "Epoch 17/100\n",
            "12/12 [==============================] - 0s 2ms/step - loss: 0.0018 - accuracy: 1.0000\n",
            "Epoch 18/100\n",
            "12/12 [==============================] - 0s 1ms/step - loss: 0.0012 - accuracy: 1.0000\n",
            "Epoch 19/100\n",
            "12/12 [==============================] - 0s 1ms/step - loss: 3.9846e-04 - accuracy: 1.0000\n",
            "Epoch 20/100\n",
            "12/12 [==============================] - 0s 2ms/step - loss: 6.5969e-04 - accuracy: 1.0000\n",
            "Epoch 21/100\n",
            "12/12 [==============================] - 0s 2ms/step - loss: 2.5729e-04 - accuracy: 1.0000\n",
            "Epoch 22/100\n",
            "12/12 [==============================] - 0s 1ms/step - loss: 1.9199e-04 - accuracy: 1.0000\n",
            "Epoch 23/100\n",
            "12/12 [==============================] - 0s 2ms/step - loss: 1.8120e-04 - accuracy: 1.0000\n",
            "Epoch 24/100\n",
            "12/12 [==============================] - 0s 1ms/step - loss: 2.5101e-04 - accuracy: 1.0000\n",
            "Epoch 25/100\n",
            "12/12 [==============================] - 0s 1ms/step - loss: 1.8995e-04 - accuracy: 1.0000\n",
            "Epoch 26/100\n",
            "12/12 [==============================] - 0s 1ms/step - loss: 1.6264e-04 - accuracy: 1.0000\n",
            "Epoch 27/100\n",
            "12/12 [==============================] - 0s 2ms/step - loss: 1.1613e-04 - accuracy: 1.0000\n",
            "Epoch 28/100\n",
            "12/12 [==============================] - 0s 2ms/step - loss: 1.0921e-04 - accuracy: 1.0000\n",
            "Epoch 29/100\n",
            "12/12 [==============================] - 0s 1ms/step - loss: 1.0395e-04 - accuracy: 1.0000\n",
            "Epoch 30/100\n",
            "12/12 [==============================] - 0s 1ms/step - loss: 9.3943e-05 - accuracy: 1.0000\n",
            "Epoch 31/100\n",
            "12/12 [==============================] - 0s 2ms/step - loss: 8.8781e-05 - accuracy: 1.0000\n",
            "Epoch 32/100\n",
            "12/12 [==============================] - 0s 2ms/step - loss: 8.3997e-05 - accuracy: 1.0000\n",
            "Epoch 33/100\n",
            "12/12 [==============================] - 0s 2ms/step - loss: 7.9222e-05 - accuracy: 1.0000\n",
            "Epoch 34/100\n",
            "12/12 [==============================] - 0s 1ms/step - loss: 7.6125e-05 - accuracy: 1.0000\n",
            "Epoch 35/100\n",
            "12/12 [==============================] - 0s 1ms/step - loss: 7.2724e-05 - accuracy: 1.0000\n",
            "Epoch 36/100\n",
            "12/12 [==============================] - 0s 1ms/step - loss: 8.3654e-05 - accuracy: 1.0000\n",
            "Epoch 37/100\n",
            "12/12 [==============================] - 0s 1ms/step - loss: 8.1522e-05 - accuracy: 1.0000\n",
            "Epoch 38/100\n",
            "12/12 [==============================] - 0s 1ms/step - loss: 5.9889e-05 - accuracy: 1.0000\n",
            "Epoch 39/100\n",
            "12/12 [==============================] - 0s 1ms/step - loss: 5.6467e-05 - accuracy: 1.0000\n",
            "Epoch 40/100\n",
            "12/12 [==============================] - 0s 1ms/step - loss: 5.4833e-05 - accuracy: 1.0000\n",
            "Epoch 41/100\n",
            "12/12 [==============================] - 0s 1ms/step - loss: 5.2083e-05 - accuracy: 1.0000\n",
            "Epoch 42/100\n",
            "12/12 [==============================] - 0s 1ms/step - loss: 4.9332e-05 - accuracy: 1.0000\n",
            "Epoch 43/100\n",
            "12/12 [==============================] - 0s 1ms/step - loss: 4.7680e-05 - accuracy: 1.0000\n",
            "Epoch 44/100\n",
            "12/12 [==============================] - 0s 2ms/step - loss: 4.6116e-05 - accuracy: 1.0000\n",
            "Epoch 45/100\n",
            "12/12 [==============================] - 0s 2ms/step - loss: 4.3791e-05 - accuracy: 1.0000\n",
            "Epoch 46/100\n",
            "12/12 [==============================] - 0s 1ms/step - loss: 4.2534e-05 - accuracy: 1.0000\n",
            "Epoch 47/100\n",
            "12/12 [==============================] - 0s 1ms/step - loss: 4.2085e-05 - accuracy: 1.0000\n",
            "Epoch 48/100\n",
            "12/12 [==============================] - 0s 1ms/step - loss: 3.9196e-05 - accuracy: 1.0000\n",
            "Epoch 49/100\n",
            "12/12 [==============================] - 0s 1ms/step - loss: 3.8581e-05 - accuracy: 1.0000\n",
            "Epoch 50/100\n",
            "12/12 [==============================] - 0s 1ms/step - loss: 3.6615e-05 - accuracy: 1.0000\n",
            "Epoch 51/100\n",
            "12/12 [==============================] - 0s 1ms/step - loss: 3.5128e-05 - accuracy: 1.0000\n",
            "Epoch 52/100\n",
            "12/12 [==============================] - 0s 1ms/step - loss: 3.6293e-05 - accuracy: 1.0000\n",
            "Epoch 53/100\n",
            "12/12 [==============================] - 0s 1ms/step - loss: 3.5502e-05 - accuracy: 1.0000\n",
            "Epoch 54/100\n",
            "12/12 [==============================] - 0s 1ms/step - loss: 3.1998e-05 - accuracy: 1.0000\n",
            "Epoch 55/100\n",
            "12/12 [==============================] - 0s 1ms/step - loss: 3.0084e-05 - accuracy: 1.0000\n",
            "Epoch 56/100\n",
            "12/12 [==============================] - 0s 1ms/step - loss: 2.8983e-05 - accuracy: 1.0000\n",
            "Epoch 57/100\n",
            "12/12 [==============================] - 0s 1ms/step - loss: 2.8420e-05 - accuracy: 1.0000\n",
            "Epoch 58/100\n",
            "12/12 [==============================] - 0s 2ms/step - loss: 2.7698e-05 - accuracy: 1.0000\n",
            "Epoch 59/100\n",
            "12/12 [==============================] - 0s 2ms/step - loss: 2.6886e-05 - accuracy: 1.0000\n",
            "Epoch 60/100\n",
            "12/12 [==============================] - 0s 1ms/step - loss: 2.5839e-05 - accuracy: 1.0000\n",
            "Epoch 61/100\n",
            "12/12 [==============================] - 0s 2ms/step - loss: 2.4900e-05 - accuracy: 1.0000\n",
            "Epoch 62/100\n",
            "12/12 [==============================] - 0s 1ms/step - loss: 2.4221e-05 - accuracy: 1.0000\n",
            "Epoch 63/100\n",
            "12/12 [==============================] - 0s 1ms/step - loss: 2.3393e-05 - accuracy: 1.0000\n",
            "Epoch 64/100\n",
            "12/12 [==============================] - 0s 2ms/step - loss: 2.2824e-05 - accuracy: 1.0000\n",
            "Epoch 65/100\n",
            "12/12 [==============================] - 0s 1ms/step - loss: 2.2353e-05 - accuracy: 1.0000\n",
            "Epoch 66/100\n",
            "12/12 [==============================] - 0s 1ms/step - loss: 2.1981e-05 - accuracy: 1.0000\n",
            "Epoch 67/100\n",
            "12/12 [==============================] - 0s 1ms/step - loss: 2.1181e-05 - accuracy: 1.0000\n",
            "Epoch 68/100\n",
            "12/12 [==============================] - 0s 1ms/step - loss: 2.0721e-05 - accuracy: 1.0000\n",
            "Epoch 69/100\n",
            "12/12 [==============================] - 0s 1ms/step - loss: 2.0035e-05 - accuracy: 1.0000\n",
            "Epoch 70/100\n",
            "12/12 [==============================] - 0s 1ms/step - loss: 1.9490e-05 - accuracy: 1.0000\n",
            "Epoch 71/100\n",
            "12/12 [==============================] - 0s 1ms/step - loss: 1.9494e-05 - accuracy: 1.0000\n",
            "Epoch 72/100\n",
            "12/12 [==============================] - 0s 1ms/step - loss: 1.8699e-05 - accuracy: 1.0000\n",
            "Epoch 73/100\n",
            "12/12 [==============================] - 0s 1ms/step - loss: 1.8391e-05 - accuracy: 1.0000\n",
            "Epoch 74/100\n",
            "12/12 [==============================] - 0s 1ms/step - loss: 1.7818e-05 - accuracy: 1.0000\n",
            "Epoch 75/100\n",
            "12/12 [==============================] - 0s 1ms/step - loss: 1.7291e-05 - accuracy: 1.0000\n",
            "Epoch 76/100\n",
            "12/12 [==============================] - 0s 2ms/step - loss: 1.7102e-05 - accuracy: 1.0000\n",
            "Epoch 77/100\n",
            "12/12 [==============================] - 0s 2ms/step - loss: 1.6516e-05 - accuracy: 1.0000\n",
            "Epoch 78/100\n",
            "12/12 [==============================] - 0s 1ms/step - loss: 1.6108e-05 - accuracy: 1.0000\n",
            "Epoch 79/100\n",
            "12/12 [==============================] - 0s 1ms/step - loss: 1.5882e-05 - accuracy: 1.0000\n",
            "Epoch 80/100\n",
            "12/12 [==============================] - 0s 1ms/step - loss: 1.5377e-05 - accuracy: 1.0000\n",
            "Epoch 81/100\n",
            "12/12 [==============================] - 0s 2ms/step - loss: 1.5009e-05 - accuracy: 1.0000\n",
            "Epoch 82/100\n",
            "12/12 [==============================] - 0s 1ms/step - loss: 1.4740e-05 - accuracy: 1.0000\n",
            "Epoch 83/100\n",
            "12/12 [==============================] - 0s 2ms/step - loss: 1.4348e-05 - accuracy: 1.0000\n",
            "Epoch 84/100\n",
            "12/12 [==============================] - 0s 1ms/step - loss: 1.4039e-05 - accuracy: 1.0000\n",
            "Epoch 85/100\n",
            "12/12 [==============================] - 0s 1ms/step - loss: 1.3788e-05 - accuracy: 1.0000\n",
            "Epoch 86/100\n",
            "12/12 [==============================] - 0s 1ms/step - loss: 1.3447e-05 - accuracy: 1.0000\n",
            "Epoch 87/100\n",
            "12/12 [==============================] - 0s 1ms/step - loss: 1.3430e-05 - accuracy: 1.0000\n",
            "Epoch 88/100\n",
            "12/12 [==============================] - 0s 1ms/step - loss: 1.3045e-05 - accuracy: 1.0000\n",
            "Epoch 89/100\n",
            "12/12 [==============================] - 0s 2ms/step - loss: 1.2704e-05 - accuracy: 1.0000\n",
            "Epoch 90/100\n",
            "12/12 [==============================] - 0s 1ms/step - loss: 1.2366e-05 - accuracy: 1.0000\n",
            "Epoch 91/100\n",
            "12/12 [==============================] - 0s 1ms/step - loss: 1.2078e-05 - accuracy: 1.0000\n",
            "Epoch 92/100\n",
            "12/12 [==============================] - 0s 1ms/step - loss: 1.1879e-05 - accuracy: 1.0000\n",
            "Epoch 93/100\n",
            "12/12 [==============================] - 0s 2ms/step - loss: 1.1627e-05 - accuracy: 1.0000\n",
            "Epoch 94/100\n",
            "12/12 [==============================] - 0s 2ms/step - loss: 1.1367e-05 - accuracy: 1.0000\n",
            "Epoch 95/100\n",
            "12/12 [==============================] - 0s 1ms/step - loss: 1.1184e-05 - accuracy: 1.0000\n",
            "Epoch 96/100\n",
            "12/12 [==============================] - 0s 1ms/step - loss: 1.1003e-05 - accuracy: 1.0000\n",
            "Epoch 97/100\n",
            "12/12 [==============================] - 0s 1ms/step - loss: 1.0808e-05 - accuracy: 1.0000\n",
            "Epoch 98/100\n",
            "12/12 [==============================] - 0s 2ms/step - loss: 1.0630e-05 - accuracy: 1.0000\n",
            "Epoch 99/100\n",
            "12/12 [==============================] - 0s 1ms/step - loss: 1.0361e-05 - accuracy: 1.0000\n",
            "Epoch 100/100\n",
            "12/12 [==============================] - 0s 1ms/step - loss: 1.0294e-05 - accuracy: 1.0000\n",
            "6/6 [==============================] - 0s 1ms/step - loss: 1.0054e-05 - accuracy: 1.0000\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[1.0053917321783956e-05, 1.0]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VYUDQqyAl5S7"
      },
      "source": [
        "## Build / Fit / avaluate (cross-validated) "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eP9BNryyl5gL",
        "outputId": "38d9a2ff-44e1-4458-b76c-e51e3331620d",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "gt_and_pred = np.empty(shape=(2, 0))\n",
        "\n",
        "for train_index, test_index in KFold(n_splits=nb_fold).split(data):\n",
        "  training_data, validation_data = data[train_index], data[test_index]\n",
        "  training_target, validation_target = target[train_index], target[test_index]\n",
        "\n",
        "  # Q11: test several learning rates\n",
        "  model = build_NN(layer_list, data.shape[1], target.shape[1], lr=0.1)\n",
        "\n",
        "  callback = EarlyStopping(patience=5)\n",
        "  # Q13: add EarlyStopping() callback\n",
        "  model.fit(training_data, training_target, batch_size=16, epochs=200, validation_data=(validation_data, validation_target), shuffle=True, callbacks=[callback])\n",
        "\n",
        "  fold_prediction = model.predict(validation_data)\n",
        "  gt_and_pred = np.column_stack((gt_and_pred, np.array([np.argmax(validation_target, axis=1), np.argmax(fold_prediction, axis=1)])))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/200\n",
            "9/9 [==============================] - 0s 18ms/step - loss: 1.2656 - accuracy: 0.4648 - val_loss: 0.8046 - val_accuracy: 0.5000\n",
            "Epoch 2/200\n",
            "9/9 [==============================] - 0s 3ms/step - loss: 0.6600 - accuracy: 0.6127 - val_loss: 0.5386 - val_accuracy: 0.6944\n",
            "Epoch 3/200\n",
            "9/9 [==============================] - 0s 3ms/step - loss: 0.5807 - accuracy: 0.6127 - val_loss: 0.5161 - val_accuracy: 0.6667\n",
            "Epoch 4/200\n",
            "9/9 [==============================] - 0s 3ms/step - loss: 0.4668 - accuracy: 0.7324 - val_loss: 0.3242 - val_accuracy: 0.8056\n",
            "Epoch 5/200\n",
            "9/9 [==============================] - 0s 3ms/step - loss: 0.4114 - accuracy: 0.8380 - val_loss: 0.6410 - val_accuracy: 0.7500\n",
            "Epoch 6/200\n",
            "9/9 [==============================] - 0s 3ms/step - loss: 0.3337 - accuracy: 0.8732 - val_loss: 0.2309 - val_accuracy: 0.8611\n",
            "Epoch 7/200\n",
            "9/9 [==============================] - 0s 3ms/step - loss: 0.1586 - accuracy: 0.9155 - val_loss: 0.2410 - val_accuracy: 0.9444\n",
            "Epoch 8/200\n",
            "9/9 [==============================] - 0s 4ms/step - loss: 0.1342 - accuracy: 0.9507 - val_loss: 0.0527 - val_accuracy: 1.0000\n",
            "Epoch 9/200\n",
            "9/9 [==============================] - 0s 4ms/step - loss: 0.0446 - accuracy: 0.9789 - val_loss: 0.0612 - val_accuracy: 1.0000\n",
            "Epoch 10/200\n",
            "9/9 [==============================] - 0s 4ms/step - loss: 0.0315 - accuracy: 0.9930 - val_loss: 0.1552 - val_accuracy: 0.9167\n",
            "Epoch 11/200\n",
            "9/9 [==============================] - 0s 4ms/step - loss: 0.1606 - accuracy: 0.9507 - val_loss: 0.0089 - val_accuracy: 1.0000\n",
            "Epoch 12/200\n",
            "9/9 [==============================] - 0s 4ms/step - loss: 0.1630 - accuracy: 0.9437 - val_loss: 0.2780 - val_accuracy: 0.8889\n",
            "Epoch 13/200\n",
            "9/9 [==============================] - 0s 3ms/step - loss: 0.1589 - accuracy: 0.9577 - val_loss: 0.0419 - val_accuracy: 1.0000\n",
            "Epoch 14/200\n",
            "9/9 [==============================] - 0s 4ms/step - loss: 0.0966 - accuracy: 0.9577 - val_loss: 0.0550 - val_accuracy: 1.0000\n",
            "Epoch 15/200\n",
            "9/9 [==============================] - 0s 4ms/step - loss: 0.3665 - accuracy: 0.9225 - val_loss: 0.6664 - val_accuracy: 0.8056\n",
            "Epoch 16/200\n",
            "9/9 [==============================] - 0s 4ms/step - loss: 0.3497 - accuracy: 0.8662 - val_loss: 0.3292 - val_accuracy: 0.9444\n",
            "Epoch 1/200\n",
            "9/9 [==============================] - 0s 16ms/step - loss: 1.3867 - accuracy: 0.5634 - val_loss: 1.0123 - val_accuracy: 0.7500\n",
            "Epoch 2/200\n",
            "9/9 [==============================] - 0s 3ms/step - loss: 0.6923 - accuracy: 0.7113 - val_loss: 0.6778 - val_accuracy: 0.6111\n",
            "Epoch 3/200\n",
            "9/9 [==============================] - 0s 3ms/step - loss: 0.5364 - accuracy: 0.8521 - val_loss: 0.3107 - val_accuracy: 0.8611\n",
            "Epoch 4/200\n",
            "9/9 [==============================] - 0s 3ms/step - loss: 0.3263 - accuracy: 0.8944 - val_loss: 0.7968 - val_accuracy: 0.8056\n",
            "Epoch 5/200\n",
            "9/9 [==============================] - 0s 4ms/step - loss: 0.7425 - accuracy: 0.8803 - val_loss: 0.6592 - val_accuracy: 0.7500\n",
            "Epoch 6/200\n",
            "9/9 [==============================] - 0s 4ms/step - loss: 0.5122 - accuracy: 0.8239 - val_loss: 0.3049 - val_accuracy: 0.8889\n",
            "Epoch 7/200\n",
            "9/9 [==============================] - 0s 3ms/step - loss: 0.3016 - accuracy: 0.9366 - val_loss: 0.2087 - val_accuracy: 0.9167\n",
            "Epoch 8/200\n",
            "9/9 [==============================] - 0s 3ms/step - loss: 0.1555 - accuracy: 0.9577 - val_loss: 0.2556 - val_accuracy: 0.9167\n",
            "Epoch 9/200\n",
            "9/9 [==============================] - 0s 3ms/step - loss: 0.1508 - accuracy: 0.9648 - val_loss: 0.3797 - val_accuracy: 0.9167\n",
            "Epoch 10/200\n",
            "9/9 [==============================] - 0s 3ms/step - loss: 0.1193 - accuracy: 0.9718 - val_loss: 0.1555 - val_accuracy: 0.9444\n",
            "Epoch 11/200\n",
            "9/9 [==============================] - 0s 3ms/step - loss: 0.0820 - accuracy: 0.9859 - val_loss: 0.1129 - val_accuracy: 0.9722\n",
            "Epoch 12/200\n",
            "9/9 [==============================] - 0s 3ms/step - loss: 0.0725 - accuracy: 0.9859 - val_loss: 0.1101 - val_accuracy: 0.9722\n",
            "Epoch 13/200\n",
            "9/9 [==============================] - 0s 4ms/step - loss: 0.0716 - accuracy: 0.9789 - val_loss: 0.1187 - val_accuracy: 0.9722\n",
            "Epoch 14/200\n",
            "9/9 [==============================] - 0s 4ms/step - loss: 0.0527 - accuracy: 0.9930 - val_loss: 0.1235 - val_accuracy: 0.9722\n",
            "Epoch 15/200\n",
            "9/9 [==============================] - 0s 4ms/step - loss: 0.0817 - accuracy: 0.9718 - val_loss: 0.1380 - val_accuracy: 0.9444\n",
            "Epoch 16/200\n",
            "9/9 [==============================] - 0s 4ms/step - loss: 0.0796 - accuracy: 0.9789 - val_loss: 0.1170 - val_accuracy: 0.9722\n",
            "Epoch 17/200\n",
            "9/9 [==============================] - 0s 4ms/step - loss: 0.0372 - accuracy: 0.9859 - val_loss: 0.1693 - val_accuracy: 0.9722\n",
            "Epoch 1/200\n",
            "9/9 [==============================] - 0s 16ms/step - loss: 1.3573 - accuracy: 0.3873 - val_loss: 1.1474 - val_accuracy: 0.3889\n",
            "Epoch 2/200\n",
            "9/9 [==============================] - 0s 3ms/step - loss: 0.7080 - accuracy: 0.6479 - val_loss: 0.2487 - val_accuracy: 0.9167\n",
            "Epoch 3/200\n",
            "9/9 [==============================] - 0s 3ms/step - loss: 0.3843 - accuracy: 0.8732 - val_loss: 0.2098 - val_accuracy: 0.9444\n",
            "Epoch 4/200\n",
            "9/9 [==============================] - 0s 3ms/step - loss: 0.2720 - accuracy: 0.9225 - val_loss: 0.2665 - val_accuracy: 0.9167\n",
            "Epoch 5/200\n",
            "9/9 [==============================] - 0s 3ms/step - loss: 0.1156 - accuracy: 0.9648 - val_loss: 0.1251 - val_accuracy: 0.9444\n",
            "Epoch 6/200\n",
            "9/9 [==============================] - 0s 3ms/step - loss: 0.0824 - accuracy: 0.9718 - val_loss: 0.1655 - val_accuracy: 0.9444\n",
            "Epoch 7/200\n",
            "9/9 [==============================] - 0s 4ms/step - loss: 0.0726 - accuracy: 0.9718 - val_loss: 0.0902 - val_accuracy: 0.9722\n",
            "Epoch 8/200\n",
            "9/9 [==============================] - 0s 3ms/step - loss: 0.1820 - accuracy: 0.9437 - val_loss: 0.0820 - val_accuracy: 0.9722\n",
            "Epoch 9/200\n",
            "9/9 [==============================] - 0s 3ms/step - loss: 0.1123 - accuracy: 0.9859 - val_loss: 0.2275 - val_accuracy: 0.9444\n",
            "Epoch 10/200\n",
            "9/9 [==============================] - 0s 3ms/step - loss: 0.0334 - accuracy: 0.9789 - val_loss: 0.2043 - val_accuracy: 0.9167\n",
            "Epoch 11/200\n",
            "9/9 [==============================] - 0s 3ms/step - loss: 0.0501 - accuracy: 0.9789 - val_loss: 0.2722 - val_accuracy: 0.9444\n",
            "Epoch 12/200\n",
            "9/9 [==============================] - 0s 4ms/step - loss: 0.0719 - accuracy: 0.9930 - val_loss: 0.7996 - val_accuracy: 0.8611\n",
            "Epoch 13/200\n",
            "9/9 [==============================] - 0s 3ms/step - loss: 0.2722 - accuracy: 0.9296 - val_loss: 0.1496 - val_accuracy: 0.9444\n",
            "Epoch 1/200\n",
            "9/9 [==============================] - 0s 15ms/step - loss: 1.4142 - accuracy: 0.3636 - val_loss: 1.0943 - val_accuracy: 0.2286\n",
            "Epoch 2/200\n",
            "9/9 [==============================] - 0s 3ms/step - loss: 0.8154 - accuracy: 0.5035 - val_loss: 0.5742 - val_accuracy: 0.7714\n",
            "Epoch 3/200\n",
            "9/9 [==============================] - 0s 3ms/step - loss: 0.5915 - accuracy: 0.7133 - val_loss: 0.2399 - val_accuracy: 0.9143\n",
            "Epoch 4/200\n",
            "9/9 [==============================] - 0s 4ms/step - loss: 0.3605 - accuracy: 0.8881 - val_loss: 0.9933 - val_accuracy: 0.8000\n",
            "Epoch 5/200\n",
            "9/9 [==============================] - 0s 4ms/step - loss: 0.5697 - accuracy: 0.8112 - val_loss: 0.1138 - val_accuracy: 0.9714\n",
            "Epoch 6/200\n",
            "9/9 [==============================] - 0s 3ms/step - loss: 0.1693 - accuracy: 0.9441 - val_loss: 0.1084 - val_accuracy: 0.9714\n",
            "Epoch 7/200\n",
            "9/9 [==============================] - 0s 3ms/step - loss: 0.0487 - accuracy: 0.9790 - val_loss: 0.2009 - val_accuracy: 0.9714\n",
            "Epoch 8/200\n",
            "9/9 [==============================] - 0s 3ms/step - loss: 0.1170 - accuracy: 0.9580 - val_loss: 0.3969 - val_accuracy: 0.9143\n",
            "Epoch 9/200\n",
            "9/9 [==============================] - 0s 3ms/step - loss: 0.1678 - accuracy: 0.9371 - val_loss: 0.0782 - val_accuracy: 0.9714\n",
            "Epoch 10/200\n",
            "9/9 [==============================] - 0s 3ms/step - loss: 0.1223 - accuracy: 0.9510 - val_loss: 0.0268 - val_accuracy: 1.0000\n",
            "Epoch 11/200\n",
            "9/9 [==============================] - 0s 3ms/step - loss: 0.1471 - accuracy: 0.9371 - val_loss: 0.1184 - val_accuracy: 0.9714\n",
            "Epoch 12/200\n",
            "9/9 [==============================] - 0s 3ms/step - loss: 0.0525 - accuracy: 0.9790 - val_loss: 0.0764 - val_accuracy: 0.9714\n",
            "Epoch 13/200\n",
            "9/9 [==============================] - 0s 4ms/step - loss: 0.0276 - accuracy: 0.9860 - val_loss: 0.2142 - val_accuracy: 0.9714\n",
            "Epoch 14/200\n",
            "9/9 [==============================] - 0s 4ms/step - loss: 0.0376 - accuracy: 0.9860 - val_loss: 0.0025 - val_accuracy: 1.0000\n",
            "Epoch 15/200\n",
            "9/9 [==============================] - 0s 3ms/step - loss: 0.1048 - accuracy: 0.9650 - val_loss: 0.3041 - val_accuracy: 0.9429\n",
            "Epoch 16/200\n",
            "9/9 [==============================] - 0s 3ms/step - loss: 0.0375 - accuracy: 0.9860 - val_loss: 0.0041 - val_accuracy: 1.0000\n",
            "Epoch 17/200\n",
            "9/9 [==============================] - 0s 3ms/step - loss: 0.0195 - accuracy: 0.9930 - val_loss: 0.1352 - val_accuracy: 0.9714\n",
            "Epoch 18/200\n",
            "9/9 [==============================] - 0s 3ms/step - loss: 0.0228 - accuracy: 0.9930 - val_loss: 0.0053 - val_accuracy: 1.0000\n",
            "Epoch 19/200\n",
            "9/9 [==============================] - 0s 3ms/step - loss: 0.0180 - accuracy: 0.9930 - val_loss: 0.1447 - val_accuracy: 0.9714\n",
            "Epoch 1/200\n",
            "9/9 [==============================] - 0s 16ms/step - loss: 2.1550 - accuracy: 0.3916 - val_loss: 1.0146 - val_accuracy: 0.6000\n",
            "Epoch 2/200\n",
            "9/9 [==============================] - 0s 4ms/step - loss: 0.8872 - accuracy: 0.5804 - val_loss: 0.6044 - val_accuracy: 0.6857\n",
            "Epoch 3/200\n",
            "9/9 [==============================] - 0s 4ms/step - loss: 0.6335 - accuracy: 0.6014 - val_loss: 0.5611 - val_accuracy: 0.6857\n",
            "Epoch 4/200\n",
            "9/9 [==============================] - 0s 3ms/step - loss: 0.6522 - accuracy: 0.6783 - val_loss: 0.6731 - val_accuracy: 0.5143\n",
            "Epoch 5/200\n",
            "9/9 [==============================] - 0s 4ms/step - loss: 0.4961 - accuracy: 0.7762 - val_loss: 0.5106 - val_accuracy: 0.8286\n",
            "Epoch 6/200\n",
            "9/9 [==============================] - 0s 4ms/step - loss: 0.3184 - accuracy: 0.8671 - val_loss: 0.3417 - val_accuracy: 0.8571\n",
            "Epoch 7/200\n",
            "9/9 [==============================] - 0s 4ms/step - loss: 0.1720 - accuracy: 0.9510 - val_loss: 0.1398 - val_accuracy: 0.9429\n",
            "Epoch 8/200\n",
            "9/9 [==============================] - 0s 4ms/step - loss: 0.1137 - accuracy: 0.9650 - val_loss: 0.2538 - val_accuracy: 0.9143\n",
            "Epoch 9/200\n",
            "9/9 [==============================] - 0s 3ms/step - loss: 0.0517 - accuracy: 0.9720 - val_loss: 0.4505 - val_accuracy: 0.9143\n",
            "Epoch 10/200\n",
            "9/9 [==============================] - 0s 4ms/step - loss: 0.0987 - accuracy: 0.9510 - val_loss: 0.0473 - val_accuracy: 0.9714\n",
            "Epoch 11/200\n",
            "9/9 [==============================] - 0s 4ms/step - loss: 0.0873 - accuracy: 0.9790 - val_loss: 0.2770 - val_accuracy: 0.9429\n",
            "Epoch 12/200\n",
            "9/9 [==============================] - 0s 5ms/step - loss: 0.2304 - accuracy: 0.9371 - val_loss: 0.5631 - val_accuracy: 0.8286\n",
            "Epoch 13/200\n",
            "9/9 [==============================] - 0s 4ms/step - loss: 0.1316 - accuracy: 0.9371 - val_loss: 0.1648 - val_accuracy: 0.9714\n",
            "Epoch 14/200\n",
            "9/9 [==============================] - 0s 4ms/step - loss: 0.0555 - accuracy: 0.9790 - val_loss: 0.2473 - val_accuracy: 0.9429\n",
            "Epoch 15/200\n",
            "9/9 [==============================] - 0s 4ms/step - loss: 0.1573 - accuracy: 0.9580 - val_loss: 0.4706 - val_accuracy: 0.8857\n",
            "WARNING:tensorflow:5 out of the last 9 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7f5744af2400> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iPob7bUl6JFY"
      },
      "source": [
        "# Q12: display confusion matrix and balanced accuracy here\n",
        "acc = balanced_accuracy_score(gt_and_pred[0], gt_and_pred[1])\n",
        "conf_mat = confusion_matrix(gt_and_pred[0], gt_and_pred[1], labels=[0, 1, 2])\n",
        "print(\"balanced_accuracy=\", acc)\n",
        "print(conf_mat)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "D_ui6Oev4shS"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}