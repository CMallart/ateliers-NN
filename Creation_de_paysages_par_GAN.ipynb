{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Creation de paysages par GAN.ipynb",
      "provenance": [],
      "authorship_tag": "ABX9TyOy0jdo116Hsk1l3KrivOIg",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/CMallart/ateliers-NN/blob/main/Creation_de_paysages_par_GAN.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "I5NQUDryIQXa"
      },
      "source": [
        "Data from :\n",
        "https://www.kaggle.com/arnaud58/landscape-pictures?select=00000001_%285%29.jpg"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "avHRdbesR0WZ"
      },
      "source": [
        "# Generative adversarial networks\n",
        "\n",
        "Les réseaux de neurones peu profonds sont somme toute des versions un peu compliquées de classifieurs statistiques, utilisés le plus souvent pour classifier des objets (phrases, images, audio, videos...) en plusieurs catégories.Il faut leur créer des variables(features) à la main et éspérer que cela leur parle.\n",
        "\n",
        "Mais les réseaux de neurones profonds, eux, permettent de faire quelque chose de beaucoup plus puissante : ils apprennent des représentations. Ils peuvent apprendre directement, sans création de features à la main, des représentations par matrices d'objets complexes, comme des images. Cela serait dommage de ne pas exploiter cela pour quelque chose de plus puissant, ou au moins de différent.\n",
        "\n",
        "Entrent en jeu les réseaux génératifs. Ces réseaux profitent du fait qu'on peut apprendre à un réseau à créer une représentation abstraite, vectorielle, d'un objet. \n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-JfCjGtIR0dz"
      },
      "source": [
        ""
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DiH3zpx6NFvP"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount(\"/content/drive\", force_remount=True)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yL4P2npHpdqI"
      },
      "source": [
        "! git clone https://github.com/CMallart/ateliers-NN.git"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Qho7VIRCqZxt"
      },
      "source": [
        "! ls"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eaIenWQ9J5QC"
      },
      "source": [
        "from matplotlib import pyplot as plt\n",
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator, array_to_img, img_to_array, load_img\n",
        "from numpy import expand_dims\n",
        "from numpy import zeros\n",
        "from numpy import ones\n",
        "from numpy import vstack\n",
        "from numpy.random import randn\n",
        "from numpy.random import randint\n",
        "import numpy as np\n",
        "from keras.optimizers import Adam\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Dense\n",
        "from keras.layers import Reshape\n",
        "from keras.layers import Flatten\n",
        "from keras.layers import Conv2D\n",
        "from keras.layers import Conv2DTranspose\n",
        "from keras.layers import LeakyReLU\n",
        "from keras.layers import Dropout\n",
        "from matplotlib import pyplot"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-j2fZwTmfN3z"
      },
      "source": [
        "# load a generator for visualisation first\n",
        "visual_generator = ImageDataGenerator(fill_mode=\"reflect\",\n",
        "                                     horizontal_flip=True)\n",
        "visual_flow = visual_generator.flow_from_directory(\"/content/ateliers-NN/data/landscapes\", class_mode=None, target_size=(256,256), batch_size=1, shuffle=False)\n",
        "\n",
        "\n",
        "images= []\n",
        "for i in range(0,4):\n",
        "  images.append(visual_flow.next()[0])\n",
        "\n",
        "print(images[0].shape, images[0])\n",
        "\n",
        "plt.figure(figsize=(10, 10))\n",
        "plt.subplot(221)\n",
        "plt.imshow((images[0]).astype('uint8'))\n",
        "\n",
        "plt.subplot(222)\n",
        "plt.imshow((images[1]).astype('uint8'))\n",
        "\n",
        "plt.subplot(223)\n",
        "plt.imshow((images[2]).astype('uint8'))\n",
        "\n",
        "plt.subplot(224)\n",
        "plt.imshow((images[3]).astype('uint8'))\n",
        "\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qtwwg_DTJarx"
      },
      "source": [
        "def define_discriminator(in_shape=(128,128,3)):\n",
        "\tmodel = Sequential()\n",
        "\t# normal\n",
        "\tmodel.add(Conv2D(64, (3,3), padding='same', input_shape=in_shape))\n",
        "\tmodel.add(LeakyReLU(alpha=0.2))\n",
        "\t# downsample\n",
        "\tmodel.add(Conv2D(128, (3,3), strides=(2,2), padding='same'))\n",
        "\tmodel.add(LeakyReLU(alpha=0.2))\n",
        "\t# downsample\n",
        "\tmodel.add(Conv2D(128, (3,3), strides=(2,2), padding='same'))\n",
        "\tmodel.add(LeakyReLU(alpha=0.2))\n",
        "\t# downsample\n",
        "\tmodel.add(Conv2D(256, (3,3), strides=(2,2), padding='same'))\n",
        "\tmodel.add(LeakyReLU(alpha=0.2))\n",
        "\t# classifier\n",
        "\tmodel.add(Flatten())\n",
        "\tmodel.add(Dropout(0.4))\n",
        "\tmodel.add(Dense(1, activation='sigmoid'))\n",
        "\t# compile model\n",
        "\topt = Adam(lr=0.0002, beta_1=0.5)\n",
        "\tmodel.compile(loss='binary_crossentropy', optimizer=opt, metrics=['accuracy'])\n",
        "\treturn model"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jyXhrHeYuPpe"
      },
      "source": [
        "def define_discriminator(in_shape=(128,128,3)):\n",
        "  model = Sequential()\n",
        "  model.add(Conv2D(32, kernel_size=3, strides=2, input_shape=in_shape, padding=\"same\"))\n",
        "  model.add(LeakyReLU(alpha=0.2))\n",
        "  model.add(Dropout(0.25))\n",
        "  model.add(Conv2D(64, kernel_size=3, strides=2, padding=\"same\"))\n",
        "  model.add(ZeroPadding2D(padding=((0,1),(0,1))))\n",
        "  model.add(BatchNormalization(momentum=0.8))\n",
        "  model.add(LeakyReLU(alpha=0.2))\n",
        "  model.add(Dropout(0.25))\n",
        "  model.add(Conv2D(128, kernel_size=3, strides=2, padding=\"same\"))\n",
        "  model.add(BatchNormalization(momentum=0.8))\n",
        "  model.add(LeakyReLU(alpha=0.2))\n",
        "  model.add(Dropout(0.25))\n",
        "  model.add(Conv2D(256, kernel_size=3, strides=1, padding=\"same\"))\n",
        "  model.add(BatchNormalization(momentum=0.8))\n",
        "  model.add(LeakyReLU(alpha=0.2))\n",
        "  model.add(Dropout(0.25))\n",
        "  model.add(Flatten())\n",
        "  model.add(Dense(1, activation='sigmoid'))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zPesDdwQJg6D"
      },
      "source": [
        "# define the standalone generator model\n",
        "def define_generator(latent_dim):\n",
        "\tmodel = Sequential()\n",
        "\t# foundation for 8x8 image\n",
        "\tn_nodes = 256 * 8 * 8\n",
        "\tmodel.add(Dense(n_nodes, input_dim=latent_dim))\n",
        "\tmodel.add(LeakyReLU(alpha=0.2))\n",
        "\tmodel.add(Reshape((8, 8, 256)))\n",
        "\t# upsample to 16x16\n",
        "\tmodel.add(Conv2DTranspose(128, (4,4), strides=(2,2), padding='same'))\n",
        "\tmodel.add(LeakyReLU(alpha=0.2))\n",
        "\t# upsample to 32x32\n",
        "\tmodel.add(Conv2DTranspose(128, (4,4), strides=(2,2), padding='same'))\n",
        "\tmodel.add(LeakyReLU(alpha=0.2))\n",
        "\t# upsample to 64x64\n",
        "\tmodel.add(Conv2DTranspose(128, (4,4), strides=(2,2), padding='same'))\n",
        "\tmodel.add(LeakyReLU(alpha=0.2))\n",
        " \t# upsample to 128x128\n",
        "\tmodel.add(Conv2DTranspose(128, (4,4), strides=(2,2), padding='same'))\n",
        "\tmodel.add(LeakyReLU(alpha=0.2))\n",
        "\t# output layer\n",
        "\tmodel.add(Conv2D(3, (3,3), activation='tanh', padding='same'))\n",
        "\treturn model"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ESkEO1QPukQX"
      },
      "source": [
        "def build_generator(self):\n",
        "\n",
        "    model = Sequential()\n",
        "\n",
        "    model.add(Dense(128 * 7 * 7, activation=\"relu\", input_dim=self.latent_dim))\n",
        "    model.add(Reshape((7, 7, 128)))\n",
        "    model.add(UpSampling2D())\n",
        "    model.add(Conv2D(128, kernel_size=3, padding=\"same\"))\n",
        "    model.add(BatchNormalization(momentum=0.8))\n",
        "    model.add(Activation(\"relu\"))\n",
        "    model.add(UpSampling2D())\n",
        "    model.add(Conv2D(64, kernel_size=3, padding=\"same\"))\n",
        "    model.add(BatchNormalization(momentum=0.8))\n",
        "    model.add(Activation(\"relu\"))\n",
        "    model.add(Conv2D(self.channels, kernel_size=3, padding=\"same\"))\n",
        "    model.add(Activation(\"tanh\"))\n",
        "\n",
        "    model.summary()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cwqfxBvxJq0g"
      },
      "source": [
        "# define the combined generator and discriminator model, for updating the generator\n",
        "def define_gan(g_model, d_model):\n",
        "\t# make weights in the discriminator not trainable\n",
        "\td_model.trainable = False\n",
        "\t# connect them\n",
        "\tmodel = Sequential()\n",
        "\t# add generator\n",
        "\tmodel.add(g_model)\n",
        "\t# add the discriminator\n",
        "\tmodel.add(d_model)\n",
        "\t# compile model\n",
        "\topt = Adam(lr=0.0002, beta_1=0.5)\n",
        "\tmodel.compile(loss='binary_crossentropy', optimizer=opt)\n",
        "\treturn model"
      ],
      "execution_count": 70,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jbCESQ_eKRwF"
      },
      "source": [
        "# to train the discriminator, we need a mix of real and fake images\n",
        "\n",
        "def generate_real_samples(dataset, n_samples):\n",
        "\t# choose random instances\n",
        "\tix = randint(0, dataset.shape[0], n_samples)\n",
        "\t# retrieve selected images\n",
        "\tX = dataset[ix]\n",
        "\t# generate 'real' class labels (1)\n",
        "\ty = ones((n_samples, 1))\n",
        "\treturn X, y\n",
        "\n",
        "# use the generator to generate n fake examples, with class labels 0\n",
        "def generate_fake_samples(g_model, latent_dim, n_samples):\n",
        "\t# generate points in latent space\n",
        "\tx_input = generate_latent_points(latent_dim, n_samples)\n",
        "\t# predict outputs\n",
        "\tX = g_model.predict(x_input)\n",
        "\t# create 'fake' class labels (0)\n",
        "\ty = zeros((n_samples, 1))\n",
        "\treturn X, y\n",
        "\n",
        "\n",
        "# generate points in latent space as input for the generator\n",
        "def generate_latent_points(latent_dim, n_samples):\n",
        "\t# generate points in the latent space\n",
        "\tx_input = randn(latent_dim * n_samples)\n",
        "\t# reshape into a batch of inputs for the network\n",
        "\tx_input = x_input.reshape(n_samples, latent_dim)\n",
        "\treturn x_input"
      ],
      "execution_count": 77,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KI-M5TAKLphg"
      },
      "source": [
        "When training the generator via this logical GAN model, there is one more important change. We want the discriminator to think that the samples output by the generator are real, not fake. Therefore, when the generator is trained as part of the GAN model, we will mark the generated samples as real (class 1).\n",
        "\n",
        "Why would we want to do this?\n",
        "\n",
        "We can imagine that the discriminator will then classify the generated samples as not real (class 0) or a low probability of being real (0.3 or 0.5). The backpropagation process used to update the model weights will see this as a large error and will update the model weights (i.e. only the weights in the generator) to correct for this error, in turn making the generator better at generating good fake samples.\n",
        "\n",
        "Let’s make this concrete.\n",
        "\n",
        "Inputs: Point in latent space, e.g. a 100-element vector of Gaussian random numbers.\n",
        "Outputs: Binary classification, likelihood the sample is real (or fake).\n",
        "The define_gan() function below takes as arguments the already-defined generator and discriminator models and creates the new, logical third model subsuming these two models. The weights in the discriminator are marked as not trainable, which only affects the weights as seen by the GAN model and not the standalone discriminator model.\n",
        "\n",
        "The GAN model then uses the same binary cross entropy loss function as the discriminator and the efficient Adam version of stochastic gradient descent with the learning rate of 0.0002 and momentum of 0.5, recommended when training deep convolutional GANs."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-9YtHd9eLDYt"
      },
      "source": [
        "from google.colab import files\n",
        "import os\n",
        "\n",
        "folder_saves = \"/content/drive/My Drive/Colab_Notebooks/plots_gan/\"\n",
        "if not os.path.exists(folder_saves):\n",
        "    os.makedirs(folder_saves)\n",
        "\n",
        "# create and save a plot of generated images\n",
        "def save_plot(examples, epoch, n=7):\n",
        "\t# scale from [-1,1] to [0,1]\n",
        "\texamples = (examples + 1) / 2.0\n",
        "\tplt.figure(figsize=(40, 40))\n",
        "\t# plot images\n",
        "\tfor i in range(n * n):\n",
        "\t\t# define subplot\n",
        "\t\tplt.subplot(n, n, 1 + i)\n",
        "\t\t# turn off axis\n",
        "\t\tplt.axis('off')\n",
        "\t\t# plot raw pixel data\n",
        "\t\tplt.imshow(examples[i])\n",
        "\t# save plot to file\n",
        "\tfilename = folder_saves+'generated_plot_e%03d.png' % (epoch+1)\n",
        "\tplt.savefig(filename)\n",
        "\tfiles.download(filename) \n",
        "\n",
        "# evaluate the discriminator, plot generated images, save generator model\n",
        "def summarize_performance(epoch, g_model, d_model, dataset, latent_dim, n_samples=150):\n",
        "\t# prepare real samples\n",
        "\tX_real, y_real = generate_real_samples(dataset, n_samples)\n",
        "\t# evaluate discriminator on real examples\n",
        "\t_, acc_real = d_model.evaluate(X_real, y_real, verbose=0)\n",
        "\t# prepare fake examples\n",
        "\tx_fake, y_fake = generate_fake_samples(g_model, latent_dim, n_samples)\n",
        "\t# evaluate discriminator on fake examples\n",
        "\t_, acc_fake = d_model.evaluate(x_fake, y_fake, verbose=0)\n",
        "\t# summarize discriminator performance\n",
        "\tprint('>Accuracy real: %.0f%%, fake: %.0f%%' % (acc_real*100, acc_fake*100))\n",
        "\t# save plot\n",
        "\tsave_plot(x_fake, epoch)\n",
        "\t# save the generator model tile file\n",
        "\tfilename = folder_saves+'generator_model_%03d.h5' % (epoch+1)\n",
        "\tg_model.save(filename)\n",
        "\tfiles.download(filename)"
      ],
      "execution_count": 97,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xf8NDPs2NYCX"
      },
      "source": [
        "# train the generator and discriminator\n",
        "def train(g_model, d_model, gan_model, dataset, latent_dim, n_epochs=30, n_batch=128):\n",
        "\tbat_per_epo = int(4335 / n_batch)\n",
        "\thalf_batch = int(n_batch / 2)\n",
        "\t# manually enumerate epochs\n",
        "\tfor i in range(n_epochs):\n",
        "\t\t# enumerate batches over the training set\n",
        "\t\tfor j in range(bat_per_epo):\n",
        "\t\t\t# get randomly selected 'real' samples\n",
        "\t\t\tX_real, y_real = generate_real_samples(dataset, half_batch)\n",
        "\t\t\t# update discriminator model weights\n",
        "\t\t\td_loss1, _ = d_model.train_on_batch(X_real, y_real)\n",
        "\t\t\t# generate 'fake' examples\n",
        "\t\t\tX_fake, y_fake = generate_fake_samples(g_model, latent_dim, half_batch)\n",
        "\t\t\t# update discriminator model weights\n",
        "\t\t\td_loss2, _ = d_model.train_on_batch(X_fake, y_fake)\n",
        "\t\t\t# prepare points in latent space as input for the generator\n",
        "\t\t\tX_gan = generate_latent_points(latent_dim, n_batch)\n",
        "\t\t\t# create inverted labels for the fake samples\n",
        "\t\t\ty_gan = ones((n_batch, 1))\n",
        "\t\t\t# update the generator via the discriminator's error\n",
        "\t\t\tg_loss = gan_model.train_on_batch(X_gan, y_gan)\n",
        "\t\t\t# summarize loss on this batch\n",
        "\t\t\tprint('>Epoch :%d, Batch : %d/%d, discrim_real_loss=%.3f, discrim_fake_loss=%.3f gan_loss=%.3f' %\n",
        "\t\t\t\t(i+1, j+1, bat_per_epo, d_loss1, d_loss2, g_loss))\n",
        "\t\t# evaluate the model performance, sometimes\n",
        "\t\tif (i+1) % 10 == 0:\n",
        "\t\t\tsummarize_performance(i, g_model, d_model, dataset, latent_dim, n_samples=256)"
      ],
      "execution_count": 91,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cqmYkD6tN-8k",
        "outputId": "75b3682f-67c2-4656-87f1-a6cfb139c090",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "train_generator = ImageDataGenerator(rescale=1/255,fill_mode=\"reflect\")\n",
        "train_flow = train_generator.flow_from_directory(\"/content/ateliers-NN/data/landscapes\", class_mode=None, target_size=(128,128), batch_size=4319)"
      ],
      "execution_count": 41,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Found 4319 images belonging to 1 classes.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9QjLoeC7RbJz",
        "outputId": "0926de31-23fb-407a-b517-85e63d7d8d9b",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "dataset_train = []\n",
        "print(\"Starting\")\n",
        "temp_data = train_flow.next()\n",
        "for i in range(temp_data.shape[0]):\n",
        "  dataset_train.append(temp_data[i])\n",
        "print(\"Done\")"
      ],
      "execution_count": 42,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Starting\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "u2ejJmrnuAh8"
      },
      "source": [
        "dataset = np.array(dataset_train)"
      ],
      "execution_count": 51,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "K7sIMl8cOBVr"
      },
      "source": [
        "# size of the latent space\n",
        "latent_dim = 100\n",
        "# create the discriminator\n",
        "d_model = define_discriminator()\n",
        "# create the generator\n",
        "g_model = define_generator(latent_dim)\n",
        "# create the gan\n",
        "gan_model = define_gan(g_model, d_model)"
      ],
      "execution_count": 92,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "p-UzmWLWvExG",
        "outputId": "9874ae14-5f4c-4450-a300-08a07a6b6064",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "d_model.summary()"
      ],
      "execution_count": 93,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"sequential_21\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "conv2d_35 (Conv2D)           (None, 128, 128, 64)      1792      \n",
            "_________________________________________________________________\n",
            "leaky_re_lu_69 (LeakyReLU)   (None, 128, 128, 64)      0         \n",
            "_________________________________________________________________\n",
            "conv2d_36 (Conv2D)           (None, 64, 64, 128)       73856     \n",
            "_________________________________________________________________\n",
            "leaky_re_lu_70 (LeakyReLU)   (None, 64, 64, 128)       0         \n",
            "_________________________________________________________________\n",
            "conv2d_37 (Conv2D)           (None, 32, 32, 128)       147584    \n",
            "_________________________________________________________________\n",
            "leaky_re_lu_71 (LeakyReLU)   (None, 32, 32, 128)       0         \n",
            "_________________________________________________________________\n",
            "conv2d_38 (Conv2D)           (None, 16, 16, 256)       295168    \n",
            "_________________________________________________________________\n",
            "leaky_re_lu_72 (LeakyReLU)   (None, 16, 16, 256)       0         \n",
            "_________________________________________________________________\n",
            "flatten_7 (Flatten)          (None, 65536)             0         \n",
            "_________________________________________________________________\n",
            "dropout_7 (Dropout)          (None, 65536)             0         \n",
            "_________________________________________________________________\n",
            "dense_14 (Dense)             (None, 1)                 65537     \n",
            "=================================================================\n",
            "Total params: 583,937\n",
            "Trainable params: 0\n",
            "Non-trainable params: 583,937\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aJPEfAnRvHly",
        "outputId": "fc340c75-d076-424c-e892-d0c3e831b930",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "g_model.summary()"
      ],
      "execution_count": 94,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"sequential_22\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "dense_15 (Dense)             (None, 16384)             1654784   \n",
            "_________________________________________________________________\n",
            "leaky_re_lu_73 (LeakyReLU)   (None, 16384)             0         \n",
            "_________________________________________________________________\n",
            "reshape_7 (Reshape)          (None, 8, 8, 256)         0         \n",
            "_________________________________________________________________\n",
            "conv2d_transpose_34 (Conv2DT (None, 16, 16, 128)       524416    \n",
            "_________________________________________________________________\n",
            "leaky_re_lu_74 (LeakyReLU)   (None, 16, 16, 128)       0         \n",
            "_________________________________________________________________\n",
            "conv2d_transpose_35 (Conv2DT (None, 32, 32, 128)       262272    \n",
            "_________________________________________________________________\n",
            "leaky_re_lu_75 (LeakyReLU)   (None, 32, 32, 128)       0         \n",
            "_________________________________________________________________\n",
            "conv2d_transpose_36 (Conv2DT (None, 64, 64, 128)       262272    \n",
            "_________________________________________________________________\n",
            "leaky_re_lu_76 (LeakyReLU)   (None, 64, 64, 128)       0         \n",
            "_________________________________________________________________\n",
            "conv2d_transpose_37 (Conv2DT (None, 128, 128, 128)     262272    \n",
            "_________________________________________________________________\n",
            "leaky_re_lu_77 (LeakyReLU)   (None, 128, 128, 128)     0         \n",
            "_________________________________________________________________\n",
            "conv2d_39 (Conv2D)           (None, 128, 128, 3)       3459      \n",
            "=================================================================\n",
            "Total params: 2,969,475\n",
            "Trainable params: 2,969,475\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2AmbMFcjvJvq",
        "outputId": "8bf8745f-5dd7-4ca1-c26c-b4343812d63e",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "gan_model.summary()"
      ],
      "execution_count": 95,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"sequential_23\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "sequential_22 (Sequential)   (None, 128, 128, 3)       2969475   \n",
            "_________________________________________________________________\n",
            "sequential_21 (Sequential)   (None, 1)                 583937    \n",
            "=================================================================\n",
            "Total params: 3,553,412\n",
            "Trainable params: 2,969,475\n",
            "Non-trainable params: 583,937\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "68GWZ_uZvCfa",
        "outputId": "1535c94c-7fb9-4ae2-cd5d-cb0d50143ddd",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "# train model\n",
        "train(g_model, d_model, gan_model, dataset, latent_dim, n_epochs=100, n_batch = 256)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            ">Epoch :1, Batch : 1/16, discrim_real_loss=0.566, discrim_fake_loss=0.561 gan_loss=1.160\n",
            ">Epoch :1, Batch : 2/16, discrim_real_loss=0.471, discrim_fake_loss=0.537 gan_loss=1.262\n",
            ">Epoch :1, Batch : 3/16, discrim_real_loss=0.456, discrim_fake_loss=0.478 gan_loss=1.344\n",
            ">Epoch :1, Batch : 4/16, discrim_real_loss=0.434, discrim_fake_loss=0.461 gan_loss=1.429\n",
            ">Epoch :1, Batch : 5/16, discrim_real_loss=0.401, discrim_fake_loss=0.527 gan_loss=1.648\n",
            ">Epoch :1, Batch : 6/16, discrim_real_loss=0.365, discrim_fake_loss=0.423 gan_loss=1.747\n",
            ">Epoch :1, Batch : 7/16, discrim_real_loss=0.330, discrim_fake_loss=0.611 gan_loss=1.786\n",
            ">Epoch :1, Batch : 8/16, discrim_real_loss=0.633, discrim_fake_loss=1.267 gan_loss=1.672\n",
            ">Epoch :1, Batch : 9/16, discrim_real_loss=1.006, discrim_fake_loss=0.776 gan_loss=1.481\n",
            ">Epoch :1, Batch : 10/16, discrim_real_loss=0.978, discrim_fake_loss=0.611 gan_loss=1.431\n",
            ">Epoch :1, Batch : 11/16, discrim_real_loss=0.914, discrim_fake_loss=0.469 gan_loss=1.464\n",
            ">Epoch :1, Batch : 12/16, discrim_real_loss=0.777, discrim_fake_loss=0.420 gan_loss=1.584\n",
            ">Epoch :1, Batch : 13/16, discrim_real_loss=0.635, discrim_fake_loss=0.468 gan_loss=1.581\n",
            ">Epoch :1, Batch : 14/16, discrim_real_loss=0.483, discrim_fake_loss=0.672 gan_loss=1.627\n",
            ">Epoch :1, Batch : 15/16, discrim_real_loss=0.612, discrim_fake_loss=0.768 gan_loss=1.607\n",
            ">Epoch :1, Batch : 16/16, discrim_real_loss=0.676, discrim_fake_loss=1.426 gan_loss=2.241\n",
            ">Epoch :2, Batch : 1/16, discrim_real_loss=0.881, discrim_fake_loss=0.474 gan_loss=3.847\n",
            ">Epoch :2, Batch : 2/16, discrim_real_loss=0.392, discrim_fake_loss=0.963 gan_loss=3.254\n",
            ">Epoch :2, Batch : 3/16, discrim_real_loss=1.397, discrim_fake_loss=0.436 gan_loss=1.298\n",
            ">Epoch :2, Batch : 4/16, discrim_real_loss=0.672, discrim_fake_loss=0.836 gan_loss=1.244\n",
            ">Epoch :2, Batch : 5/16, discrim_real_loss=0.557, discrim_fake_loss=0.567 gan_loss=1.366\n",
            ">Epoch :2, Batch : 6/16, discrim_real_loss=0.546, discrim_fake_loss=0.762 gan_loss=1.509\n",
            ">Epoch :2, Batch : 7/16, discrim_real_loss=0.702, discrim_fake_loss=0.697 gan_loss=1.279\n",
            ">Epoch :2, Batch : 8/16, discrim_real_loss=0.774, discrim_fake_loss=0.910 gan_loss=1.042\n",
            ">Epoch :2, Batch : 9/16, discrim_real_loss=0.731, discrim_fake_loss=0.719 gan_loss=1.002\n",
            ">Epoch :2, Batch : 10/16, discrim_real_loss=0.768, discrim_fake_loss=0.582 gan_loss=1.025\n",
            ">Epoch :2, Batch : 11/16, discrim_real_loss=0.702, discrim_fake_loss=0.575 gan_loss=1.032\n",
            ">Epoch :2, Batch : 12/16, discrim_real_loss=0.632, discrim_fake_loss=0.548 gan_loss=1.097\n",
            ">Epoch :2, Batch : 13/16, discrim_real_loss=0.592, discrim_fake_loss=0.532 gan_loss=1.127\n",
            ">Epoch :2, Batch : 14/16, discrim_real_loss=0.574, discrim_fake_loss=0.567 gan_loss=1.109\n",
            ">Epoch :2, Batch : 15/16, discrim_real_loss=0.545, discrim_fake_loss=0.620 gan_loss=1.088\n",
            ">Epoch :2, Batch : 16/16, discrim_real_loss=0.512, discrim_fake_loss=0.665 gan_loss=0.974\n",
            ">Epoch :3, Batch : 1/16, discrim_real_loss=0.591, discrim_fake_loss=0.770 gan_loss=0.895\n",
            ">Epoch :3, Batch : 2/16, discrim_real_loss=0.528, discrim_fake_loss=0.796 gan_loss=0.904\n",
            ">Epoch :3, Batch : 3/16, discrim_real_loss=0.637, discrim_fake_loss=0.844 gan_loss=0.896\n",
            ">Epoch :3, Batch : 4/16, discrim_real_loss=0.675, discrim_fake_loss=0.685 gan_loss=0.941\n",
            ">Epoch :3, Batch : 5/16, discrim_real_loss=0.672, discrim_fake_loss=0.682 gan_loss=1.015\n",
            ">Epoch :3, Batch : 6/16, discrim_real_loss=0.621, discrim_fake_loss=0.633 gan_loss=1.147\n",
            ">Epoch :3, Batch : 7/16, discrim_real_loss=0.569, discrim_fake_loss=0.520 gan_loss=1.233\n",
            ">Epoch :3, Batch : 8/16, discrim_real_loss=0.645, discrim_fake_loss=0.557 gan_loss=1.262\n",
            ">Epoch :3, Batch : 9/16, discrim_real_loss=0.617, discrim_fake_loss=0.596 gan_loss=1.262\n",
            ">Epoch :3, Batch : 10/16, discrim_real_loss=0.689, discrim_fake_loss=0.578 gan_loss=1.180\n",
            ">Epoch :3, Batch : 11/16, discrim_real_loss=0.656, discrim_fake_loss=0.635 gan_loss=1.158\n",
            ">Epoch :3, Batch : 12/16, discrim_real_loss=0.741, discrim_fake_loss=0.656 gan_loss=1.144\n",
            ">Epoch :3, Batch : 13/16, discrim_real_loss=0.765, discrim_fake_loss=0.606 gan_loss=1.164\n",
            ">Epoch :3, Batch : 14/16, discrim_real_loss=0.734, discrim_fake_loss=0.587 gan_loss=1.179\n",
            ">Epoch :3, Batch : 15/16, discrim_real_loss=0.749, discrim_fake_loss=0.534 gan_loss=1.176\n",
            ">Epoch :3, Batch : 16/16, discrim_real_loss=0.707, discrim_fake_loss=0.543 gan_loss=1.105\n",
            ">Epoch :4, Batch : 1/16, discrim_real_loss=0.650, discrim_fake_loss=0.560 gan_loss=1.089\n",
            ">Epoch :4, Batch : 2/16, discrim_real_loss=0.665, discrim_fake_loss=0.543 gan_loss=1.072\n",
            ">Epoch :4, Batch : 3/16, discrim_real_loss=0.612, discrim_fake_loss=0.562 gan_loss=1.097\n",
            ">Epoch :4, Batch : 4/16, discrim_real_loss=0.609, discrim_fake_loss=0.520 gan_loss=1.117\n",
            ">Epoch :4, Batch : 5/16, discrim_real_loss=0.591, discrim_fake_loss=0.531 gan_loss=1.127\n",
            ">Epoch :4, Batch : 6/16, discrim_real_loss=0.577, discrim_fake_loss=0.527 gan_loss=1.130\n",
            ">Epoch :4, Batch : 7/16, discrim_real_loss=0.627, discrim_fake_loss=0.551 gan_loss=1.105\n",
            ">Epoch :4, Batch : 8/16, discrim_real_loss=0.588, discrim_fake_loss=0.593 gan_loss=1.108\n",
            ">Epoch :4, Batch : 9/16, discrim_real_loss=0.632, discrim_fake_loss=0.576 gan_loss=1.055\n",
            ">Epoch :4, Batch : 10/16, discrim_real_loss=0.595, discrim_fake_loss=0.634 gan_loss=1.048\n",
            ">Epoch :4, Batch : 11/16, discrim_real_loss=0.718, discrim_fake_loss=0.661 gan_loss=1.027\n",
            ">Epoch :4, Batch : 12/16, discrim_real_loss=0.663, discrim_fake_loss=0.698 gan_loss=1.057\n",
            ">Epoch :4, Batch : 13/16, discrim_real_loss=0.741, discrim_fake_loss=0.672 gan_loss=1.103\n",
            ">Epoch :4, Batch : 14/16, discrim_real_loss=0.769, discrim_fake_loss=0.612 gan_loss=1.177\n",
            ">Epoch :4, Batch : 15/16, discrim_real_loss=0.733, discrim_fake_loss=0.508 gan_loss=1.224\n",
            ">Epoch :4, Batch : 16/16, discrim_real_loss=0.830, discrim_fake_loss=0.547 gan_loss=1.224\n",
            ">Epoch :5, Batch : 1/16, discrim_real_loss=0.800, discrim_fake_loss=0.575 gan_loss=1.168\n",
            ">Epoch :5, Batch : 2/16, discrim_real_loss=0.758, discrim_fake_loss=0.591 gan_loss=1.121\n",
            ">Epoch :5, Batch : 3/16, discrim_real_loss=0.706, discrim_fake_loss=0.593 gan_loss=1.075\n",
            ">Epoch :5, Batch : 4/16, discrim_real_loss=0.773, discrim_fake_loss=0.616 gan_loss=1.062\n",
            ">Epoch :5, Batch : 5/16, discrim_real_loss=0.744, discrim_fake_loss=0.585 gan_loss=1.087\n",
            ">Epoch :5, Batch : 6/16, discrim_real_loss=0.759, discrim_fake_loss=0.598 gan_loss=1.025\n",
            ">Epoch :5, Batch : 7/16, discrim_real_loss=0.726, discrim_fake_loss=0.593 gan_loss=1.015\n",
            ">Epoch :5, Batch : 8/16, discrim_real_loss=0.678, discrim_fake_loss=0.600 gan_loss=1.035\n",
            ">Epoch :5, Batch : 9/16, discrim_real_loss=0.627, discrim_fake_loss=0.585 gan_loss=1.060\n",
            ">Epoch :5, Batch : 10/16, discrim_real_loss=0.601, discrim_fake_loss=0.567 gan_loss=1.075\n",
            ">Epoch :5, Batch : 11/16, discrim_real_loss=0.584, discrim_fake_loss=0.549 gan_loss=1.058\n",
            ">Epoch :5, Batch : 12/16, discrim_real_loss=0.587, discrim_fake_loss=0.627 gan_loss=1.028\n",
            ">Epoch :5, Batch : 13/16, discrim_real_loss=0.532, discrim_fake_loss=0.596 gan_loss=1.016\n",
            ">Epoch :5, Batch : 14/16, discrim_real_loss=0.529, discrim_fake_loss=0.618 gan_loss=0.996\n",
            ">Epoch :5, Batch : 15/16, discrim_real_loss=0.500, discrim_fake_loss=0.669 gan_loss=1.003\n",
            ">Epoch :5, Batch : 16/16, discrim_real_loss=0.516, discrim_fake_loss=0.690 gan_loss=0.957\n",
            ">Epoch :6, Batch : 1/16, discrim_real_loss=0.597, discrim_fake_loss=0.701 gan_loss=0.997\n",
            ">Epoch :6, Batch : 2/16, discrim_real_loss=0.693, discrim_fake_loss=0.674 gan_loss=1.015\n",
            ">Epoch :6, Batch : 3/16, discrim_real_loss=0.661, discrim_fake_loss=0.646 gan_loss=1.041\n",
            ">Epoch :6, Batch : 4/16, discrim_real_loss=0.579, discrim_fake_loss=0.578 gan_loss=1.161\n",
            ">Epoch :6, Batch : 5/16, discrim_real_loss=0.571, discrim_fake_loss=0.475 gan_loss=1.300\n",
            ">Epoch :6, Batch : 6/16, discrim_real_loss=0.541, discrim_fake_loss=0.422 gan_loss=1.324\n",
            ">Epoch :6, Batch : 7/16, discrim_real_loss=0.496, discrim_fake_loss=0.455 gan_loss=1.275\n",
            ">Epoch :6, Batch : 8/16, discrim_real_loss=0.490, discrim_fake_loss=0.553 gan_loss=1.168\n",
            ">Epoch :6, Batch : 9/16, discrim_real_loss=0.463, discrim_fake_loss=0.608 gan_loss=1.106\n",
            ">Epoch :6, Batch : 10/16, discrim_real_loss=0.469, discrim_fake_loss=0.692 gan_loss=1.198\n",
            ">Epoch :6, Batch : 11/16, discrim_real_loss=0.571, discrim_fake_loss=0.624 gan_loss=1.251\n",
            ">Epoch :6, Batch : 12/16, discrim_real_loss=0.747, discrim_fake_loss=0.668 gan_loss=1.345\n",
            ">Epoch :6, Batch : 13/16, discrim_real_loss=0.768, discrim_fake_loss=0.453 gan_loss=1.459\n",
            ">Epoch :6, Batch : 14/16, discrim_real_loss=0.711, discrim_fake_loss=0.452 gan_loss=1.433\n",
            ">Epoch :6, Batch : 15/16, discrim_real_loss=0.610, discrim_fake_loss=0.471 gan_loss=1.389\n",
            ">Epoch :6, Batch : 16/16, discrim_real_loss=0.535, discrim_fake_loss=0.498 gan_loss=1.324\n",
            ">Epoch :7, Batch : 1/16, discrim_real_loss=0.535, discrim_fake_loss=0.550 gan_loss=1.208\n",
            ">Epoch :7, Batch : 2/16, discrim_real_loss=0.416, discrim_fake_loss=0.543 gan_loss=1.224\n",
            ">Epoch :7, Batch : 3/16, discrim_real_loss=0.491, discrim_fake_loss=0.651 gan_loss=1.262\n",
            ">Epoch :7, Batch : 4/16, discrim_real_loss=0.478, discrim_fake_loss=0.520 gan_loss=1.255\n",
            ">Epoch :7, Batch : 5/16, discrim_real_loss=0.564, discrim_fake_loss=0.636 gan_loss=1.216\n",
            ">Epoch :7, Batch : 6/16, discrim_real_loss=0.603, discrim_fake_loss=0.609 gan_loss=1.233\n",
            ">Epoch :7, Batch : 7/16, discrim_real_loss=0.652, discrim_fake_loss=0.600 gan_loss=1.185\n",
            ">Epoch :7, Batch : 8/16, discrim_real_loss=0.589, discrim_fake_loss=0.632 gan_loss=1.196\n",
            ">Epoch :7, Batch : 9/16, discrim_real_loss=0.549, discrim_fake_loss=0.585 gan_loss=1.226\n",
            ">Epoch :7, Batch : 10/16, discrim_real_loss=0.571, discrim_fake_loss=0.617 gan_loss=1.310\n",
            ">Epoch :7, Batch : 11/16, discrim_real_loss=0.636, discrim_fake_loss=0.542 gan_loss=1.267\n",
            ">Epoch :7, Batch : 12/16, discrim_real_loss=0.685, discrim_fake_loss=0.587 gan_loss=1.238\n",
            ">Epoch :7, Batch : 13/16, discrim_real_loss=0.601, discrim_fake_loss=0.573 gan_loss=1.231\n",
            ">Epoch :7, Batch : 14/16, discrim_real_loss=0.557, discrim_fake_loss=0.555 gan_loss=1.231\n",
            ">Epoch :7, Batch : 15/16, discrim_real_loss=0.614, discrim_fake_loss=0.591 gan_loss=1.252\n",
            ">Epoch :7, Batch : 16/16, discrim_real_loss=0.645, discrim_fake_loss=0.533 gan_loss=1.265\n",
            ">Epoch :8, Batch : 1/16, discrim_real_loss=0.612, discrim_fake_loss=0.545 gan_loss=1.258\n",
            ">Epoch :8, Batch : 2/16, discrim_real_loss=0.639, discrim_fake_loss=0.507 gan_loss=1.208\n",
            ">Epoch :8, Batch : 3/16, discrim_real_loss=0.582, discrim_fake_loss=0.591 gan_loss=1.171\n",
            ">Epoch :8, Batch : 4/16, discrim_real_loss=0.561, discrim_fake_loss=0.585 gan_loss=1.196\n",
            ">Epoch :8, Batch : 5/16, discrim_real_loss=0.601, discrim_fake_loss=0.586 gan_loss=1.156\n",
            ">Epoch :8, Batch : 6/16, discrim_real_loss=0.627, discrim_fake_loss=0.697 gan_loss=1.193\n",
            ">Epoch :8, Batch : 7/16, discrim_real_loss=0.647, discrim_fake_loss=0.714 gan_loss=1.209\n",
            ">Epoch :8, Batch : 8/16, discrim_real_loss=0.683, discrim_fake_loss=0.696 gan_loss=1.233\n",
            ">Epoch :8, Batch : 9/16, discrim_real_loss=0.778, discrim_fake_loss=0.673 gan_loss=1.315\n",
            ">Epoch :8, Batch : 10/16, discrim_real_loss=0.776, discrim_fake_loss=0.606 gan_loss=1.355\n",
            ">Epoch :8, Batch : 11/16, discrim_real_loss=0.697, discrim_fake_loss=0.526 gan_loss=1.326\n",
            ">Epoch :8, Batch : 12/16, discrim_real_loss=0.614, discrim_fake_loss=0.574 gan_loss=1.268\n",
            ">Epoch :8, Batch : 13/16, discrim_real_loss=0.564, discrim_fake_loss=0.620 gan_loss=1.201\n",
            ">Epoch :8, Batch : 14/16, discrim_real_loss=0.671, discrim_fake_loss=0.689 gan_loss=1.076\n",
            ">Epoch :8, Batch : 15/16, discrim_real_loss=0.546, discrim_fake_loss=0.748 gan_loss=1.031\n",
            ">Epoch :8, Batch : 16/16, discrim_real_loss=0.651, discrim_fake_loss=0.757 gan_loss=0.987\n",
            ">Epoch :9, Batch : 1/16, discrim_real_loss=0.649, discrim_fake_loss=0.755 gan_loss=0.997\n",
            ">Epoch :9, Batch : 2/16, discrim_real_loss=0.751, discrim_fake_loss=0.685 gan_loss=0.944\n",
            ">Epoch :9, Batch : 3/16, discrim_real_loss=0.664, discrim_fake_loss=0.676 gan_loss=0.981\n",
            ">Epoch :9, Batch : 4/16, discrim_real_loss=0.654, discrim_fake_loss=0.633 gan_loss=1.024\n",
            ">Epoch :9, Batch : 5/16, discrim_real_loss=0.572, discrim_fake_loss=0.560 gan_loss=1.074\n",
            ">Epoch :9, Batch : 6/16, discrim_real_loss=0.524, discrim_fake_loss=0.624 gan_loss=1.135\n",
            ">Epoch :9, Batch : 7/16, discrim_real_loss=0.540, discrim_fake_loss=0.597 gan_loss=1.258\n",
            ">Epoch :9, Batch : 8/16, discrim_real_loss=0.471, discrim_fake_loss=0.591 gan_loss=1.378\n",
            ">Epoch :9, Batch : 9/16, discrim_real_loss=0.634, discrim_fake_loss=0.614 gan_loss=1.432\n",
            ">Epoch :9, Batch : 10/16, discrim_real_loss=0.664, discrim_fake_loss=0.763 gan_loss=1.383\n",
            ">Epoch :9, Batch : 11/16, discrim_real_loss=0.770, discrim_fake_loss=0.640 gan_loss=1.361\n",
            ">Epoch :9, Batch : 12/16, discrim_real_loss=0.910, discrim_fake_loss=0.596 gan_loss=1.222\n",
            ">Epoch :9, Batch : 13/16, discrim_real_loss=0.831, discrim_fake_loss=0.722 gan_loss=1.190\n",
            ">Epoch :9, Batch : 14/16, discrim_real_loss=0.797, discrim_fake_loss=0.621 gan_loss=1.179\n",
            ">Epoch :9, Batch : 15/16, discrim_real_loss=0.817, discrim_fake_loss=0.706 gan_loss=1.210\n",
            ">Epoch :9, Batch : 16/16, discrim_real_loss=0.739, discrim_fake_loss=0.564 gan_loss=1.183\n",
            ">Epoch :10, Batch : 1/16, discrim_real_loss=0.696, discrim_fake_loss=0.571 gan_loss=1.191\n",
            ">Epoch :10, Batch : 2/16, discrim_real_loss=0.656, discrim_fake_loss=0.631 gan_loss=1.188\n",
            ">Epoch :10, Batch : 3/16, discrim_real_loss=0.648, discrim_fake_loss=0.612 gan_loss=1.176\n",
            ">Epoch :10, Batch : 4/16, discrim_real_loss=0.577, discrim_fake_loss=0.590 gan_loss=1.096\n",
            ">Epoch :10, Batch : 5/16, discrim_real_loss=0.577, discrim_fake_loss=0.687 gan_loss=1.078\n",
            ">Epoch :10, Batch : 6/16, discrim_real_loss=0.608, discrim_fake_loss=0.661 gan_loss=1.080\n",
            ">Epoch :10, Batch : 7/16, discrim_real_loss=0.645, discrim_fake_loss=0.739 gan_loss=1.145\n",
            ">Epoch :10, Batch : 8/16, discrim_real_loss=0.624, discrim_fake_loss=0.563 gan_loss=1.204\n",
            ">Epoch :10, Batch : 9/16, discrim_real_loss=0.673, discrim_fake_loss=0.588 gan_loss=1.242\n",
            ">Epoch :10, Batch : 10/16, discrim_real_loss=0.685, discrim_fake_loss=0.573 gan_loss=1.240\n",
            ">Epoch :10, Batch : 11/16, discrim_real_loss=0.745, discrim_fake_loss=0.614 gan_loss=1.205\n",
            ">Epoch :10, Batch : 12/16, discrim_real_loss=0.710, discrim_fake_loss=0.601 gan_loss=1.213\n",
            ">Epoch :10, Batch : 13/16, discrim_real_loss=0.668, discrim_fake_loss=0.537 gan_loss=1.296\n",
            ">Epoch :10, Batch : 14/16, discrim_real_loss=0.721, discrim_fake_loss=0.530 gan_loss=1.251\n",
            ">Epoch :10, Batch : 15/16, discrim_real_loss=0.672, discrim_fake_loss=0.558 gan_loss=1.160\n",
            ">Epoch :10, Batch : 16/16, discrim_real_loss=0.609, discrim_fake_loss=0.625 gan_loss=1.129\n",
            ">Accuracy real: 58%, fake: 77%\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "application/javascript": [
              "\n",
              "    async function download(id, filename, size) {\n",
              "      if (!google.colab.kernel.accessAllowed) {\n",
              "        return;\n",
              "      }\n",
              "      const div = document.createElement('div');\n",
              "      const label = document.createElement('label');\n",
              "      label.textContent = `Downloading \"${filename}\": `;\n",
              "      div.appendChild(label);\n",
              "      const progress = document.createElement('progress');\n",
              "      progress.max = size;\n",
              "      div.appendChild(progress);\n",
              "      document.body.appendChild(div);\n",
              "\n",
              "      const buffers = [];\n",
              "      let downloaded = 0;\n",
              "\n",
              "      const channel = await google.colab.kernel.comms.open(id);\n",
              "      // Send a message to notify the kernel that we're ready.\n",
              "      channel.send({})\n",
              "\n",
              "      for await (const message of channel.messages) {\n",
              "        // Send a message to notify the kernel that we're ready.\n",
              "        channel.send({})\n",
              "        if (message.buffers) {\n",
              "          for (const buffer of message.buffers) {\n",
              "            buffers.push(buffer);\n",
              "            downloaded += buffer.byteLength;\n",
              "            progress.value = downloaded;\n",
              "          }\n",
              "        }\n",
              "      }\n",
              "      const blob = new Blob(buffers, {type: 'application/binary'});\n",
              "      const a = document.createElement('a');\n",
              "      a.href = window.URL.createObjectURL(blob);\n",
              "      a.download = filename;\n",
              "      div.appendChild(a);\n",
              "      a.click();\n",
              "      div.remove();\n",
              "    }\n",
              "  "
            ],
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "application/javascript": [
              "download(\"download_10a4c310-d0de-4947-a8c7-e8aa1a5fa469\", \"generated_plot_e010.png\", 6001037)"
            ],
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "application/javascript": [
              "\n",
              "    async function download(id, filename, size) {\n",
              "      if (!google.colab.kernel.accessAllowed) {\n",
              "        return;\n",
              "      }\n",
              "      const div = document.createElement('div');\n",
              "      const label = document.createElement('label');\n",
              "      label.textContent = `Downloading \"${filename}\": `;\n",
              "      div.appendChild(label);\n",
              "      const progress = document.createElement('progress');\n",
              "      progress.max = size;\n",
              "      div.appendChild(progress);\n",
              "      document.body.appendChild(div);\n",
              "\n",
              "      const buffers = [];\n",
              "      let downloaded = 0;\n",
              "\n",
              "      const channel = await google.colab.kernel.comms.open(id);\n",
              "      // Send a message to notify the kernel that we're ready.\n",
              "      channel.send({})\n",
              "\n",
              "      for await (const message of channel.messages) {\n",
              "        // Send a message to notify the kernel that we're ready.\n",
              "        channel.send({})\n",
              "        if (message.buffers) {\n",
              "          for (const buffer of message.buffers) {\n",
              "            buffers.push(buffer);\n",
              "            downloaded += buffer.byteLength;\n",
              "            progress.value = downloaded;\n",
              "          }\n",
              "        }\n",
              "      }\n",
              "      const blob = new Blob(buffers, {type: 'application/binary'});\n",
              "      const a = document.createElement('a');\n",
              "      a.href = window.URL.createObjectURL(blob);\n",
              "      a.download = filename;\n",
              "      div.appendChild(a);\n",
              "      a.click();\n",
              "      div.remove();\n",
              "    }\n",
              "  "
            ],
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "application/javascript": [
              "download(\"download_10da5261-4961-4b52-b256-0054153d2732\", \"generator_model_010.h5\", 11913368)"
            ],
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            ">Epoch :11, Batch : 1/16, discrim_real_loss=0.628, discrim_fake_loss=0.634 gan_loss=1.137\n",
            ">Epoch :11, Batch : 2/16, discrim_real_loss=0.618, discrim_fake_loss=0.670 gan_loss=1.106\n",
            ">Epoch :11, Batch : 3/16, discrim_real_loss=0.604, discrim_fake_loss=0.810 gan_loss=1.252\n",
            ">Epoch :11, Batch : 4/16, discrim_real_loss=0.700, discrim_fake_loss=0.567 gan_loss=1.345\n",
            ">Epoch :11, Batch : 5/16, discrim_real_loss=0.741, discrim_fake_loss=0.620 gan_loss=1.360\n",
            ">Epoch :11, Batch : 6/16, discrim_real_loss=0.690, discrim_fake_loss=0.599 gan_loss=1.367\n",
            ">Epoch :11, Batch : 7/16, discrim_real_loss=0.682, discrim_fake_loss=0.536 gan_loss=1.323\n",
            ">Epoch :11, Batch : 8/16, discrim_real_loss=0.718, discrim_fake_loss=0.567 gan_loss=1.156\n",
            ">Epoch :11, Batch : 9/16, discrim_real_loss=0.687, discrim_fake_loss=0.610 gan_loss=0.991\n",
            ">Epoch :11, Batch : 10/16, discrim_real_loss=0.650, discrim_fake_loss=0.650 gan_loss=0.969\n",
            ">Epoch :11, Batch : 11/16, discrim_real_loss=0.603, discrim_fake_loss=0.585 gan_loss=0.981\n",
            ">Epoch :11, Batch : 12/16, discrim_real_loss=0.551, discrim_fake_loss=0.586 gan_loss=1.064\n",
            ">Epoch :11, Batch : 13/16, discrim_real_loss=0.529, discrim_fake_loss=0.545 gan_loss=1.099\n",
            ">Epoch :11, Batch : 14/16, discrim_real_loss=0.564, discrim_fake_loss=0.526 gan_loss=1.096\n",
            ">Epoch :11, Batch : 15/16, discrim_real_loss=0.537, discrim_fake_loss=0.559 gan_loss=1.105\n",
            ">Epoch :11, Batch : 16/16, discrim_real_loss=0.578, discrim_fake_loss=0.617 gan_loss=1.063\n",
            ">Epoch :12, Batch : 1/16, discrim_real_loss=0.542, discrim_fake_loss=0.658 gan_loss=1.113\n",
            ">Epoch :12, Batch : 2/16, discrim_real_loss=0.655, discrim_fake_loss=0.625 gan_loss=1.141\n",
            ">Epoch :12, Batch : 3/16, discrim_real_loss=0.671, discrim_fake_loss=0.576 gan_loss=1.156\n",
            ">Epoch :12, Batch : 4/16, discrim_real_loss=0.687, discrim_fake_loss=0.597 gan_loss=1.215\n",
            ">Epoch :12, Batch : 5/16, discrim_real_loss=0.666, discrim_fake_loss=0.550 gan_loss=1.134\n",
            ">Epoch :12, Batch : 6/16, discrim_real_loss=0.624, discrim_fake_loss=0.628 gan_loss=1.112\n",
            ">Epoch :12, Batch : 7/16, discrim_real_loss=0.615, discrim_fake_loss=0.560 gan_loss=1.207\n",
            ">Epoch :12, Batch : 8/16, discrim_real_loss=0.639, discrim_fake_loss=0.585 gan_loss=1.173\n",
            ">Epoch :12, Batch : 9/16, discrim_real_loss=0.644, discrim_fake_loss=0.601 gan_loss=1.096\n",
            ">Epoch :12, Batch : 10/16, discrim_real_loss=0.629, discrim_fake_loss=0.635 gan_loss=1.104\n",
            ">Epoch :12, Batch : 11/16, discrim_real_loss=0.626, discrim_fake_loss=0.634 gan_loss=1.069\n",
            ">Epoch :12, Batch : 12/16, discrim_real_loss=0.619, discrim_fake_loss=0.620 gan_loss=1.032\n",
            ">Epoch :12, Batch : 13/16, discrim_real_loss=0.634, discrim_fake_loss=0.636 gan_loss=1.045\n",
            ">Epoch :12, Batch : 14/16, discrim_real_loss=0.648, discrim_fake_loss=0.595 gan_loss=1.105\n",
            ">Epoch :12, Batch : 15/16, discrim_real_loss=0.660, discrim_fake_loss=0.578 gan_loss=1.152\n",
            ">Epoch :12, Batch : 16/16, discrim_real_loss=0.694, discrim_fake_loss=0.560 gan_loss=1.100\n",
            ">Epoch :13, Batch : 1/16, discrim_real_loss=0.643, discrim_fake_loss=0.593 gan_loss=1.100\n",
            ">Epoch :13, Batch : 2/16, discrim_real_loss=0.619, discrim_fake_loss=0.536 gan_loss=1.111\n",
            ">Epoch :13, Batch : 3/16, discrim_real_loss=0.602, discrim_fake_loss=0.556 gan_loss=1.115\n",
            ">Epoch :13, Batch : 4/16, discrim_real_loss=0.567, discrim_fake_loss=0.556 gan_loss=1.147\n",
            ">Epoch :13, Batch : 5/16, discrim_real_loss=0.610, discrim_fake_loss=0.504 gan_loss=1.125\n",
            ">Epoch :13, Batch : 6/16, discrim_real_loss=0.495, discrim_fake_loss=0.534 gan_loss=1.131\n",
            ">Epoch :13, Batch : 7/16, discrim_real_loss=0.525, discrim_fake_loss=0.570 gan_loss=1.131\n",
            ">Epoch :13, Batch : 8/16, discrim_real_loss=0.596, discrim_fake_loss=0.584 gan_loss=1.131\n",
            ">Epoch :13, Batch : 9/16, discrim_real_loss=0.641, discrim_fake_loss=0.623 gan_loss=1.131\n",
            ">Epoch :13, Batch : 10/16, discrim_real_loss=0.613, discrim_fake_loss=0.672 gan_loss=1.161\n",
            ">Epoch :13, Batch : 11/16, discrim_real_loss=0.618, discrim_fake_loss=0.659 gan_loss=1.151\n",
            ">Epoch :13, Batch : 12/16, discrim_real_loss=0.675, discrim_fake_loss=0.686 gan_loss=1.102\n",
            ">Epoch :13, Batch : 13/16, discrim_real_loss=0.711, discrim_fake_loss=0.645 gan_loss=1.144\n",
            ">Epoch :13, Batch : 14/16, discrim_real_loss=0.609, discrim_fake_loss=0.594 gan_loss=1.237\n",
            ">Epoch :13, Batch : 15/16, discrim_real_loss=0.585, discrim_fake_loss=0.552 gan_loss=1.238\n",
            ">Epoch :13, Batch : 16/16, discrim_real_loss=0.577, discrim_fake_loss=0.585 gan_loss=1.162\n",
            ">Epoch :14, Batch : 1/16, discrim_real_loss=0.611, discrim_fake_loss=0.586 gan_loss=1.089\n",
            ">Epoch :14, Batch : 2/16, discrim_real_loss=0.610, discrim_fake_loss=0.612 gan_loss=1.066\n",
            ">Epoch :14, Batch : 3/16, discrim_real_loss=0.603, discrim_fake_loss=0.572 gan_loss=1.028\n",
            ">Epoch :14, Batch : 4/16, discrim_real_loss=0.573, discrim_fake_loss=0.576 gan_loss=1.052\n",
            ">Epoch :14, Batch : 5/16, discrim_real_loss=0.582, discrim_fake_loss=0.591 gan_loss=1.079\n",
            ">Epoch :14, Batch : 6/16, discrim_real_loss=0.508, discrim_fake_loss=0.566 gan_loss=1.084\n",
            ">Epoch :14, Batch : 7/16, discrim_real_loss=0.601, discrim_fake_loss=0.568 gan_loss=1.089\n",
            ">Epoch :14, Batch : 8/16, discrim_real_loss=0.528, discrim_fake_loss=0.592 gan_loss=1.092\n",
            ">Epoch :14, Batch : 9/16, discrim_real_loss=0.559, discrim_fake_loss=0.628 gan_loss=1.177\n",
            ">Epoch :14, Batch : 10/16, discrim_real_loss=0.578, discrim_fake_loss=0.536 gan_loss=1.268\n",
            ">Epoch :14, Batch : 11/16, discrim_real_loss=0.614, discrim_fake_loss=0.564 gan_loss=1.385\n",
            ">Epoch :14, Batch : 12/16, discrim_real_loss=0.602, discrim_fake_loss=0.514 gan_loss=1.493\n",
            ">Epoch :14, Batch : 13/16, discrim_real_loss=0.576, discrim_fake_loss=0.576 gan_loss=1.607\n",
            ">Epoch :14, Batch : 14/16, discrim_real_loss=0.609, discrim_fake_loss=0.550 gan_loss=1.718\n",
            ">Epoch :14, Batch : 15/16, discrim_real_loss=0.756, discrim_fake_loss=0.609 gan_loss=1.717\n",
            ">Epoch :14, Batch : 16/16, discrim_real_loss=0.734, discrim_fake_loss=0.545 gan_loss=1.594\n",
            ">Epoch :15, Batch : 1/16, discrim_real_loss=0.700, discrim_fake_loss=0.622 gan_loss=1.374\n",
            ">Epoch :15, Batch : 2/16, discrim_real_loss=0.758, discrim_fake_loss=0.660 gan_loss=1.231\n",
            ">Epoch :15, Batch : 3/16, discrim_real_loss=0.646, discrim_fake_loss=0.685 gan_loss=1.135\n",
            ">Epoch :15, Batch : 4/16, discrim_real_loss=0.658, discrim_fake_loss=0.661 gan_loss=1.061\n",
            ">Epoch :15, Batch : 5/16, discrim_real_loss=0.632, discrim_fake_loss=0.686 gan_loss=1.097\n",
            ">Epoch :15, Batch : 6/16, discrim_real_loss=0.651, discrim_fake_loss=0.650 gan_loss=1.056\n",
            ">Epoch :15, Batch : 7/16, discrim_real_loss=0.670, discrim_fake_loss=0.665 gan_loss=1.052\n",
            ">Epoch :15, Batch : 8/16, discrim_real_loss=0.671, discrim_fake_loss=0.654 gan_loss=1.042\n",
            ">Epoch :15, Batch : 9/16, discrim_real_loss=0.670, discrim_fake_loss=0.675 gan_loss=1.102\n",
            ">Epoch :15, Batch : 10/16, discrim_real_loss=0.627, discrim_fake_loss=0.643 gan_loss=1.189\n",
            ">Epoch :15, Batch : 11/16, discrim_real_loss=0.655, discrim_fake_loss=0.543 gan_loss=1.202\n",
            ">Epoch :15, Batch : 12/16, discrim_real_loss=0.690, discrim_fake_loss=0.587 gan_loss=1.092\n",
            ">Epoch :15, Batch : 13/16, discrim_real_loss=0.611, discrim_fake_loss=0.636 gan_loss=1.088\n",
            ">Epoch :15, Batch : 14/16, discrim_real_loss=0.631, discrim_fake_loss=0.617 gan_loss=1.133\n",
            ">Epoch :15, Batch : 15/16, discrim_real_loss=0.647, discrim_fake_loss=0.546 gan_loss=1.149\n",
            ">Epoch :15, Batch : 16/16, discrim_real_loss=0.611, discrim_fake_loss=0.576 gan_loss=1.149\n",
            ">Epoch :16, Batch : 1/16, discrim_real_loss=0.611, discrim_fake_loss=0.579 gan_loss=1.141\n",
            ">Epoch :16, Batch : 2/16, discrim_real_loss=0.600, discrim_fake_loss=0.578 gan_loss=1.091\n",
            ">Epoch :16, Batch : 3/16, discrim_real_loss=0.653, discrim_fake_loss=0.580 gan_loss=1.072\n",
            ">Epoch :16, Batch : 4/16, discrim_real_loss=0.656, discrim_fake_loss=0.630 gan_loss=1.050\n",
            ">Epoch :16, Batch : 5/16, discrim_real_loss=0.664, discrim_fake_loss=0.636 gan_loss=1.077\n",
            ">Epoch :16, Batch : 6/16, discrim_real_loss=0.672, discrim_fake_loss=0.622 gan_loss=1.133\n",
            ">Epoch :16, Batch : 7/16, discrim_real_loss=0.685, discrim_fake_loss=0.544 gan_loss=1.128\n",
            ">Epoch :16, Batch : 8/16, discrim_real_loss=0.659, discrim_fake_loss=0.595 gan_loss=1.177\n",
            ">Epoch :16, Batch : 9/16, discrim_real_loss=0.638, discrim_fake_loss=0.590 gan_loss=1.174\n",
            ">Epoch :16, Batch : 10/16, discrim_real_loss=0.618, discrim_fake_loss=0.625 gan_loss=1.193\n",
            ">Epoch :16, Batch : 11/16, discrim_real_loss=0.626, discrim_fake_loss=0.549 gan_loss=1.202\n",
            ">Epoch :16, Batch : 12/16, discrim_real_loss=0.644, discrim_fake_loss=0.655 gan_loss=1.110\n",
            ">Epoch :16, Batch : 13/16, discrim_real_loss=0.609, discrim_fake_loss=0.600 gan_loss=1.044\n",
            ">Epoch :16, Batch : 14/16, discrim_real_loss=0.518, discrim_fake_loss=0.652 gan_loss=1.047\n",
            ">Epoch :16, Batch : 15/16, discrim_real_loss=0.492, discrim_fake_loss=0.607 gan_loss=1.097\n",
            ">Epoch :16, Batch : 16/16, discrim_real_loss=0.443, discrim_fake_loss=0.630 gan_loss=1.171\n",
            ">Epoch :17, Batch : 1/16, discrim_real_loss=0.520, discrim_fake_loss=0.588 gan_loss=1.156\n",
            ">Epoch :17, Batch : 2/16, discrim_real_loss=0.491, discrim_fake_loss=0.696 gan_loss=1.138\n",
            ">Epoch :17, Batch : 3/16, discrim_real_loss=0.617, discrim_fake_loss=0.777 gan_loss=1.168\n",
            ">Epoch :17, Batch : 4/16, discrim_real_loss=0.685, discrim_fake_loss=0.711 gan_loss=1.251\n",
            ">Epoch :17, Batch : 5/16, discrim_real_loss=0.753, discrim_fake_loss=0.552 gan_loss=1.224\n",
            ">Epoch :17, Batch : 6/16, discrim_real_loss=0.670, discrim_fake_loss=0.552 gan_loss=1.154\n",
            ">Epoch :17, Batch : 7/16, discrim_real_loss=0.657, discrim_fake_loss=0.631 gan_loss=1.252\n",
            ">Epoch :17, Batch : 8/16, discrim_real_loss=0.672, discrim_fake_loss=0.568 gan_loss=1.274\n",
            ">Epoch :17, Batch : 9/16, discrim_real_loss=0.742, discrim_fake_loss=0.560 gan_loss=1.184\n",
            ">Epoch :17, Batch : 10/16, discrim_real_loss=0.625, discrim_fake_loss=0.595 gan_loss=1.069\n",
            ">Epoch :17, Batch : 11/16, discrim_real_loss=0.593, discrim_fake_loss=0.745 gan_loss=1.046\n",
            ">Epoch :17, Batch : 12/16, discrim_real_loss=0.593, discrim_fake_loss=0.666 gan_loss=1.100\n",
            ">Epoch :17, Batch : 13/16, discrim_real_loss=0.639, discrim_fake_loss=0.739 gan_loss=1.154\n",
            ">Epoch :17, Batch : 14/16, discrim_real_loss=0.681, discrim_fake_loss=0.570 gan_loss=1.127\n",
            ">Epoch :17, Batch : 15/16, discrim_real_loss=0.676, discrim_fake_loss=0.698 gan_loss=1.100\n",
            ">Epoch :17, Batch : 16/16, discrim_real_loss=0.607, discrim_fake_loss=0.663 gan_loss=1.089\n",
            ">Epoch :18, Batch : 1/16, discrim_real_loss=0.638, discrim_fake_loss=0.665 gan_loss=1.088\n",
            ">Epoch :18, Batch : 2/16, discrim_real_loss=0.616, discrim_fake_loss=0.620 gan_loss=1.094\n",
            ">Epoch :18, Batch : 3/16, discrim_real_loss=0.597, discrim_fake_loss=0.667 gan_loss=1.127\n",
            ">Epoch :18, Batch : 4/16, discrim_real_loss=0.622, discrim_fake_loss=0.626 gan_loss=1.081\n",
            ">Epoch :18, Batch : 5/16, discrim_real_loss=0.706, discrim_fake_loss=0.679 gan_loss=1.059\n",
            ">Epoch :18, Batch : 6/16, discrim_real_loss=0.676, discrim_fake_loss=0.598 gan_loss=1.074\n",
            ">Epoch :18, Batch : 7/16, discrim_real_loss=0.689, discrim_fake_loss=0.629 gan_loss=1.065\n",
            ">Epoch :18, Batch : 8/16, discrim_real_loss=0.655, discrim_fake_loss=0.635 gan_loss=1.128\n",
            ">Epoch :18, Batch : 9/16, discrim_real_loss=0.677, discrim_fake_loss=0.544 gan_loss=1.237\n",
            ">Epoch :18, Batch : 10/16, discrim_real_loss=0.647, discrim_fake_loss=0.506 gan_loss=1.312\n",
            ">Epoch :18, Batch : 11/16, discrim_real_loss=0.647, discrim_fake_loss=0.502 gan_loss=1.319\n",
            ">Epoch :18, Batch : 12/16, discrim_real_loss=0.616, discrim_fake_loss=0.570 gan_loss=1.173\n",
            ">Epoch :18, Batch : 13/16, discrim_real_loss=0.567, discrim_fake_loss=0.645 gan_loss=1.137\n",
            ">Epoch :18, Batch : 14/16, discrim_real_loss=0.529, discrim_fake_loss=0.640 gan_loss=1.138\n",
            ">Epoch :18, Batch : 15/16, discrim_real_loss=0.540, discrim_fake_loss=0.656 gan_loss=1.113\n",
            ">Epoch :18, Batch : 16/16, discrim_real_loss=0.593, discrim_fake_loss=0.672 gan_loss=1.186\n",
            ">Epoch :19, Batch : 1/16, discrim_real_loss=0.621, discrim_fake_loss=0.619 gan_loss=1.207\n",
            ">Epoch :19, Batch : 2/16, discrim_real_loss=0.614, discrim_fake_loss=0.581 gan_loss=1.220\n",
            ">Epoch :19, Batch : 3/16, discrim_real_loss=0.601, discrim_fake_loss=0.647 gan_loss=1.180\n",
            ">Epoch :19, Batch : 4/16, discrim_real_loss=0.635, discrim_fake_loss=0.718 gan_loss=1.251\n",
            ">Epoch :19, Batch : 5/16, discrim_real_loss=0.737, discrim_fake_loss=0.728 gan_loss=1.292\n",
            ">Epoch :19, Batch : 6/16, discrim_real_loss=0.778, discrim_fake_loss=0.594 gan_loss=1.317\n",
            ">Epoch :19, Batch : 7/16, discrim_real_loss=0.851, discrim_fake_loss=0.594 gan_loss=1.262\n",
            ">Epoch :19, Batch : 8/16, discrim_real_loss=0.850, discrim_fake_loss=0.598 gan_loss=1.230\n",
            ">Epoch :19, Batch : 9/16, discrim_real_loss=0.856, discrim_fake_loss=0.576 gan_loss=1.220\n",
            ">Epoch :19, Batch : 10/16, discrim_real_loss=0.781, discrim_fake_loss=0.556 gan_loss=1.123\n",
            ">Epoch :19, Batch : 11/16, discrim_real_loss=0.729, discrim_fake_loss=0.577 gan_loss=1.101\n",
            ">Epoch :19, Batch : 12/16, discrim_real_loss=0.669, discrim_fake_loss=0.621 gan_loss=1.072\n",
            ">Epoch :19, Batch : 13/16, discrim_real_loss=0.668, discrim_fake_loss=0.585 gan_loss=1.080\n",
            ">Epoch :19, Batch : 14/16, discrim_real_loss=0.651, discrim_fake_loss=0.587 gan_loss=1.086\n",
            ">Epoch :19, Batch : 15/16, discrim_real_loss=0.670, discrim_fake_loss=0.635 gan_loss=1.094\n",
            ">Epoch :19, Batch : 16/16, discrim_real_loss=0.655, discrim_fake_loss=0.644 gan_loss=1.105\n",
            ">Epoch :20, Batch : 1/16, discrim_real_loss=0.639, discrim_fake_loss=0.612 gan_loss=1.162\n",
            ">Epoch :20, Batch : 2/16, discrim_real_loss=0.637, discrim_fake_loss=0.588 gan_loss=1.124\n",
            ">Epoch :20, Batch : 3/16, discrim_real_loss=0.663, discrim_fake_loss=0.623 gan_loss=1.088\n",
            ">Epoch :20, Batch : 4/16, discrim_real_loss=0.620, discrim_fake_loss=0.670 gan_loss=1.005\n",
            ">Epoch :20, Batch : 5/16, discrim_real_loss=0.603, discrim_fake_loss=0.689 gan_loss=0.992\n",
            ">Epoch :20, Batch : 6/16, discrim_real_loss=0.633, discrim_fake_loss=0.708 gan_loss=1.002\n",
            ">Epoch :20, Batch : 7/16, discrim_real_loss=0.686, discrim_fake_loss=0.649 gan_loss=1.031\n",
            ">Epoch :20, Batch : 8/16, discrim_real_loss=0.681, discrim_fake_loss=0.652 gan_loss=1.000\n",
            ">Epoch :20, Batch : 9/16, discrim_real_loss=0.650, discrim_fake_loss=0.660 gan_loss=1.048\n",
            ">Epoch :20, Batch : 10/16, discrim_real_loss=0.705, discrim_fake_loss=0.579 gan_loss=1.032\n",
            ">Epoch :20, Batch : 11/16, discrim_real_loss=0.652, discrim_fake_loss=0.620 gan_loss=1.002\n",
            ">Epoch :20, Batch : 12/16, discrim_real_loss=0.646, discrim_fake_loss=0.669 gan_loss=1.032\n",
            ">Epoch :20, Batch : 13/16, discrim_real_loss=0.652, discrim_fake_loss=0.652 gan_loss=1.060\n",
            ">Epoch :20, Batch : 14/16, discrim_real_loss=0.628, discrim_fake_loss=0.579 gan_loss=1.135\n",
            ">Epoch :20, Batch : 15/16, discrim_real_loss=0.640, discrim_fake_loss=0.586 gan_loss=1.124\n",
            ">Epoch :20, Batch : 16/16, discrim_real_loss=0.609, discrim_fake_loss=0.569 gan_loss=1.137\n",
            ">Accuracy real: 77%, fake: 90%\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "application/javascript": [
              "\n",
              "    async function download(id, filename, size) {\n",
              "      if (!google.colab.kernel.accessAllowed) {\n",
              "        return;\n",
              "      }\n",
              "      const div = document.createElement('div');\n",
              "      const label = document.createElement('label');\n",
              "      label.textContent = `Downloading \"${filename}\": `;\n",
              "      div.appendChild(label);\n",
              "      const progress = document.createElement('progress');\n",
              "      progress.max = size;\n",
              "      div.appendChild(progress);\n",
              "      document.body.appendChild(div);\n",
              "\n",
              "      const buffers = [];\n",
              "      let downloaded = 0;\n",
              "\n",
              "      const channel = await google.colab.kernel.comms.open(id);\n",
              "      // Send a message to notify the kernel that we're ready.\n",
              "      channel.send({})\n",
              "\n",
              "      for await (const message of channel.messages) {\n",
              "        // Send a message to notify the kernel that we're ready.\n",
              "        channel.send({})\n",
              "        if (message.buffers) {\n",
              "          for (const buffer of message.buffers) {\n",
              "            buffers.push(buffer);\n",
              "            downloaded += buffer.byteLength;\n",
              "            progress.value = downloaded;\n",
              "          }\n",
              "        }\n",
              "      }\n",
              "      const blob = new Blob(buffers, {type: 'application/binary'});\n",
              "      const a = document.createElement('a');\n",
              "      a.href = window.URL.createObjectURL(blob);\n",
              "      a.download = filename;\n",
              "      div.appendChild(a);\n",
              "      a.click();\n",
              "      div.remove();\n",
              "    }\n",
              "  "
            ],
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "application/javascript": [
              "download(\"download_d3f43eaa-a1dd-4a77-a5c7-76d27bfd31d8\", \"generated_plot_e020.png\", 5966970)"
            ],
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "application/javascript": [
              "\n",
              "    async function download(id, filename, size) {\n",
              "      if (!google.colab.kernel.accessAllowed) {\n",
              "        return;\n",
              "      }\n",
              "      const div = document.createElement('div');\n",
              "      const label = document.createElement('label');\n",
              "      label.textContent = `Downloading \"${filename}\": `;\n",
              "      div.appendChild(label);\n",
              "      const progress = document.createElement('progress');\n",
              "      progress.max = size;\n",
              "      div.appendChild(progress);\n",
              "      document.body.appendChild(div);\n",
              "\n",
              "      const buffers = [];\n",
              "      let downloaded = 0;\n",
              "\n",
              "      const channel = await google.colab.kernel.comms.open(id);\n",
              "      // Send a message to notify the kernel that we're ready.\n",
              "      channel.send({})\n",
              "\n",
              "      for await (const message of channel.messages) {\n",
              "        // Send a message to notify the kernel that we're ready.\n",
              "        channel.send({})\n",
              "        if (message.buffers) {\n",
              "          for (const buffer of message.buffers) {\n",
              "            buffers.push(buffer);\n",
              "            downloaded += buffer.byteLength;\n",
              "            progress.value = downloaded;\n",
              "          }\n",
              "        }\n",
              "      }\n",
              "      const blob = new Blob(buffers, {type: 'application/binary'});\n",
              "      const a = document.createElement('a');\n",
              "      a.href = window.URL.createObjectURL(blob);\n",
              "      a.download = filename;\n",
              "      div.appendChild(a);\n",
              "      a.click();\n",
              "      div.remove();\n",
              "    }\n",
              "  "
            ],
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "application/javascript": [
              "download(\"download_3d47021d-53b2-4bf1-97ee-c8c59aabad92\", \"generator_model_020.h5\", 11913368)"
            ],
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            ">Epoch :21, Batch : 1/16, discrim_real_loss=0.528, discrim_fake_loss=0.585 gan_loss=1.205\n",
            ">Epoch :21, Batch : 2/16, discrim_real_loss=0.532, discrim_fake_loss=0.590 gan_loss=1.256\n",
            ">Epoch :21, Batch : 3/16, discrim_real_loss=0.505, discrim_fake_loss=0.525 gan_loss=1.313\n",
            ">Epoch :21, Batch : 4/16, discrim_real_loss=0.507, discrim_fake_loss=0.605 gan_loss=1.208\n",
            ">Epoch :21, Batch : 5/16, discrim_real_loss=0.458, discrim_fake_loss=0.541 gan_loss=1.161\n",
            ">Epoch :21, Batch : 6/16, discrim_real_loss=0.451, discrim_fake_loss=0.664 gan_loss=1.244\n",
            ">Epoch :21, Batch : 7/16, discrim_real_loss=0.534, discrim_fake_loss=0.520 gan_loss=1.228\n",
            ">Epoch :21, Batch : 8/16, discrim_real_loss=0.528, discrim_fake_loss=0.566 gan_loss=1.118\n",
            ">Epoch :21, Batch : 9/16, discrim_real_loss=0.550, discrim_fake_loss=0.661 gan_loss=1.089\n",
            ">Epoch :21, Batch : 10/16, discrim_real_loss=0.578, discrim_fake_loss=0.587 gan_loss=1.074\n",
            ">Epoch :21, Batch : 11/16, discrim_real_loss=0.549, discrim_fake_loss=0.693 gan_loss=1.043\n",
            ">Epoch :21, Batch : 12/16, discrim_real_loss=0.641, discrim_fake_loss=0.680 gan_loss=1.049\n",
            ">Epoch :21, Batch : 13/16, discrim_real_loss=0.666, discrim_fake_loss=0.656 gan_loss=1.077\n",
            ">Epoch :21, Batch : 14/16, discrim_real_loss=0.638, discrim_fake_loss=0.619 gan_loss=1.124\n",
            ">Epoch :21, Batch : 15/16, discrim_real_loss=0.623, discrim_fake_loss=0.566 gan_loss=1.167\n",
            ">Epoch :21, Batch : 16/16, discrim_real_loss=0.599, discrim_fake_loss=0.591 gan_loss=1.211\n",
            ">Epoch :22, Batch : 1/16, discrim_real_loss=0.629, discrim_fake_loss=0.547 gan_loss=1.210\n",
            ">Epoch :22, Batch : 2/16, discrim_real_loss=0.579, discrim_fake_loss=0.675 gan_loss=1.295\n",
            ">Epoch :22, Batch : 3/16, discrim_real_loss=0.670, discrim_fake_loss=0.602 gan_loss=1.323\n",
            ">Epoch :22, Batch : 4/16, discrim_real_loss=0.680, discrim_fake_loss=0.616 gan_loss=1.325\n",
            ">Epoch :22, Batch : 5/16, discrim_real_loss=0.698, discrim_fake_loss=0.558 gan_loss=1.318\n",
            ">Epoch :22, Batch : 6/16, discrim_real_loss=0.659, discrim_fake_loss=0.560 gan_loss=1.349\n",
            ">Epoch :22, Batch : 7/16, discrim_real_loss=0.644, discrim_fake_loss=0.564 gan_loss=1.309\n",
            ">Epoch :22, Batch : 8/16, discrim_real_loss=0.597, discrim_fake_loss=0.602 gan_loss=1.403\n",
            ">Epoch :22, Batch : 9/16, discrim_real_loss=0.717, discrim_fake_loss=0.543 gan_loss=1.267\n",
            ">Epoch :22, Batch : 10/16, discrim_real_loss=0.586, discrim_fake_loss=0.607 gan_loss=1.245\n",
            ">Epoch :22, Batch : 11/16, discrim_real_loss=0.642, discrim_fake_loss=0.568 gan_loss=1.198\n",
            ">Epoch :22, Batch : 12/16, discrim_real_loss=0.586, discrim_fake_loss=0.632 gan_loss=1.222\n",
            ">Epoch :22, Batch : 13/16, discrim_real_loss=0.562, discrim_fake_loss=0.557 gan_loss=1.275\n",
            ">Epoch :22, Batch : 14/16, discrim_real_loss=0.660, discrim_fake_loss=0.586 gan_loss=1.293\n",
            ">Epoch :22, Batch : 15/16, discrim_real_loss=0.640, discrim_fake_loss=0.575 gan_loss=1.254\n",
            ">Epoch :22, Batch : 16/16, discrim_real_loss=0.641, discrim_fake_loss=0.584 gan_loss=1.241\n",
            ">Epoch :23, Batch : 1/16, discrim_real_loss=0.632, discrim_fake_loss=0.551 gan_loss=1.191\n",
            ">Epoch :23, Batch : 2/16, discrim_real_loss=0.588, discrim_fake_loss=0.614 gan_loss=1.223\n",
            ">Epoch :23, Batch : 3/16, discrim_real_loss=0.612, discrim_fake_loss=0.559 gan_loss=1.198\n",
            ">Epoch :23, Batch : 4/16, discrim_real_loss=0.717, discrim_fake_loss=0.636 gan_loss=1.112\n",
            ">Epoch :23, Batch : 5/16, discrim_real_loss=0.676, discrim_fake_loss=0.695 gan_loss=1.113\n",
            ">Epoch :23, Batch : 6/16, discrim_real_loss=0.670, discrim_fake_loss=0.648 gan_loss=1.091\n",
            ">Epoch :23, Batch : 7/16, discrim_real_loss=0.696, discrim_fake_loss=0.698 gan_loss=1.126\n",
            ">Epoch :23, Batch : 8/16, discrim_real_loss=0.748, discrim_fake_loss=0.667 gan_loss=1.118\n",
            ">Epoch :23, Batch : 9/16, discrim_real_loss=0.771, discrim_fake_loss=0.779 gan_loss=1.217\n",
            ">Epoch :23, Batch : 10/16, discrim_real_loss=0.800, discrim_fake_loss=0.575 gan_loss=1.334\n",
            ">Epoch :23, Batch : 11/16, discrim_real_loss=0.742, discrim_fake_loss=0.499 gan_loss=1.271\n",
            ">Epoch :23, Batch : 12/16, discrim_real_loss=0.589, discrim_fake_loss=0.671 gan_loss=1.140\n",
            ">Epoch :23, Batch : 13/16, discrim_real_loss=0.515, discrim_fake_loss=0.933 gan_loss=1.117\n",
            ">Epoch :23, Batch : 14/16, discrim_real_loss=0.662, discrim_fake_loss=0.670 gan_loss=1.071\n",
            ">Epoch :23, Batch : 15/16, discrim_real_loss=0.730, discrim_fake_loss=0.682 gan_loss=1.011\n",
            ">Epoch :23, Batch : 16/16, discrim_real_loss=0.684, discrim_fake_loss=0.660 gan_loss=1.021\n",
            ">Epoch :24, Batch : 1/16, discrim_real_loss=0.712, discrim_fake_loss=0.669 gan_loss=1.034\n",
            ">Epoch :24, Batch : 2/16, discrim_real_loss=0.700, discrim_fake_loss=0.608 gan_loss=1.073\n",
            ">Epoch :24, Batch : 3/16, discrim_real_loss=0.672, discrim_fake_loss=0.596 gan_loss=1.134\n",
            ">Epoch :24, Batch : 4/16, discrim_real_loss=0.700, discrim_fake_loss=0.577 gan_loss=1.135\n",
            ">Epoch :24, Batch : 5/16, discrim_real_loss=0.623, discrim_fake_loss=0.678 gan_loss=1.206\n",
            ">Epoch :24, Batch : 6/16, discrim_real_loss=0.700, discrim_fake_loss=0.520 gan_loss=1.179\n",
            ">Epoch :24, Batch : 7/16, discrim_real_loss=0.739, discrim_fake_loss=0.587 gan_loss=1.113\n",
            ">Epoch :24, Batch : 8/16, discrim_real_loss=0.677, discrim_fake_loss=0.593 gan_loss=1.075\n",
            ">Epoch :24, Batch : 9/16, discrim_real_loss=0.599, discrim_fake_loss=0.644 gan_loss=1.079\n",
            ">Epoch :24, Batch : 10/16, discrim_real_loss=0.639, discrim_fake_loss=0.617 gan_loss=1.055\n",
            ">Epoch :24, Batch : 11/16, discrim_real_loss=0.668, discrim_fake_loss=0.693 gan_loss=1.054\n",
            ">Epoch :24, Batch : 12/16, discrim_real_loss=0.638, discrim_fake_loss=0.648 gan_loss=1.090\n",
            ">Epoch :24, Batch : 13/16, discrim_real_loss=0.641, discrim_fake_loss=0.598 gan_loss=1.109\n",
            ">Epoch :24, Batch : 14/16, discrim_real_loss=0.550, discrim_fake_loss=0.636 gan_loss=1.103\n",
            ">Epoch :24, Batch : 15/16, discrim_real_loss=0.537, discrim_fake_loss=0.606 gan_loss=1.127\n",
            ">Epoch :24, Batch : 16/16, discrim_real_loss=0.539, discrim_fake_loss=0.713 gan_loss=1.112\n",
            ">Epoch :25, Batch : 1/16, discrim_real_loss=0.630, discrim_fake_loss=0.746 gan_loss=1.125\n",
            ">Epoch :25, Batch : 2/16, discrim_real_loss=0.736, discrim_fake_loss=0.631 gan_loss=1.072\n",
            ">Epoch :25, Batch : 3/16, discrim_real_loss=0.752, discrim_fake_loss=0.679 gan_loss=1.023\n",
            ">Epoch :25, Batch : 4/16, discrim_real_loss=0.692, discrim_fake_loss=0.711 gan_loss=1.030\n",
            ">Epoch :25, Batch : 5/16, discrim_real_loss=0.744, discrim_fake_loss=0.643 gan_loss=1.044\n",
            ">Epoch :25, Batch : 6/16, discrim_real_loss=0.750, discrim_fake_loss=0.614 gan_loss=1.057\n",
            ">Epoch :25, Batch : 7/16, discrim_real_loss=0.734, discrim_fake_loss=0.642 gan_loss=1.068\n",
            ">Epoch :25, Batch : 8/16, discrim_real_loss=0.690, discrim_fake_loss=0.596 gan_loss=1.092\n",
            ">Epoch :25, Batch : 9/16, discrim_real_loss=0.720, discrim_fake_loss=0.621 gan_loss=1.104\n",
            ">Epoch :25, Batch : 10/16, discrim_real_loss=0.680, discrim_fake_loss=0.582 gan_loss=1.117\n",
            ">Epoch :25, Batch : 11/16, discrim_real_loss=0.623, discrim_fake_loss=0.643 gan_loss=1.089\n",
            ">Epoch :25, Batch : 12/16, discrim_real_loss=0.661, discrim_fake_loss=0.674 gan_loss=1.095\n",
            ">Epoch :25, Batch : 13/16, discrim_real_loss=0.622, discrim_fake_loss=0.681 gan_loss=1.083\n",
            ">Epoch :25, Batch : 14/16, discrim_real_loss=0.683, discrim_fake_loss=0.614 gan_loss=1.067\n",
            ">Epoch :25, Batch : 15/16, discrim_real_loss=0.670, discrim_fake_loss=0.619 gan_loss=1.046\n",
            ">Epoch :25, Batch : 16/16, discrim_real_loss=0.626, discrim_fake_loss=0.608 gan_loss=1.035\n",
            ">Epoch :26, Batch : 1/16, discrim_real_loss=0.640, discrim_fake_loss=0.648 gan_loss=1.065\n",
            ">Epoch :26, Batch : 2/16, discrim_real_loss=0.652, discrim_fake_loss=0.584 gan_loss=1.090\n",
            ">Epoch :26, Batch : 3/16, discrim_real_loss=0.617, discrim_fake_loss=0.653 gan_loss=1.147\n",
            ">Epoch :26, Batch : 4/16, discrim_real_loss=0.717, discrim_fake_loss=0.526 gan_loss=1.208\n",
            ">Epoch :26, Batch : 5/16, discrim_real_loss=0.630, discrim_fake_loss=0.578 gan_loss=1.149\n",
            ">Epoch :26, Batch : 6/16, discrim_real_loss=0.622, discrim_fake_loss=0.786 gan_loss=1.231\n",
            ">Epoch :26, Batch : 7/16, discrim_real_loss=0.720, discrim_fake_loss=0.482 gan_loss=1.210\n",
            ">Epoch :26, Batch : 8/16, discrim_real_loss=0.751, discrim_fake_loss=0.515 gan_loss=1.036\n",
            ">Epoch :26, Batch : 9/16, discrim_real_loss=0.664, discrim_fake_loss=0.662 gan_loss=0.993\n",
            ">Epoch :26, Batch : 10/16, discrim_real_loss=0.635, discrim_fake_loss=0.655 gan_loss=0.994\n",
            ">Epoch :26, Batch : 11/16, discrim_real_loss=0.682, discrim_fake_loss=0.645 gan_loss=0.999\n",
            ">Epoch :26, Batch : 12/16, discrim_real_loss=0.666, discrim_fake_loss=0.650 gan_loss=1.027\n",
            ">Epoch :26, Batch : 13/16, discrim_real_loss=0.665, discrim_fake_loss=0.631 gan_loss=1.021\n",
            ">Epoch :26, Batch : 14/16, discrim_real_loss=0.676, discrim_fake_loss=0.629 gan_loss=1.001\n",
            ">Epoch :26, Batch : 15/16, discrim_real_loss=0.669, discrim_fake_loss=0.734 gan_loss=1.036\n",
            ">Epoch :26, Batch : 16/16, discrim_real_loss=0.649, discrim_fake_loss=0.676 gan_loss=1.134\n",
            ">Epoch :27, Batch : 1/16, discrim_real_loss=0.696, discrim_fake_loss=0.577 gan_loss=1.100\n",
            ">Epoch :27, Batch : 2/16, discrim_real_loss=0.635, discrim_fake_loss=0.587 gan_loss=1.057\n",
            ">Epoch :27, Batch : 3/16, discrim_real_loss=0.551, discrim_fake_loss=0.594 gan_loss=1.092\n",
            ">Epoch :27, Batch : 4/16, discrim_real_loss=0.543, discrim_fake_loss=0.598 gan_loss=1.092\n",
            ">Epoch :27, Batch : 5/16, discrim_real_loss=0.514, discrim_fake_loss=0.629 gan_loss=1.046\n",
            ">Epoch :27, Batch : 6/16, discrim_real_loss=0.477, discrim_fake_loss=0.637 gan_loss=1.104\n",
            ">Epoch :27, Batch : 7/16, discrim_real_loss=0.555, discrim_fake_loss=0.711 gan_loss=1.180\n",
            ">Epoch :27, Batch : 8/16, discrim_real_loss=0.575, discrim_fake_loss=0.521 gan_loss=1.196\n",
            ">Epoch :27, Batch : 9/16, discrim_real_loss=0.595, discrim_fake_loss=0.610 gan_loss=1.203\n",
            ">Epoch :27, Batch : 10/16, discrim_real_loss=0.537, discrim_fake_loss=0.533 gan_loss=1.237\n",
            ">Epoch :27, Batch : 11/16, discrim_real_loss=0.540, discrim_fake_loss=0.603 gan_loss=1.233\n",
            ">Epoch :27, Batch : 12/16, discrim_real_loss=0.630, discrim_fake_loss=0.607 gan_loss=1.241\n",
            ">Epoch :27, Batch : 13/16, discrim_real_loss=0.572, discrim_fake_loss=0.636 gan_loss=1.179\n",
            ">Epoch :27, Batch : 14/16, discrim_real_loss=0.667, discrim_fake_loss=0.599 gan_loss=1.065\n",
            ">Epoch :27, Batch : 15/16, discrim_real_loss=0.651, discrim_fake_loss=0.776 gan_loss=1.122\n",
            ">Epoch :27, Batch : 16/16, discrim_real_loss=0.677, discrim_fake_loss=0.622 gan_loss=1.167\n",
            ">Epoch :28, Batch : 1/16, discrim_real_loss=0.747, discrim_fake_loss=0.600 gan_loss=1.135\n",
            ">Epoch :28, Batch : 2/16, discrim_real_loss=0.701, discrim_fake_loss=0.606 gan_loss=1.112\n",
            ">Epoch :28, Batch : 3/16, discrim_real_loss=0.663, discrim_fake_loss=0.603 gan_loss=1.105\n",
            ">Epoch :28, Batch : 4/16, discrim_real_loss=0.593, discrim_fake_loss=0.612 gan_loss=1.129\n",
            ">Epoch :28, Batch : 5/16, discrim_real_loss=0.670, discrim_fake_loss=0.562 gan_loss=1.144\n",
            ">Epoch :28, Batch : 6/16, discrim_real_loss=0.721, discrim_fake_loss=0.546 gan_loss=1.123\n",
            ">Epoch :28, Batch : 7/16, discrim_real_loss=0.669, discrim_fake_loss=0.538 gan_loss=1.053\n",
            ">Epoch :28, Batch : 8/16, discrim_real_loss=0.633, discrim_fake_loss=0.583 gan_loss=1.048\n",
            ">Epoch :28, Batch : 9/16, discrim_real_loss=0.620, discrim_fake_loss=0.569 gan_loss=1.056\n",
            ">Epoch :28, Batch : 10/16, discrim_real_loss=0.634, discrim_fake_loss=0.564 gan_loss=1.059\n",
            ">Epoch :28, Batch : 11/16, discrim_real_loss=0.587, discrim_fake_loss=0.558 gan_loss=1.092\n",
            ">Epoch :28, Batch : 12/16, discrim_real_loss=0.569, discrim_fake_loss=0.521 gan_loss=1.082\n",
            ">Epoch :28, Batch : 13/16, discrim_real_loss=0.575, discrim_fake_loss=0.545 gan_loss=1.081\n",
            ">Epoch :28, Batch : 14/16, discrim_real_loss=0.587, discrim_fake_loss=0.568 gan_loss=1.069\n",
            ">Epoch :28, Batch : 15/16, discrim_real_loss=0.572, discrim_fake_loss=0.578 gan_loss=1.020\n",
            ">Epoch :28, Batch : 16/16, discrim_real_loss=0.583, discrim_fake_loss=0.636 gan_loss=0.991\n",
            ">Epoch :29, Batch : 1/16, discrim_real_loss=0.600, discrim_fake_loss=0.631 gan_loss=1.029\n",
            ">Epoch :29, Batch : 2/16, discrim_real_loss=0.574, discrim_fake_loss=0.583 gan_loss=1.165\n",
            ">Epoch :29, Batch : 3/16, discrim_real_loss=0.552, discrim_fake_loss=0.514 gan_loss=1.240\n",
            ">Epoch :29, Batch : 4/16, discrim_real_loss=0.554, discrim_fake_loss=0.508 gan_loss=1.258\n",
            ">Epoch :29, Batch : 5/16, discrim_real_loss=0.552, discrim_fake_loss=0.513 gan_loss=1.195\n",
            ">Epoch :29, Batch : 6/16, discrim_real_loss=0.544, discrim_fake_loss=0.559 gan_loss=1.112\n",
            ">Epoch :29, Batch : 7/16, discrim_real_loss=0.592, discrim_fake_loss=0.608 gan_loss=1.066\n",
            ">Epoch :29, Batch : 8/16, discrim_real_loss=0.533, discrim_fake_loss=0.607 gan_loss=1.047\n",
            ">Epoch :29, Batch : 9/16, discrim_real_loss=0.533, discrim_fake_loss=0.634 gan_loss=1.077\n",
            ">Epoch :29, Batch : 10/16, discrim_real_loss=0.597, discrim_fake_loss=0.617 gan_loss=1.087\n",
            ">Epoch :29, Batch : 11/16, discrim_real_loss=0.581, discrim_fake_loss=0.627 gan_loss=1.120\n",
            ">Epoch :29, Batch : 12/16, discrim_real_loss=0.633, discrim_fake_loss=0.617 gan_loss=1.219\n",
            ">Epoch :29, Batch : 13/16, discrim_real_loss=0.619, discrim_fake_loss=0.540 gan_loss=1.225\n",
            ">Epoch :29, Batch : 14/16, discrim_real_loss=0.620, discrim_fake_loss=0.566 gan_loss=1.187\n",
            ">Epoch :29, Batch : 15/16, discrim_real_loss=0.619, discrim_fake_loss=0.680 gan_loss=1.141\n",
            ">Epoch :29, Batch : 16/16, discrim_real_loss=0.624, discrim_fake_loss=0.673 gan_loss=1.196\n",
            ">Epoch :30, Batch : 1/16, discrim_real_loss=0.652, discrim_fake_loss=0.592 gan_loss=1.204\n",
            ">Epoch :30, Batch : 2/16, discrim_real_loss=0.646, discrim_fake_loss=0.674 gan_loss=1.176\n",
            ">Epoch :30, Batch : 3/16, discrim_real_loss=0.658, discrim_fake_loss=0.612 gan_loss=1.178\n",
            ">Epoch :30, Batch : 4/16, discrim_real_loss=0.633, discrim_fake_loss=0.725 gan_loss=1.233\n",
            ">Epoch :30, Batch : 5/16, discrim_real_loss=0.686, discrim_fake_loss=0.665 gan_loss=1.336\n",
            ">Epoch :30, Batch : 6/16, discrim_real_loss=0.680, discrim_fake_loss=0.561 gan_loss=1.385\n",
            ">Epoch :30, Batch : 7/16, discrim_real_loss=0.742, discrim_fake_loss=0.609 gan_loss=1.409\n",
            ">Epoch :30, Batch : 8/16, discrim_real_loss=0.807, discrim_fake_loss=0.577 gan_loss=1.400\n",
            ">Epoch :30, Batch : 9/16, discrim_real_loss=0.745, discrim_fake_loss=0.595 gan_loss=1.425\n",
            ">Epoch :30, Batch : 10/16, discrim_real_loss=0.713, discrim_fake_loss=0.576 gan_loss=1.486\n",
            ">Epoch :30, Batch : 11/16, discrim_real_loss=0.682, discrim_fake_loss=0.625 gan_loss=1.402\n",
            ">Epoch :30, Batch : 12/16, discrim_real_loss=0.728, discrim_fake_loss=0.667 gan_loss=1.237\n",
            ">Epoch :30, Batch : 13/16, discrim_real_loss=0.695, discrim_fake_loss=0.686 gan_loss=1.141\n",
            ">Epoch :30, Batch : 14/16, discrim_real_loss=0.763, discrim_fake_loss=0.783 gan_loss=1.040\n",
            ">Epoch :30, Batch : 15/16, discrim_real_loss=0.790, discrim_fake_loss=0.728 gan_loss=1.064\n",
            ">Epoch :30, Batch : 16/16, discrim_real_loss=0.794, discrim_fake_loss=0.627 gan_loss=1.122\n",
            ">Accuracy real: 36%, fake: 85%\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "application/javascript": [
              "\n",
              "    async function download(id, filename, size) {\n",
              "      if (!google.colab.kernel.accessAllowed) {\n",
              "        return;\n",
              "      }\n",
              "      const div = document.createElement('div');\n",
              "      const label = document.createElement('label');\n",
              "      label.textContent = `Downloading \"${filename}\": `;\n",
              "      div.appendChild(label);\n",
              "      const progress = document.createElement('progress');\n",
              "      progress.max = size;\n",
              "      div.appendChild(progress);\n",
              "      document.body.appendChild(div);\n",
              "\n",
              "      const buffers = [];\n",
              "      let downloaded = 0;\n",
              "\n",
              "      const channel = await google.colab.kernel.comms.open(id);\n",
              "      // Send a message to notify the kernel that we're ready.\n",
              "      channel.send({})\n",
              "\n",
              "      for await (const message of channel.messages) {\n",
              "        // Send a message to notify the kernel that we're ready.\n",
              "        channel.send({})\n",
              "        if (message.buffers) {\n",
              "          for (const buffer of message.buffers) {\n",
              "            buffers.push(buffer);\n",
              "            downloaded += buffer.byteLength;\n",
              "            progress.value = downloaded;\n",
              "          }\n",
              "        }\n",
              "      }\n",
              "      const blob = new Blob(buffers, {type: 'application/binary'});\n",
              "      const a = document.createElement('a');\n",
              "      a.href = window.URL.createObjectURL(blob);\n",
              "      a.download = filename;\n",
              "      div.appendChild(a);\n",
              "      a.click();\n",
              "      div.remove();\n",
              "    }\n",
              "  "
            ],
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "application/javascript": [
              "download(\"download_bdce48cf-c53c-44bd-88e7-88b13eaef73a\", \"generated_plot_e030.png\", 5840795)"
            ],
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "application/javascript": [
              "\n",
              "    async function download(id, filename, size) {\n",
              "      if (!google.colab.kernel.accessAllowed) {\n",
              "        return;\n",
              "      }\n",
              "      const div = document.createElement('div');\n",
              "      const label = document.createElement('label');\n",
              "      label.textContent = `Downloading \"${filename}\": `;\n",
              "      div.appendChild(label);\n",
              "      const progress = document.createElement('progress');\n",
              "      progress.max = size;\n",
              "      div.appendChild(progress);\n",
              "      document.body.appendChild(div);\n",
              "\n",
              "      const buffers = [];\n",
              "      let downloaded = 0;\n",
              "\n",
              "      const channel = await google.colab.kernel.comms.open(id);\n",
              "      // Send a message to notify the kernel that we're ready.\n",
              "      channel.send({})\n",
              "\n",
              "      for await (const message of channel.messages) {\n",
              "        // Send a message to notify the kernel that we're ready.\n",
              "        channel.send({})\n",
              "        if (message.buffers) {\n",
              "          for (const buffer of message.buffers) {\n",
              "            buffers.push(buffer);\n",
              "            downloaded += buffer.byteLength;\n",
              "            progress.value = downloaded;\n",
              "          }\n",
              "        }\n",
              "      }\n",
              "      const blob = new Blob(buffers, {type: 'application/binary'});\n",
              "      const a = document.createElement('a');\n",
              "      a.href = window.URL.createObjectURL(blob);\n",
              "      a.download = filename;\n",
              "      div.appendChild(a);\n",
              "      a.click();\n",
              "      div.remove();\n",
              "    }\n",
              "  "
            ],
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "application/javascript": [
              "download(\"download_8011d098-ea41-4d0e-981c-13745d1894f4\", \"generator_model_030.h5\", 11913368)"
            ],
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            ">Epoch :31, Batch : 1/16, discrim_real_loss=0.623, discrim_fake_loss=0.549 gan_loss=1.213\n",
            ">Epoch :31, Batch : 2/16, discrim_real_loss=0.685, discrim_fake_loss=0.514 gan_loss=1.277\n",
            ">Epoch :31, Batch : 3/16, discrim_real_loss=0.638, discrim_fake_loss=0.572 gan_loss=1.267\n",
            ">Epoch :31, Batch : 4/16, discrim_real_loss=0.613, discrim_fake_loss=0.588 gan_loss=1.284\n",
            ">Epoch :31, Batch : 5/16, discrim_real_loss=0.653, discrim_fake_loss=0.529 gan_loss=1.202\n",
            ">Epoch :31, Batch : 6/16, discrim_real_loss=0.586, discrim_fake_loss=0.550 gan_loss=1.185\n",
            ">Epoch :31, Batch : 7/16, discrim_real_loss=0.598, discrim_fake_loss=0.530 gan_loss=1.157\n",
            ">Epoch :31, Batch : 8/16, discrim_real_loss=0.540, discrim_fake_loss=0.588 gan_loss=1.220\n",
            ">Epoch :31, Batch : 9/16, discrim_real_loss=0.503, discrim_fake_loss=0.580 gan_loss=1.245\n",
            ">Epoch :31, Batch : 10/16, discrim_real_loss=0.602, discrim_fake_loss=0.587 gan_loss=1.232\n",
            ">Epoch :31, Batch : 11/16, discrim_real_loss=0.598, discrim_fake_loss=0.787 gan_loss=1.372\n",
            ">Epoch :31, Batch : 12/16, discrim_real_loss=0.757, discrim_fake_loss=0.550 gan_loss=1.357\n",
            ">Epoch :31, Batch : 13/16, discrim_real_loss=0.749, discrim_fake_loss=0.653 gan_loss=1.356\n",
            ">Epoch :31, Batch : 14/16, discrim_real_loss=0.746, discrim_fake_loss=0.597 gan_loss=1.255\n",
            ">Epoch :31, Batch : 15/16, discrim_real_loss=0.755, discrim_fake_loss=0.623 gan_loss=1.180\n",
            ">Epoch :31, Batch : 16/16, discrim_real_loss=0.667, discrim_fake_loss=0.619 gan_loss=1.152\n",
            ">Epoch :32, Batch : 1/16, discrim_real_loss=0.681, discrim_fake_loss=0.664 gan_loss=1.091\n",
            ">Epoch :32, Batch : 2/16, discrim_real_loss=0.719, discrim_fake_loss=0.574 gan_loss=1.038\n",
            ">Epoch :32, Batch : 3/16, discrim_real_loss=0.661, discrim_fake_loss=0.680 gan_loss=1.052\n",
            ">Epoch :32, Batch : 4/16, discrim_real_loss=0.674, discrim_fake_loss=0.620 gan_loss=1.100\n",
            ">Epoch :32, Batch : 5/16, discrim_real_loss=0.607, discrim_fake_loss=0.596 gan_loss=1.115\n",
            ">Epoch :32, Batch : 6/16, discrim_real_loss=0.638, discrim_fake_loss=0.632 gan_loss=1.092\n",
            ">Epoch :32, Batch : 7/16, discrim_real_loss=0.658, discrim_fake_loss=0.702 gan_loss=1.079\n",
            ">Epoch :32, Batch : 8/16, discrim_real_loss=0.647, discrim_fake_loss=0.642 gan_loss=1.061\n",
            ">Epoch :32, Batch : 9/16, discrim_real_loss=0.712, discrim_fake_loss=0.683 gan_loss=1.008\n",
            ">Epoch :32, Batch : 10/16, discrim_real_loss=0.766, discrim_fake_loss=0.796 gan_loss=1.052\n",
            ">Epoch :32, Batch : 11/16, discrim_real_loss=0.809, discrim_fake_loss=0.623 gan_loss=1.158\n",
            ">Epoch :32, Batch : 12/16, discrim_real_loss=0.818, discrim_fake_loss=0.593 gan_loss=1.188\n",
            ">Epoch :32, Batch : 13/16, discrim_real_loss=0.776, discrim_fake_loss=0.674 gan_loss=1.102\n",
            ">Epoch :32, Batch : 14/16, discrim_real_loss=0.704, discrim_fake_loss=0.684 gan_loss=1.010\n",
            ">Epoch :32, Batch : 15/16, discrim_real_loss=0.721, discrim_fake_loss=0.658 gan_loss=0.976\n",
            ">Epoch :32, Batch : 16/16, discrim_real_loss=0.707, discrim_fake_loss=0.661 gan_loss=0.962\n",
            ">Epoch :33, Batch : 1/16, discrim_real_loss=0.715, discrim_fake_loss=0.706 gan_loss=0.963\n",
            ">Epoch :33, Batch : 2/16, discrim_real_loss=0.684, discrim_fake_loss=0.679 gan_loss=0.964\n",
            ">Epoch :33, Batch : 3/16, discrim_real_loss=0.656, discrim_fake_loss=0.624 gan_loss=1.019\n",
            ">Epoch :33, Batch : 4/16, discrim_real_loss=0.681, discrim_fake_loss=0.627 gan_loss=1.031\n",
            ">Epoch :33, Batch : 5/16, discrim_real_loss=0.630, discrim_fake_loss=0.585 gan_loss=1.083\n",
            ">Epoch :33, Batch : 6/16, discrim_real_loss=0.657, discrim_fake_loss=0.581 gan_loss=1.113\n",
            ">Epoch :33, Batch : 7/16, discrim_real_loss=0.647, discrim_fake_loss=0.550 gan_loss=1.120\n",
            ">Epoch :33, Batch : 8/16, discrim_real_loss=0.623, discrim_fake_loss=0.562 gan_loss=1.105\n",
            ">Epoch :33, Batch : 9/16, discrim_real_loss=0.627, discrim_fake_loss=0.584 gan_loss=1.103\n",
            ">Epoch :33, Batch : 10/16, discrim_real_loss=0.604, discrim_fake_loss=0.571 gan_loss=1.098\n",
            ">Epoch :33, Batch : 11/16, discrim_real_loss=0.563, discrim_fake_loss=0.600 gan_loss=1.116\n",
            ">Epoch :33, Batch : 12/16, discrim_real_loss=0.606, discrim_fake_loss=0.634 gan_loss=1.088\n",
            ">Epoch :33, Batch : 13/16, discrim_real_loss=0.610, discrim_fake_loss=0.626 gan_loss=1.089\n",
            ">Epoch :33, Batch : 14/16, discrim_real_loss=0.639, discrim_fake_loss=0.664 gan_loss=1.067\n",
            ">Epoch :33, Batch : 15/16, discrim_real_loss=0.602, discrim_fake_loss=0.655 gan_loss=1.090\n",
            ">Epoch :33, Batch : 16/16, discrim_real_loss=0.631, discrim_fake_loss=0.637 gan_loss=1.045\n",
            ">Epoch :34, Batch : 1/16, discrim_real_loss=0.673, discrim_fake_loss=0.641 gan_loss=1.055\n",
            ">Epoch :34, Batch : 2/16, discrim_real_loss=0.643, discrim_fake_loss=0.702 gan_loss=1.093\n",
            ">Epoch :34, Batch : 3/16, discrim_real_loss=0.640, discrim_fake_loss=0.624 gan_loss=1.143\n",
            ">Epoch :34, Batch : 4/16, discrim_real_loss=0.659, discrim_fake_loss=0.599 gan_loss=1.125\n",
            ">Epoch :34, Batch : 5/16, discrim_real_loss=0.687, discrim_fake_loss=0.613 gan_loss=1.052\n",
            ">Epoch :34, Batch : 6/16, discrim_real_loss=0.647, discrim_fake_loss=0.635 gan_loss=1.024\n",
            ">Epoch :34, Batch : 7/16, discrim_real_loss=0.610, discrim_fake_loss=0.598 gan_loss=1.028\n",
            ">Epoch :34, Batch : 8/16, discrim_real_loss=0.544, discrim_fake_loss=0.602 gan_loss=0.980\n",
            ">Epoch :34, Batch : 9/16, discrim_real_loss=0.580, discrim_fake_loss=0.651 gan_loss=1.005\n",
            ">Epoch :34, Batch : 10/16, discrim_real_loss=0.545, discrim_fake_loss=0.632 gan_loss=1.018\n",
            ">Epoch :34, Batch : 11/16, discrim_real_loss=0.500, discrim_fake_loss=0.638 gan_loss=1.036\n",
            ">Epoch :34, Batch : 12/16, discrim_real_loss=0.532, discrim_fake_loss=0.655 gan_loss=1.032\n",
            ">Epoch :34, Batch : 13/16, discrim_real_loss=0.541, discrim_fake_loss=0.647 gan_loss=1.029\n",
            ">Epoch :34, Batch : 14/16, discrim_real_loss=0.509, discrim_fake_loss=0.682 gan_loss=1.078\n",
            ">Epoch :34, Batch : 15/16, discrim_real_loss=0.593, discrim_fake_loss=0.662 gan_loss=1.203\n",
            ">Epoch :34, Batch : 16/16, discrim_real_loss=0.558, discrim_fake_loss=0.564 gan_loss=1.301\n",
            ">Epoch :35, Batch : 1/16, discrim_real_loss=0.602, discrim_fake_loss=0.503 gan_loss=1.370\n",
            ">Epoch :35, Batch : 2/16, discrim_real_loss=0.586, discrim_fake_loss=0.676 gan_loss=1.334\n",
            ">Epoch :35, Batch : 3/16, discrim_real_loss=0.580, discrim_fake_loss=0.609 gan_loss=1.301\n",
            ">Epoch :35, Batch : 4/16, discrim_real_loss=0.613, discrim_fake_loss=0.563 gan_loss=1.232\n",
            ">Epoch :35, Batch : 5/16, discrim_real_loss=0.574, discrim_fake_loss=0.770 gan_loss=1.279\n",
            ">Epoch :35, Batch : 6/16, discrim_real_loss=0.718, discrim_fake_loss=0.549 gan_loss=1.260\n",
            ">Epoch :35, Batch : 7/16, discrim_real_loss=0.734, discrim_fake_loss=0.630 gan_loss=1.249\n",
            ">Epoch :35, Batch : 8/16, discrim_real_loss=0.682, discrim_fake_loss=0.612 gan_loss=1.180\n",
            ">Epoch :35, Batch : 9/16, discrim_real_loss=0.636, discrim_fake_loss=0.709 gan_loss=1.163\n",
            ">Epoch :35, Batch : 10/16, discrim_real_loss=0.709, discrim_fake_loss=0.629 gan_loss=1.127\n",
            ">Epoch :35, Batch : 11/16, discrim_real_loss=0.661, discrim_fake_loss=0.726 gan_loss=1.083\n",
            ">Epoch :35, Batch : 12/16, discrim_real_loss=0.774, discrim_fake_loss=0.712 gan_loss=1.034\n",
            ">Epoch :35, Batch : 13/16, discrim_real_loss=0.738, discrim_fake_loss=0.723 gan_loss=1.014\n",
            ">Epoch :35, Batch : 14/16, discrim_real_loss=0.775, discrim_fake_loss=0.697 gan_loss=1.059\n",
            ">Epoch :35, Batch : 15/16, discrim_real_loss=0.705, discrim_fake_loss=0.677 gan_loss=1.075\n",
            ">Epoch :35, Batch : 16/16, discrim_real_loss=0.675, discrim_fake_loss=0.622 gan_loss=1.156\n",
            ">Epoch :36, Batch : 1/16, discrim_real_loss=0.686, discrim_fake_loss=0.573 gan_loss=1.141\n",
            ">Epoch :36, Batch : 2/16, discrim_real_loss=0.720, discrim_fake_loss=0.620 gan_loss=1.078\n",
            ">Epoch :36, Batch : 3/16, discrim_real_loss=0.609, discrim_fake_loss=0.645 gan_loss=1.094\n",
            ">Epoch :36, Batch : 4/16, discrim_real_loss=0.622, discrim_fake_loss=0.616 gan_loss=1.106\n",
            ">Epoch :36, Batch : 5/16, discrim_real_loss=0.632, discrim_fake_loss=0.571 gan_loss=1.107\n",
            ">Epoch :36, Batch : 6/16, discrim_real_loss=0.608, discrim_fake_loss=0.671 gan_loss=1.145\n",
            ">Epoch :36, Batch : 7/16, discrim_real_loss=0.672, discrim_fake_loss=0.547 gan_loss=1.152\n",
            ">Epoch :36, Batch : 8/16, discrim_real_loss=0.652, discrim_fake_loss=0.589 gan_loss=1.133\n",
            ">Epoch :36, Batch : 9/16, discrim_real_loss=0.653, discrim_fake_loss=0.609 gan_loss=1.126\n",
            ">Epoch :36, Batch : 10/16, discrim_real_loss=0.666, discrim_fake_loss=0.557 gan_loss=1.070\n",
            ">Epoch :36, Batch : 11/16, discrim_real_loss=0.671, discrim_fake_loss=0.640 gan_loss=1.017\n",
            ">Epoch :36, Batch : 12/16, discrim_real_loss=0.592, discrim_fake_loss=0.602 gan_loss=1.012\n",
            ">Epoch :36, Batch : 13/16, discrim_real_loss=0.624, discrim_fake_loss=0.653 gan_loss=1.048\n",
            ">Epoch :36, Batch : 14/16, discrim_real_loss=0.585, discrim_fake_loss=0.632 gan_loss=1.054\n",
            ">Epoch :36, Batch : 15/16, discrim_real_loss=0.564, discrim_fake_loss=0.670 gan_loss=1.225\n",
            ">Epoch :36, Batch : 16/16, discrim_real_loss=0.579, discrim_fake_loss=0.592 gan_loss=1.229\n",
            ">Epoch :37, Batch : 1/16, discrim_real_loss=0.550, discrim_fake_loss=0.625 gan_loss=1.430\n",
            ">Epoch :37, Batch : 2/16, discrim_real_loss=0.601, discrim_fake_loss=0.687 gan_loss=1.306\n",
            ">Epoch :37, Batch : 3/16, discrim_real_loss=0.709, discrim_fake_loss=0.555 gan_loss=1.114\n",
            ">Epoch :37, Batch : 4/16, discrim_real_loss=0.643, discrim_fake_loss=0.566 gan_loss=1.032\n",
            ">Epoch :37, Batch : 5/16, discrim_real_loss=0.632, discrim_fake_loss=0.570 gan_loss=1.030\n",
            ">Epoch :37, Batch : 6/16, discrim_real_loss=0.615, discrim_fake_loss=0.575 gan_loss=1.033\n",
            ">Epoch :37, Batch : 7/16, discrim_real_loss=0.535, discrim_fake_loss=0.563 gan_loss=1.060\n",
            ">Epoch :37, Batch : 8/16, discrim_real_loss=0.562, discrim_fake_loss=0.594 gan_loss=1.068\n",
            ">Epoch :37, Batch : 9/16, discrim_real_loss=0.554, discrim_fake_loss=0.609 gan_loss=1.062\n",
            ">Epoch :37, Batch : 10/16, discrim_real_loss=0.556, discrim_fake_loss=0.700 gan_loss=1.081\n",
            ">Epoch :37, Batch : 11/16, discrim_real_loss=0.634, discrim_fake_loss=0.694 gan_loss=1.069\n",
            ">Epoch :37, Batch : 12/16, discrim_real_loss=0.653, discrim_fake_loss=0.645 gan_loss=1.076\n",
            ">Epoch :37, Batch : 13/16, discrim_real_loss=0.650, discrim_fake_loss=0.658 gan_loss=1.080\n",
            ">Epoch :37, Batch : 14/16, discrim_real_loss=0.582, discrim_fake_loss=0.723 gan_loss=1.158\n",
            ">Epoch :37, Batch : 15/16, discrim_real_loss=0.614, discrim_fake_loss=0.558 gan_loss=1.241\n",
            ">Epoch :37, Batch : 16/16, discrim_real_loss=0.597, discrim_fake_loss=0.677 gan_loss=1.219\n",
            ">Epoch :38, Batch : 1/16, discrim_real_loss=0.562, discrim_fake_loss=0.770 gan_loss=1.204\n",
            ">Epoch :38, Batch : 2/16, discrim_real_loss=0.638, discrim_fake_loss=0.715 gan_loss=1.201\n",
            ">Epoch :38, Batch : 3/16, discrim_real_loss=0.722, discrim_fake_loss=0.726 gan_loss=1.166\n",
            ">Epoch :38, Batch : 4/16, discrim_real_loss=0.752, discrim_fake_loss=0.590 gan_loss=1.314\n",
            ">Epoch :38, Batch : 5/16, discrim_real_loss=0.690, discrim_fake_loss=0.611 gan_loss=1.486\n",
            ">Epoch :38, Batch : 6/16, discrim_real_loss=0.716, discrim_fake_loss=0.527 gan_loss=1.356\n",
            ">Epoch :38, Batch : 7/16, discrim_real_loss=0.732, discrim_fake_loss=0.758 gan_loss=1.241\n",
            ">Epoch :38, Batch : 8/16, discrim_real_loss=0.812, discrim_fake_loss=0.546 gan_loss=1.189\n",
            ">Epoch :38, Batch : 9/16, discrim_real_loss=0.816, discrim_fake_loss=0.552 gan_loss=1.093\n",
            ">Epoch :38, Batch : 10/16, discrim_real_loss=0.733, discrim_fake_loss=0.570 gan_loss=1.058\n",
            ">Epoch :38, Batch : 11/16, discrim_real_loss=0.697, discrim_fake_loss=0.567 gan_loss=1.066\n",
            ">Epoch :38, Batch : 12/16, discrim_real_loss=0.629, discrim_fake_loss=0.543 gan_loss=1.068\n",
            ">Epoch :38, Batch : 13/16, discrim_real_loss=0.631, discrim_fake_loss=0.627 gan_loss=1.027\n",
            ">Epoch :38, Batch : 14/16, discrim_real_loss=0.580, discrim_fake_loss=0.625 gan_loss=1.043\n",
            ">Epoch :38, Batch : 15/16, discrim_real_loss=0.599, discrim_fake_loss=0.622 gan_loss=1.058\n",
            ">Epoch :38, Batch : 16/16, discrim_real_loss=0.657, discrim_fake_loss=0.600 gan_loss=1.036\n",
            ">Epoch :39, Batch : 1/16, discrim_real_loss=0.593, discrim_fake_loss=0.607 gan_loss=1.031\n",
            ">Epoch :39, Batch : 2/16, discrim_real_loss=0.575, discrim_fake_loss=0.621 gan_loss=1.090\n",
            ">Epoch :39, Batch : 3/16, discrim_real_loss=0.580, discrim_fake_loss=0.542 gan_loss=1.170\n",
            ">Epoch :39, Batch : 4/16, discrim_real_loss=0.565, discrim_fake_loss=0.498 gan_loss=1.186\n",
            ">Epoch :39, Batch : 5/16, discrim_real_loss=0.478, discrim_fake_loss=0.594 gan_loss=1.150\n",
            ">Epoch :39, Batch : 6/16, discrim_real_loss=0.462, discrim_fake_loss=0.683 gan_loss=1.196\n",
            ">Epoch :39, Batch : 7/16, discrim_real_loss=0.591, discrim_fake_loss=0.707 gan_loss=1.230\n",
            ">Epoch :39, Batch : 8/16, discrim_real_loss=0.704, discrim_fake_loss=0.659 gan_loss=1.304\n",
            ">Epoch :39, Batch : 9/16, discrim_real_loss=0.859, discrim_fake_loss=0.596 gan_loss=1.305\n",
            ">Epoch :39, Batch : 10/16, discrim_real_loss=0.804, discrim_fake_loss=0.571 gan_loss=1.321\n",
            ">Epoch :39, Batch : 11/16, discrim_real_loss=0.773, discrim_fake_loss=0.534 gan_loss=1.326\n",
            ">Epoch :39, Batch : 12/16, discrim_real_loss=0.721, discrim_fake_loss=0.521 gan_loss=1.322\n",
            ">Epoch :39, Batch : 13/16, discrim_real_loss=0.636, discrim_fake_loss=0.552 gan_loss=1.308\n",
            ">Epoch :39, Batch : 14/16, discrim_real_loss=0.574, discrim_fake_loss=0.537 gan_loss=1.251\n",
            ">Epoch :39, Batch : 15/16, discrim_real_loss=0.554, discrim_fake_loss=0.704 gan_loss=1.264\n",
            ">Epoch :39, Batch : 16/16, discrim_real_loss=0.558, discrim_fake_loss=0.640 gan_loss=1.311\n",
            ">Epoch :40, Batch : 1/16, discrim_real_loss=0.708, discrim_fake_loss=0.630 gan_loss=1.195\n",
            ">Epoch :40, Batch : 2/16, discrim_real_loss=0.760, discrim_fake_loss=0.575 gan_loss=1.156\n",
            ">Epoch :40, Batch : 3/16, discrim_real_loss=0.676, discrim_fake_loss=0.564 gan_loss=1.140\n",
            ">Epoch :40, Batch : 4/16, discrim_real_loss=0.606, discrim_fake_loss=0.517 gan_loss=1.214\n",
            ">Epoch :40, Batch : 5/16, discrim_real_loss=0.496, discrim_fake_loss=0.562 gan_loss=1.290\n",
            ">Epoch :40, Batch : 6/16, discrim_real_loss=0.540, discrim_fake_loss=0.482 gan_loss=1.301\n",
            ">Epoch :40, Batch : 7/16, discrim_real_loss=0.539, discrim_fake_loss=0.572 gan_loss=1.287\n",
            ">Epoch :40, Batch : 8/16, discrim_real_loss=0.585, discrim_fake_loss=0.627 gan_loss=1.259\n",
            ">Epoch :40, Batch : 9/16, discrim_real_loss=0.626, discrim_fake_loss=0.582 gan_loss=1.192\n",
            ">Epoch :40, Batch : 10/16, discrim_real_loss=0.623, discrim_fake_loss=0.614 gan_loss=1.204\n",
            ">Epoch :40, Batch : 11/16, discrim_real_loss=0.640, discrim_fake_loss=0.573 gan_loss=1.261\n",
            ">Epoch :40, Batch : 12/16, discrim_real_loss=0.668, discrim_fake_loss=0.535 gan_loss=1.383\n",
            ">Epoch :40, Batch : 13/16, discrim_real_loss=0.659, discrim_fake_loss=0.510 gan_loss=1.471\n",
            ">Epoch :40, Batch : 14/16, discrim_real_loss=0.684, discrim_fake_loss=0.536 gan_loss=1.338\n",
            ">Epoch :40, Batch : 15/16, discrim_real_loss=0.661, discrim_fake_loss=0.627 gan_loss=1.190\n",
            ">Epoch :40, Batch : 16/16, discrim_real_loss=0.671, discrim_fake_loss=0.749 gan_loss=1.070\n",
            ">Accuracy real: 39%, fake: 46%\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "application/javascript": [
              "\n",
              "    async function download(id, filename, size) {\n",
              "      if (!google.colab.kernel.accessAllowed) {\n",
              "        return;\n",
              "      }\n",
              "      const div = document.createElement('div');\n",
              "      const label = document.createElement('label');\n",
              "      label.textContent = `Downloading \"${filename}\": `;\n",
              "      div.appendChild(label);\n",
              "      const progress = document.createElement('progress');\n",
              "      progress.max = size;\n",
              "      div.appendChild(progress);\n",
              "      document.body.appendChild(div);\n",
              "\n",
              "      const buffers = [];\n",
              "      let downloaded = 0;\n",
              "\n",
              "      const channel = await google.colab.kernel.comms.open(id);\n",
              "      // Send a message to notify the kernel that we're ready.\n",
              "      channel.send({})\n",
              "\n",
              "      for await (const message of channel.messages) {\n",
              "        // Send a message to notify the kernel that we're ready.\n",
              "        channel.send({})\n",
              "        if (message.buffers) {\n",
              "          for (const buffer of message.buffers) {\n",
              "            buffers.push(buffer);\n",
              "            downloaded += buffer.byteLength;\n",
              "            progress.value = downloaded;\n",
              "          }\n",
              "        }\n",
              "      }\n",
              "      const blob = new Blob(buffers, {type: 'application/binary'});\n",
              "      const a = document.createElement('a');\n",
              "      a.href = window.URL.createObjectURL(blob);\n",
              "      a.download = filename;\n",
              "      div.appendChild(a);\n",
              "      a.click();\n",
              "      div.remove();\n",
              "    }\n",
              "  "
            ],
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "application/javascript": [
              "download(\"download_b80aa8b7-b0e4-41bc-b98b-205d96860f03\", \"generated_plot_e040.png\", 6027729)"
            ],
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "application/javascript": [
              "\n",
              "    async function download(id, filename, size) {\n",
              "      if (!google.colab.kernel.accessAllowed) {\n",
              "        return;\n",
              "      }\n",
              "      const div = document.createElement('div');\n",
              "      const label = document.createElement('label');\n",
              "      label.textContent = `Downloading \"${filename}\": `;\n",
              "      div.appendChild(label);\n",
              "      const progress = document.createElement('progress');\n",
              "      progress.max = size;\n",
              "      div.appendChild(progress);\n",
              "      document.body.appendChild(div);\n",
              "\n",
              "      const buffers = [];\n",
              "      let downloaded = 0;\n",
              "\n",
              "      const channel = await google.colab.kernel.comms.open(id);\n",
              "      // Send a message to notify the kernel that we're ready.\n",
              "      channel.send({})\n",
              "\n",
              "      for await (const message of channel.messages) {\n",
              "        // Send a message to notify the kernel that we're ready.\n",
              "        channel.send({})\n",
              "        if (message.buffers) {\n",
              "          for (const buffer of message.buffers) {\n",
              "            buffers.push(buffer);\n",
              "            downloaded += buffer.byteLength;\n",
              "            progress.value = downloaded;\n",
              "          }\n",
              "        }\n",
              "      }\n",
              "      const blob = new Blob(buffers, {type: 'application/binary'});\n",
              "      const a = document.createElement('a');\n",
              "      a.href = window.URL.createObjectURL(blob);\n",
              "      a.download = filename;\n",
              "      div.appendChild(a);\n",
              "      a.click();\n",
              "      div.remove();\n",
              "    }\n",
              "  "
            ],
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "application/javascript": [
              "download(\"download_5df5b4e7-9fb0-4e6b-9ec7-ae805c71741a\", \"generator_model_040.h5\", 11913368)"
            ],
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            ">Epoch :41, Batch : 1/16, discrim_real_loss=0.781, discrim_fake_loss=0.797 gan_loss=0.931\n",
            ">Epoch :41, Batch : 2/16, discrim_real_loss=0.762, discrim_fake_loss=0.818 gan_loss=0.912\n",
            ">Epoch :41, Batch : 3/16, discrim_real_loss=0.629, discrim_fake_loss=0.743 gan_loss=0.941\n",
            ">Epoch :41, Batch : 4/16, discrim_real_loss=0.593, discrim_fake_loss=0.810 gan_loss=1.007\n",
            ">Epoch :41, Batch : 5/16, discrim_real_loss=0.538, discrim_fake_loss=0.893 gan_loss=1.185\n",
            ">Epoch :41, Batch : 6/16, discrim_real_loss=0.722, discrim_fake_loss=0.805 gan_loss=1.231\n",
            ">Epoch :41, Batch : 7/16, discrim_real_loss=0.880, discrim_fake_loss=0.758 gan_loss=1.230\n",
            ">Epoch :41, Batch : 8/16, discrim_real_loss=0.991, discrim_fake_loss=0.614 gan_loss=1.236\n",
            ">Epoch :41, Batch : 9/16, discrim_real_loss=0.986, discrim_fake_loss=0.519 gan_loss=1.226\n",
            ">Epoch :41, Batch : 10/16, discrim_real_loss=0.783, discrim_fake_loss=0.519 gan_loss=1.237\n",
            ">Epoch :41, Batch : 11/16, discrim_real_loss=0.696, discrim_fake_loss=0.500 gan_loss=1.303\n",
            ">Epoch :41, Batch : 12/16, discrim_real_loss=0.611, discrim_fake_loss=0.516 gan_loss=1.421\n",
            ">Epoch :41, Batch : 13/16, discrim_real_loss=0.607, discrim_fake_loss=0.534 gan_loss=1.382\n",
            ">Epoch :41, Batch : 14/16, discrim_real_loss=0.644, discrim_fake_loss=0.546 gan_loss=1.228\n",
            ">Epoch :41, Batch : 15/16, discrim_real_loss=0.672, discrim_fake_loss=0.661 gan_loss=1.091\n",
            ">Epoch :41, Batch : 16/16, discrim_real_loss=0.630, discrim_fake_loss=0.594 gan_loss=1.082\n",
            ">Epoch :42, Batch : 1/16, discrim_real_loss=0.613, discrim_fake_loss=0.593 gan_loss=1.057\n",
            ">Epoch :42, Batch : 2/16, discrim_real_loss=0.603, discrim_fake_loss=0.586 gan_loss=1.134\n",
            ">Epoch :42, Batch : 3/16, discrim_real_loss=0.518, discrim_fake_loss=0.544 gan_loss=1.225\n",
            ">Epoch :42, Batch : 4/16, discrim_real_loss=0.535, discrim_fake_loss=0.565 gan_loss=1.324\n",
            ">Epoch :42, Batch : 5/16, discrim_real_loss=0.495, discrim_fake_loss=0.606 gan_loss=1.292\n",
            ">Epoch :42, Batch : 6/16, discrim_real_loss=0.626, discrim_fake_loss=0.719 gan_loss=1.139\n",
            ">Epoch :42, Batch : 7/16, discrim_real_loss=0.607, discrim_fake_loss=0.726 gan_loss=1.095\n",
            ">Epoch :42, Batch : 8/16, discrim_real_loss=0.682, discrim_fake_loss=0.640 gan_loss=1.096\n",
            ">Epoch :42, Batch : 9/16, discrim_real_loss=0.603, discrim_fake_loss=0.640 gan_loss=1.209\n",
            ">Epoch :42, Batch : 10/16, discrim_real_loss=0.643, discrim_fake_loss=0.645 gan_loss=1.263\n",
            ">Epoch :42, Batch : 11/16, discrim_real_loss=0.682, discrim_fake_loss=0.617 gan_loss=1.206\n",
            ">Epoch :42, Batch : 12/16, discrim_real_loss=0.742, discrim_fake_loss=0.588 gan_loss=1.108\n",
            ">Epoch :42, Batch : 13/16, discrim_real_loss=0.707, discrim_fake_loss=0.614 gan_loss=1.041\n",
            ">Epoch :42, Batch : 14/16, discrim_real_loss=0.663, discrim_fake_loss=0.654 gan_loss=1.040\n",
            ">Epoch :42, Batch : 15/16, discrim_real_loss=0.643, discrim_fake_loss=0.615 gan_loss=1.063\n",
            ">Epoch :42, Batch : 16/16, discrim_real_loss=0.628, discrim_fake_loss=0.587 gan_loss=1.059\n",
            ">Epoch :43, Batch : 1/16, discrim_real_loss=0.641, discrim_fake_loss=0.571 gan_loss=1.055\n",
            ">Epoch :43, Batch : 2/16, discrim_real_loss=0.601, discrim_fake_loss=0.604 gan_loss=1.054\n",
            ">Epoch :43, Batch : 3/16, discrim_real_loss=0.598, discrim_fake_loss=0.606 gan_loss=1.059\n",
            ">Epoch :43, Batch : 4/16, discrim_real_loss=0.578, discrim_fake_loss=0.615 gan_loss=1.094\n",
            ">Epoch :43, Batch : 5/16, discrim_real_loss=0.645, discrim_fake_loss=0.571 gan_loss=1.137\n",
            ">Epoch :43, Batch : 6/16, discrim_real_loss=0.618, discrim_fake_loss=0.568 gan_loss=1.183\n",
            ">Epoch :43, Batch : 7/16, discrim_real_loss=0.588, discrim_fake_loss=0.504 gan_loss=1.247\n",
            ">Epoch :43, Batch : 8/16, discrim_real_loss=0.592, discrim_fake_loss=0.505 gan_loss=1.270\n",
            ">Epoch :43, Batch : 9/16, discrim_real_loss=0.544, discrim_fake_loss=0.571 gan_loss=1.369\n",
            ">Epoch :43, Batch : 10/16, discrim_real_loss=0.622, discrim_fake_loss=0.557 gan_loss=1.350\n",
            ">Epoch :43, Batch : 11/16, discrim_real_loss=0.585, discrim_fake_loss=0.605 gan_loss=1.303\n",
            ">Epoch :43, Batch : 12/16, discrim_real_loss=0.630, discrim_fake_loss=0.634 gan_loss=1.237\n",
            ">Epoch :43, Batch : 13/16, discrim_real_loss=0.645, discrim_fake_loss=0.755 gan_loss=1.240\n",
            ">Epoch :43, Batch : 14/16, discrim_real_loss=0.716, discrim_fake_loss=0.705 gan_loss=1.262\n",
            ">Epoch :43, Batch : 15/16, discrim_real_loss=0.751, discrim_fake_loss=0.567 gan_loss=1.303\n",
            ">Epoch :43, Batch : 16/16, discrim_real_loss=0.693, discrim_fake_loss=0.568 gan_loss=1.205\n",
            ">Epoch :44, Batch : 1/16, discrim_real_loss=0.642, discrim_fake_loss=0.649 gan_loss=1.188\n",
            ">Epoch :44, Batch : 2/16, discrim_real_loss=0.673, discrim_fake_loss=0.639 gan_loss=1.103\n",
            ">Epoch :44, Batch : 3/16, discrim_real_loss=0.670, discrim_fake_loss=0.661 gan_loss=1.083\n",
            ">Epoch :44, Batch : 4/16, discrim_real_loss=0.702, discrim_fake_loss=0.646 gan_loss=1.138\n",
            ">Epoch :44, Batch : 5/16, discrim_real_loss=0.672, discrim_fake_loss=0.622 gan_loss=1.127\n",
            ">Epoch :44, Batch : 6/16, discrim_real_loss=0.671, discrim_fake_loss=0.622 gan_loss=1.234\n",
            ">Epoch :44, Batch : 7/16, discrim_real_loss=0.713, discrim_fake_loss=0.716 gan_loss=1.234\n",
            ">Epoch :44, Batch : 8/16, discrim_real_loss=0.805, discrim_fake_loss=0.611 gan_loss=1.157\n",
            ">Epoch :44, Batch : 9/16, discrim_real_loss=0.785, discrim_fake_loss=0.697 gan_loss=1.107\n",
            ">Epoch :44, Batch : 10/16, discrim_real_loss=0.745, discrim_fake_loss=0.687 gan_loss=1.161\n",
            ">Epoch :44, Batch : 11/16, discrim_real_loss=0.744, discrim_fake_loss=0.539 gan_loss=1.156\n",
            ">Epoch :44, Batch : 12/16, discrim_real_loss=0.672, discrim_fake_loss=0.577 gan_loss=1.103\n",
            ">Epoch :44, Batch : 13/16, discrim_real_loss=0.664, discrim_fake_loss=0.655 gan_loss=1.015\n",
            ">Epoch :44, Batch : 14/16, discrim_real_loss=0.631, discrim_fake_loss=0.727 gan_loss=0.973\n",
            ">Epoch :44, Batch : 15/16, discrim_real_loss=0.651, discrim_fake_loss=0.759 gan_loss=0.979\n",
            ">Epoch :44, Batch : 16/16, discrim_real_loss=0.672, discrim_fake_loss=0.660 gan_loss=0.973\n",
            ">Epoch :45, Batch : 1/16, discrim_real_loss=0.641, discrim_fake_loss=0.686 gan_loss=0.996\n",
            ">Epoch :45, Batch : 2/16, discrim_real_loss=0.634, discrim_fake_loss=0.653 gan_loss=1.013\n",
            ">Epoch :45, Batch : 3/16, discrim_real_loss=0.654, discrim_fake_loss=0.655 gan_loss=1.044\n",
            ">Epoch :45, Batch : 4/16, discrim_real_loss=0.676, discrim_fake_loss=0.628 gan_loss=1.059\n",
            ">Epoch :45, Batch : 5/16, discrim_real_loss=0.639, discrim_fake_loss=0.671 gan_loss=1.088\n",
            ">Epoch :45, Batch : 6/16, discrim_real_loss=0.682, discrim_fake_loss=0.641 gan_loss=1.074\n",
            ">Epoch :45, Batch : 7/16, discrim_real_loss=0.706, discrim_fake_loss=0.642 gan_loss=1.015\n",
            ">Epoch :45, Batch : 8/16, discrim_real_loss=0.700, discrim_fake_loss=0.639 gan_loss=1.028\n",
            ">Epoch :45, Batch : 9/16, discrim_real_loss=0.714, discrim_fake_loss=0.642 gan_loss=0.962\n",
            ">Epoch :45, Batch : 10/16, discrim_real_loss=0.643, discrim_fake_loss=0.634 gan_loss=0.981\n",
            ">Epoch :45, Batch : 11/16, discrim_real_loss=0.639, discrim_fake_loss=0.602 gan_loss=0.984\n",
            ">Epoch :45, Batch : 12/16, discrim_real_loss=0.667, discrim_fake_loss=0.613 gan_loss=1.003\n",
            ">Epoch :45, Batch : 13/16, discrim_real_loss=0.649, discrim_fake_loss=0.609 gan_loss=1.008\n",
            ">Epoch :45, Batch : 14/16, discrim_real_loss=0.611, discrim_fake_loss=0.610 gan_loss=1.041\n",
            ">Epoch :45, Batch : 15/16, discrim_real_loss=0.605, discrim_fake_loss=0.593 gan_loss=1.034\n",
            ">Epoch :45, Batch : 16/16, discrim_real_loss=0.559, discrim_fake_loss=0.574 gan_loss=1.066\n",
            ">Epoch :46, Batch : 1/16, discrim_real_loss=0.620, discrim_fake_loss=0.584 gan_loss=1.083\n",
            ">Epoch :46, Batch : 2/16, discrim_real_loss=0.575, discrim_fake_loss=0.607 gan_loss=1.134\n",
            ">Epoch :46, Batch : 3/16, discrim_real_loss=0.662, discrim_fake_loss=0.545 gan_loss=1.166\n",
            ">Epoch :46, Batch : 4/16, discrim_real_loss=0.666, discrim_fake_loss=0.568 gan_loss=1.214\n",
            ">Epoch :46, Batch : 5/16, discrim_real_loss=0.612, discrim_fake_loss=0.526 gan_loss=1.234\n",
            ">Epoch :46, Batch : 6/16, discrim_real_loss=0.643, discrim_fake_loss=0.589 gan_loss=1.190\n",
            ">Epoch :46, Batch : 7/16, discrim_real_loss=0.586, discrim_fake_loss=0.679 gan_loss=1.231\n",
            ">Epoch :46, Batch : 8/16, discrim_real_loss=0.621, discrim_fake_loss=0.645 gan_loss=1.192\n",
            ">Epoch :46, Batch : 9/16, discrim_real_loss=0.704, discrim_fake_loss=0.644 gan_loss=1.256\n",
            ">Epoch :46, Batch : 10/16, discrim_real_loss=0.627, discrim_fake_loss=0.505 gan_loss=1.257\n",
            ">Epoch :46, Batch : 11/16, discrim_real_loss=0.634, discrim_fake_loss=0.494 gan_loss=1.223\n",
            ">Epoch :46, Batch : 12/16, discrim_real_loss=0.591, discrim_fake_loss=0.583 gan_loss=1.124\n",
            ">Epoch :46, Batch : 13/16, discrim_real_loss=0.572, discrim_fake_loss=0.616 gan_loss=1.013\n",
            ">Epoch :46, Batch : 14/16, discrim_real_loss=0.548, discrim_fake_loss=0.616 gan_loss=1.004\n",
            ">Epoch :46, Batch : 15/16, discrim_real_loss=0.556, discrim_fake_loss=0.576 gan_loss=1.017\n",
            ">Epoch :46, Batch : 16/16, discrim_real_loss=0.561, discrim_fake_loss=0.573 gan_loss=1.025\n",
            ">Epoch :47, Batch : 1/16, discrim_real_loss=0.560, discrim_fake_loss=0.555 gan_loss=1.079\n",
            ">Epoch :47, Batch : 2/16, discrim_real_loss=0.581, discrim_fake_loss=0.539 gan_loss=1.132\n",
            ">Epoch :47, Batch : 3/16, discrim_real_loss=0.555, discrim_fake_loss=0.510 gan_loss=1.141\n",
            ">Epoch :47, Batch : 4/16, discrim_real_loss=0.505, discrim_fake_loss=0.515 gan_loss=1.112\n",
            ">Epoch :47, Batch : 5/16, discrim_real_loss=0.522, discrim_fake_loss=0.562 gan_loss=1.146\n",
            ">Epoch :47, Batch : 6/16, discrim_real_loss=0.537, discrim_fake_loss=0.660 gan_loss=1.111\n",
            ">Epoch :47, Batch : 7/16, discrim_real_loss=0.564, discrim_fake_loss=0.594 gan_loss=1.155\n",
            ">Epoch :47, Batch : 8/16, discrim_real_loss=0.600, discrim_fake_loss=0.607 gan_loss=1.096\n",
            ">Epoch :47, Batch : 9/16, discrim_real_loss=0.659, discrim_fake_loss=0.586 gan_loss=1.179\n",
            ">Epoch :47, Batch : 10/16, discrim_real_loss=0.616, discrim_fake_loss=0.583 gan_loss=1.250\n",
            ">Epoch :47, Batch : 11/16, discrim_real_loss=0.685, discrim_fake_loss=0.517 gan_loss=1.268\n",
            ">Epoch :47, Batch : 12/16, discrim_real_loss=0.639, discrim_fake_loss=0.459 gan_loss=1.341\n",
            ">Epoch :47, Batch : 13/16, discrim_real_loss=0.589, discrim_fake_loss=0.464 gan_loss=1.341\n",
            ">Epoch :47, Batch : 14/16, discrim_real_loss=0.510, discrim_fake_loss=0.458 gan_loss=1.347\n",
            ">Epoch :47, Batch : 15/16, discrim_real_loss=0.540, discrim_fake_loss=0.466 gan_loss=1.239\n",
            ">Epoch :47, Batch : 16/16, discrim_real_loss=0.515, discrim_fake_loss=0.607 gan_loss=1.202\n",
            ">Epoch :48, Batch : 1/16, discrim_real_loss=0.468, discrim_fake_loss=0.589 gan_loss=1.237\n",
            ">Epoch :48, Batch : 2/16, discrim_real_loss=0.616, discrim_fake_loss=0.595 gan_loss=1.189\n",
            ">Epoch :48, Batch : 3/16, discrim_real_loss=0.640, discrim_fake_loss=0.651 gan_loss=1.170\n",
            ">Epoch :48, Batch : 4/16, discrim_real_loss=0.703, discrim_fake_loss=0.706 gan_loss=1.231\n",
            ">Epoch :48, Batch : 5/16, discrim_real_loss=0.723, discrim_fake_loss=0.623 gan_loss=1.222\n",
            ">Epoch :48, Batch : 6/16, discrim_real_loss=0.780, discrim_fake_loss=0.620 gan_loss=1.173\n",
            ">Epoch :48, Batch : 7/16, discrim_real_loss=0.670, discrim_fake_loss=0.613 gan_loss=1.206\n",
            ">Epoch :48, Batch : 8/16, discrim_real_loss=0.672, discrim_fake_loss=0.506 gan_loss=1.217\n",
            ">Epoch :48, Batch : 9/16, discrim_real_loss=0.647, discrim_fake_loss=0.544 gan_loss=1.160\n",
            ">Epoch :48, Batch : 10/16, discrim_real_loss=0.607, discrim_fake_loss=0.590 gan_loss=1.153\n",
            ">Epoch :48, Batch : 11/16, discrim_real_loss=0.616, discrim_fake_loss=0.578 gan_loss=1.063\n",
            ">Epoch :48, Batch : 12/16, discrim_real_loss=0.540, discrim_fake_loss=0.619 gan_loss=1.060\n",
            ">Epoch :48, Batch : 13/16, discrim_real_loss=0.531, discrim_fake_loss=0.581 gan_loss=1.172\n",
            ">Epoch :48, Batch : 14/16, discrim_real_loss=0.526, discrim_fake_loss=0.507 gan_loss=1.244\n",
            ">Epoch :48, Batch : 15/16, discrim_real_loss=0.482, discrim_fake_loss=0.580 gan_loss=1.286\n",
            ">Epoch :48, Batch : 16/16, discrim_real_loss=0.442, discrim_fake_loss=0.508 gan_loss=1.357\n",
            ">Epoch :49, Batch : 1/16, discrim_real_loss=0.487, discrim_fake_loss=0.528 gan_loss=1.328\n",
            ">Epoch :49, Batch : 2/16, discrim_real_loss=0.553, discrim_fake_loss=0.582 gan_loss=1.235\n",
            ">Epoch :49, Batch : 3/16, discrim_real_loss=0.534, discrim_fake_loss=0.577 gan_loss=1.252\n",
            ">Epoch :49, Batch : 4/16, discrim_real_loss=0.596, discrim_fake_loss=0.516 gan_loss=1.271\n",
            ">Epoch :49, Batch : 5/16, discrim_real_loss=0.533, discrim_fake_loss=0.550 gan_loss=1.232\n",
            ">Epoch :49, Batch : 6/16, discrim_real_loss=0.534, discrim_fake_loss=0.602 gan_loss=1.224\n",
            ">Epoch :49, Batch : 7/16, discrim_real_loss=0.571, discrim_fake_loss=0.620 gan_loss=1.267\n",
            ">Epoch :49, Batch : 8/16, discrim_real_loss=0.632, discrim_fake_loss=0.652 gan_loss=1.212\n",
            ">Epoch :49, Batch : 9/16, discrim_real_loss=0.676, discrim_fake_loss=0.655 gan_loss=1.151\n",
            ">Epoch :49, Batch : 10/16, discrim_real_loss=0.689, discrim_fake_loss=0.783 gan_loss=1.126\n",
            ">Epoch :49, Batch : 11/16, discrim_real_loss=0.724, discrim_fake_loss=0.723 gan_loss=1.098\n",
            ">Epoch :49, Batch : 12/16, discrim_real_loss=0.768, discrim_fake_loss=0.695 gan_loss=1.149\n",
            ">Epoch :49, Batch : 13/16, discrim_real_loss=0.695, discrim_fake_loss=0.666 gan_loss=1.150\n",
            ">Epoch :49, Batch : 14/16, discrim_real_loss=0.680, discrim_fake_loss=0.654 gan_loss=1.061\n",
            ">Epoch :49, Batch : 15/16, discrim_real_loss=0.643, discrim_fake_loss=0.644 gan_loss=1.123\n",
            ">Epoch :49, Batch : 16/16, discrim_real_loss=0.621, discrim_fake_loss=0.618 gan_loss=1.122\n",
            ">Epoch :50, Batch : 1/16, discrim_real_loss=0.604, discrim_fake_loss=0.603 gan_loss=1.134\n",
            ">Epoch :50, Batch : 2/16, discrim_real_loss=0.636, discrim_fake_loss=0.632 gan_loss=1.119\n",
            ">Epoch :50, Batch : 3/16, discrim_real_loss=0.655, discrim_fake_loss=0.616 gan_loss=1.098\n",
            ">Epoch :50, Batch : 4/16, discrim_real_loss=0.616, discrim_fake_loss=0.618 gan_loss=1.112\n",
            ">Epoch :50, Batch : 5/16, discrim_real_loss=0.599, discrim_fake_loss=0.621 gan_loss=1.188\n",
            ">Epoch :50, Batch : 6/16, discrim_real_loss=0.594, discrim_fake_loss=0.591 gan_loss=1.315\n",
            ">Epoch :50, Batch : 7/16, discrim_real_loss=0.582, discrim_fake_loss=0.518 gan_loss=1.410\n",
            ">Epoch :50, Batch : 8/16, discrim_real_loss=0.562, discrim_fake_loss=0.765 gan_loss=1.596\n",
            ">Epoch :50, Batch : 9/16, discrim_real_loss=0.724, discrim_fake_loss=0.386 gan_loss=1.435\n",
            ">Epoch :50, Batch : 10/16, discrim_real_loss=0.720, discrim_fake_loss=0.556 gan_loss=1.233\n",
            ">Epoch :50, Batch : 11/16, discrim_real_loss=0.645, discrim_fake_loss=0.697 gan_loss=1.250\n",
            ">Epoch :50, Batch : 12/16, discrim_real_loss=0.644, discrim_fake_loss=0.554 gan_loss=1.210\n",
            ">Epoch :50, Batch : 13/16, discrim_real_loss=0.588, discrim_fake_loss=0.573 gan_loss=1.177\n",
            ">Epoch :50, Batch : 14/16, discrim_real_loss=0.549, discrim_fake_loss=0.601 gan_loss=1.236\n",
            ">Epoch :50, Batch : 15/16, discrim_real_loss=0.572, discrim_fake_loss=0.598 gan_loss=1.294\n",
            ">Epoch :50, Batch : 16/16, discrim_real_loss=0.597, discrim_fake_loss=0.535 gan_loss=1.244\n",
            ">Accuracy real: 55%, fake: 92%\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "application/javascript": [
              "\n",
              "    async function download(id, filename, size) {\n",
              "      if (!google.colab.kernel.accessAllowed) {\n",
              "        return;\n",
              "      }\n",
              "      const div = document.createElement('div');\n",
              "      const label = document.createElement('label');\n",
              "      label.textContent = `Downloading \"${filename}\": `;\n",
              "      div.appendChild(label);\n",
              "      const progress = document.createElement('progress');\n",
              "      progress.max = size;\n",
              "      div.appendChild(progress);\n",
              "      document.body.appendChild(div);\n",
              "\n",
              "      const buffers = [];\n",
              "      let downloaded = 0;\n",
              "\n",
              "      const channel = await google.colab.kernel.comms.open(id);\n",
              "      // Send a message to notify the kernel that we're ready.\n",
              "      channel.send({})\n",
              "\n",
              "      for await (const message of channel.messages) {\n",
              "        // Send a message to notify the kernel that we're ready.\n",
              "        channel.send({})\n",
              "        if (message.buffers) {\n",
              "          for (const buffer of message.buffers) {\n",
              "            buffers.push(buffer);\n",
              "            downloaded += buffer.byteLength;\n",
              "            progress.value = downloaded;\n",
              "          }\n",
              "        }\n",
              "      }\n",
              "      const blob = new Blob(buffers, {type: 'application/binary'});\n",
              "      const a = document.createElement('a');\n",
              "      a.href = window.URL.createObjectURL(blob);\n",
              "      a.download = filename;\n",
              "      div.appendChild(a);\n",
              "      a.click();\n",
              "      div.remove();\n",
              "    }\n",
              "  "
            ],
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "application/javascript": [
              "download(\"download_8f482f83-1b97-4d6f-ada1-082bf0ccec9a\", \"generated_plot_e050.png\", 6053412)"
            ],
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "application/javascript": [
              "\n",
              "    async function download(id, filename, size) {\n",
              "      if (!google.colab.kernel.accessAllowed) {\n",
              "        return;\n",
              "      }\n",
              "      const div = document.createElement('div');\n",
              "      const label = document.createElement('label');\n",
              "      label.textContent = `Downloading \"${filename}\": `;\n",
              "      div.appendChild(label);\n",
              "      const progress = document.createElement('progress');\n",
              "      progress.max = size;\n",
              "      div.appendChild(progress);\n",
              "      document.body.appendChild(div);\n",
              "\n",
              "      const buffers = [];\n",
              "      let downloaded = 0;\n",
              "\n",
              "      const channel = await google.colab.kernel.comms.open(id);\n",
              "      // Send a message to notify the kernel that we're ready.\n",
              "      channel.send({})\n",
              "\n",
              "      for await (const message of channel.messages) {\n",
              "        // Send a message to notify the kernel that we're ready.\n",
              "        channel.send({})\n",
              "        if (message.buffers) {\n",
              "          for (const buffer of message.buffers) {\n",
              "            buffers.push(buffer);\n",
              "            downloaded += buffer.byteLength;\n",
              "            progress.value = downloaded;\n",
              "          }\n",
              "        }\n",
              "      }\n",
              "      const blob = new Blob(buffers, {type: 'application/binary'});\n",
              "      const a = document.createElement('a');\n",
              "      a.href = window.URL.createObjectURL(blob);\n",
              "      a.download = filename;\n",
              "      div.appendChild(a);\n",
              "      a.click();\n",
              "      div.remove();\n",
              "    }\n",
              "  "
            ],
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "application/javascript": [
              "download(\"download_acbfc2a0-1d51-406c-bee9-a0a3b44e0ce5\", \"generator_model_050.h5\", 11913368)"
            ],
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            ">Epoch :51, Batch : 1/16, discrim_real_loss=0.540, discrim_fake_loss=0.548 gan_loss=1.258\n",
            ">Epoch :51, Batch : 2/16, discrim_real_loss=0.644, discrim_fake_loss=0.629 gan_loss=1.323\n",
            ">Epoch :51, Batch : 3/16, discrim_real_loss=0.637, discrim_fake_loss=0.467 gan_loss=1.414\n",
            ">Epoch :51, Batch : 4/16, discrim_real_loss=0.633, discrim_fake_loss=0.501 gan_loss=1.426\n",
            ">Epoch :51, Batch : 5/16, discrim_real_loss=0.666, discrim_fake_loss=0.491 gan_loss=1.242\n",
            ">Epoch :51, Batch : 6/16, discrim_real_loss=0.606, discrim_fake_loss=0.652 gan_loss=1.150\n",
            ">Epoch :51, Batch : 7/16, discrim_real_loss=0.452, discrim_fake_loss=0.759 gan_loss=1.162\n",
            ">Epoch :51, Batch : 8/16, discrim_real_loss=0.621, discrim_fake_loss=0.681 gan_loss=1.210\n",
            ">Epoch :51, Batch : 9/16, discrim_real_loss=0.648, discrim_fake_loss=0.605 gan_loss=1.185\n",
            ">Epoch :51, Batch : 10/16, discrim_real_loss=0.629, discrim_fake_loss=0.678 gan_loss=1.145\n",
            ">Epoch :51, Batch : 11/16, discrim_real_loss=0.654, discrim_fake_loss=0.662 gan_loss=1.277\n",
            ">Epoch :51, Batch : 12/16, discrim_real_loss=0.564, discrim_fake_loss=0.501 gan_loss=1.389\n",
            ">Epoch :51, Batch : 13/16, discrim_real_loss=0.579, discrim_fake_loss=0.560 gan_loss=1.384\n",
            ">Epoch :51, Batch : 14/16, discrim_real_loss=0.624, discrim_fake_loss=0.632 gan_loss=1.338\n",
            ">Epoch :51, Batch : 15/16, discrim_real_loss=0.698, discrim_fake_loss=0.609 gan_loss=1.279\n",
            ">Epoch :51, Batch : 16/16, discrim_real_loss=0.699, discrim_fake_loss=0.600 gan_loss=1.197\n",
            ">Epoch :52, Batch : 1/16, discrim_real_loss=0.625, discrim_fake_loss=0.519 gan_loss=1.216\n",
            ">Epoch :52, Batch : 2/16, discrim_real_loss=0.620, discrim_fake_loss=0.508 gan_loss=1.225\n",
            ">Epoch :52, Batch : 3/16, discrim_real_loss=0.481, discrim_fake_loss=0.490 gan_loss=1.282\n",
            ">Epoch :52, Batch : 4/16, discrim_real_loss=0.468, discrim_fake_loss=0.529 gan_loss=1.273\n",
            ">Epoch :52, Batch : 5/16, discrim_real_loss=0.490, discrim_fake_loss=0.507 gan_loss=1.255\n",
            ">Epoch :52, Batch : 6/16, discrim_real_loss=0.526, discrim_fake_loss=0.700 gan_loss=1.224\n",
            ">Epoch :52, Batch : 7/16, discrim_real_loss=0.447, discrim_fake_loss=0.622 gan_loss=1.230\n",
            ">Epoch :52, Batch : 8/16, discrim_real_loss=0.631, discrim_fake_loss=0.621 gan_loss=1.184\n",
            ">Epoch :52, Batch : 9/16, discrim_real_loss=0.582, discrim_fake_loss=0.623 gan_loss=1.219\n",
            ">Epoch :52, Batch : 10/16, discrim_real_loss=0.415, discrim_fake_loss=0.607 gan_loss=1.417\n",
            ">Epoch :52, Batch : 11/16, discrim_real_loss=0.426, discrim_fake_loss=0.696 gan_loss=1.620\n",
            ">Epoch :52, Batch : 12/16, discrim_real_loss=0.545, discrim_fake_loss=0.772 gan_loss=1.675\n",
            ">Epoch :52, Batch : 13/16, discrim_real_loss=0.779, discrim_fake_loss=0.835 gan_loss=1.453\n",
            ">Epoch :52, Batch : 14/16, discrim_real_loss=0.882, discrim_fake_loss=0.661 gan_loss=1.440\n",
            ">Epoch :52, Batch : 15/16, discrim_real_loss=0.906, discrim_fake_loss=0.551 gan_loss=1.435\n",
            ">Epoch :52, Batch : 16/16, discrim_real_loss=0.704, discrim_fake_loss=0.484 gan_loss=1.442\n",
            ">Epoch :53, Batch : 1/16, discrim_real_loss=0.660, discrim_fake_loss=0.518 gan_loss=1.471\n",
            ">Epoch :53, Batch : 2/16, discrim_real_loss=0.649, discrim_fake_loss=0.496 gan_loss=1.434\n",
            ">Epoch :53, Batch : 3/16, discrim_real_loss=0.508, discrim_fake_loss=0.516 gan_loss=1.376\n",
            ">Epoch :53, Batch : 4/16, discrim_real_loss=0.684, discrim_fake_loss=0.524 gan_loss=1.300\n",
            ">Epoch :53, Batch : 5/16, discrim_real_loss=0.566, discrim_fake_loss=0.543 gan_loss=1.282\n",
            ">Epoch :53, Batch : 6/16, discrim_real_loss=0.501, discrim_fake_loss=0.571 gan_loss=1.386\n",
            ">Epoch :53, Batch : 7/16, discrim_real_loss=0.609, discrim_fake_loss=0.697 gan_loss=1.341\n",
            ">Epoch :53, Batch : 8/16, discrim_real_loss=0.652, discrim_fake_loss=0.838 gan_loss=1.453\n",
            ">Epoch :53, Batch : 9/16, discrim_real_loss=0.800, discrim_fake_loss=0.615 gan_loss=1.680\n",
            ">Epoch :53, Batch : 10/16, discrim_real_loss=0.765, discrim_fake_loss=0.515 gan_loss=1.511\n",
            ">Epoch :53, Batch : 11/16, discrim_real_loss=0.827, discrim_fake_loss=0.542 gan_loss=1.267\n",
            ">Epoch :53, Batch : 12/16, discrim_real_loss=0.720, discrim_fake_loss=0.648 gan_loss=1.286\n",
            ">Epoch :53, Batch : 13/16, discrim_real_loss=0.685, discrim_fake_loss=0.511 gan_loss=1.262\n",
            ">Epoch :53, Batch : 14/16, discrim_real_loss=0.611, discrim_fake_loss=0.555 gan_loss=1.292\n",
            ">Epoch :53, Batch : 15/16, discrim_real_loss=0.607, discrim_fake_loss=0.560 gan_loss=1.295\n",
            ">Epoch :53, Batch : 16/16, discrim_real_loss=0.667, discrim_fake_loss=0.571 gan_loss=1.286\n",
            ">Epoch :54, Batch : 1/16, discrim_real_loss=0.664, discrim_fake_loss=0.726 gan_loss=1.422\n",
            ">Epoch :54, Batch : 2/16, discrim_real_loss=0.816, discrim_fake_loss=0.494 gan_loss=1.413\n",
            ">Epoch :54, Batch : 3/16, discrim_real_loss=0.737, discrim_fake_loss=0.591 gan_loss=1.385\n",
            ">Epoch :54, Batch : 4/16, discrim_real_loss=0.776, discrim_fake_loss=0.588 gan_loss=1.345\n",
            ">Epoch :54, Batch : 5/16, discrim_real_loss=0.751, discrim_fake_loss=0.600 gan_loss=1.327\n",
            ">Epoch :54, Batch : 6/16, discrim_real_loss=0.725, discrim_fake_loss=0.586 gan_loss=1.320\n",
            ">Epoch :54, Batch : 7/16, discrim_real_loss=0.667, discrim_fake_loss=0.539 gan_loss=1.345\n",
            ">Epoch :54, Batch : 8/16, discrim_real_loss=0.630, discrim_fake_loss=0.521 gan_loss=1.379\n",
            ">Epoch :54, Batch : 9/16, discrim_real_loss=0.522, discrim_fake_loss=0.489 gan_loss=1.395\n",
            ">Epoch :54, Batch : 10/16, discrim_real_loss=0.523, discrim_fake_loss=0.538 gan_loss=1.354\n",
            ">Epoch :54, Batch : 11/16, discrim_real_loss=0.514, discrim_fake_loss=0.566 gan_loss=1.259\n",
            ">Epoch :54, Batch : 12/16, discrim_real_loss=0.468, discrim_fake_loss=0.665 gan_loss=1.288\n",
            ">Epoch :54, Batch : 13/16, discrim_real_loss=0.494, discrim_fake_loss=0.719 gan_loss=1.241\n",
            ">Epoch :54, Batch : 14/16, discrim_real_loss=0.540, discrim_fake_loss=0.819 gan_loss=1.416\n",
            ">Epoch :54, Batch : 15/16, discrim_real_loss=0.643, discrim_fake_loss=0.664 gan_loss=1.482\n",
            ">Epoch :54, Batch : 16/16, discrim_real_loss=0.546, discrim_fake_loss=0.747 gan_loss=1.508\n",
            ">Epoch :55, Batch : 1/16, discrim_real_loss=0.607, discrim_fake_loss=0.871 gan_loss=1.641\n",
            ">Epoch :55, Batch : 2/16, discrim_real_loss=0.863, discrim_fake_loss=0.662 gan_loss=1.449\n",
            ">Epoch :55, Batch : 3/16, discrim_real_loss=0.776, discrim_fake_loss=1.241 gan_loss=1.578\n",
            ">Epoch :55, Batch : 4/16, discrim_real_loss=1.139, discrim_fake_loss=0.590 gan_loss=1.428\n",
            ">Epoch :55, Batch : 5/16, discrim_real_loss=0.957, discrim_fake_loss=0.525 gan_loss=1.234\n",
            ">Epoch :55, Batch : 6/16, discrim_real_loss=0.768, discrim_fake_loss=0.672 gan_loss=1.126\n",
            ">Epoch :55, Batch : 7/16, discrim_real_loss=0.729, discrim_fake_loss=0.609 gan_loss=1.128\n",
            ">Epoch :55, Batch : 8/16, discrim_real_loss=0.683, discrim_fake_loss=0.599 gan_loss=1.118\n",
            ">Epoch :55, Batch : 9/16, discrim_real_loss=0.598, discrim_fake_loss=0.605 gan_loss=1.102\n",
            ">Epoch :55, Batch : 10/16, discrim_real_loss=0.622, discrim_fake_loss=0.627 gan_loss=1.114\n",
            ">Epoch :55, Batch : 11/16, discrim_real_loss=0.596, discrim_fake_loss=0.624 gan_loss=1.142\n",
            ">Epoch :55, Batch : 12/16, discrim_real_loss=0.543, discrim_fake_loss=0.569 gan_loss=1.147\n",
            ">Epoch :55, Batch : 13/16, discrim_real_loss=0.602, discrim_fake_loss=0.618 gan_loss=1.161\n",
            ">Epoch :55, Batch : 14/16, discrim_real_loss=0.604, discrim_fake_loss=0.625 gan_loss=1.161\n",
            ">Epoch :55, Batch : 15/16, discrim_real_loss=0.644, discrim_fake_loss=0.609 gan_loss=1.101\n",
            ">Epoch :55, Batch : 16/16, discrim_real_loss=0.621, discrim_fake_loss=0.625 gan_loss=1.121\n",
            ">Epoch :56, Batch : 1/16, discrim_real_loss=0.676, discrim_fake_loss=0.621 gan_loss=1.119\n",
            ">Epoch :56, Batch : 2/16, discrim_real_loss=0.593, discrim_fake_loss=0.623 gan_loss=1.123\n",
            ">Epoch :56, Batch : 3/16, discrim_real_loss=0.625, discrim_fake_loss=0.583 gan_loss=1.175\n",
            ">Epoch :56, Batch : 4/16, discrim_real_loss=0.585, discrim_fake_loss=0.535 gan_loss=1.212\n",
            ">Epoch :56, Batch : 5/16, discrim_real_loss=0.622, discrim_fake_loss=0.597 gan_loss=1.133\n",
            ">Epoch :56, Batch : 6/16, discrim_real_loss=0.584, discrim_fake_loss=0.633 gan_loss=1.164\n",
            ">Epoch :56, Batch : 7/16, discrim_real_loss=0.591, discrim_fake_loss=0.595 gan_loss=1.203\n",
            ">Epoch :56, Batch : 8/16, discrim_real_loss=0.606, discrim_fake_loss=0.589 gan_loss=1.239\n",
            ">Epoch :56, Batch : 9/16, discrim_real_loss=0.575, discrim_fake_loss=0.548 gan_loss=1.252\n",
            ">Epoch :56, Batch : 10/16, discrim_real_loss=0.637, discrim_fake_loss=0.543 gan_loss=1.268\n",
            ">Epoch :56, Batch : 11/16, discrim_real_loss=0.572, discrim_fake_loss=0.607 gan_loss=1.221\n",
            ">Epoch :56, Batch : 12/16, discrim_real_loss=0.561, discrim_fake_loss=0.630 gan_loss=1.274\n",
            ">Epoch :56, Batch : 13/16, discrim_real_loss=0.658, discrim_fake_loss=0.629 gan_loss=1.263\n",
            ">Epoch :56, Batch : 14/16, discrim_real_loss=0.665, discrim_fake_loss=0.702 gan_loss=1.245\n",
            ">Epoch :56, Batch : 15/16, discrim_real_loss=0.725, discrim_fake_loss=0.635 gan_loss=1.296\n",
            ">Epoch :56, Batch : 16/16, discrim_real_loss=0.681, discrim_fake_loss=0.541 gan_loss=1.284\n",
            ">Epoch :57, Batch : 1/16, discrim_real_loss=0.554, discrim_fake_loss=0.667 gan_loss=1.380\n",
            ">Epoch :57, Batch : 2/16, discrim_real_loss=0.630, discrim_fake_loss=0.447 gan_loss=1.429\n",
            ">Epoch :57, Batch : 3/16, discrim_real_loss=0.444, discrim_fake_loss=0.536 gan_loss=1.423\n",
            ">Epoch :57, Batch : 4/16, discrim_real_loss=0.474, discrim_fake_loss=0.557 gan_loss=1.483\n",
            ">Epoch :57, Batch : 5/16, discrim_real_loss=0.531, discrim_fake_loss=0.599 gan_loss=1.442\n",
            ">Epoch :57, Batch : 6/16, discrim_real_loss=0.544, discrim_fake_loss=0.587 gan_loss=1.428\n",
            ">Epoch :57, Batch : 7/16, discrim_real_loss=0.587, discrim_fake_loss=0.608 gan_loss=1.509\n",
            ">Epoch :57, Batch : 8/16, discrim_real_loss=0.728, discrim_fake_loss=0.494 gan_loss=1.591\n",
            ">Epoch :57, Batch : 9/16, discrim_real_loss=0.593, discrim_fake_loss=0.567 gan_loss=1.635\n",
            ">Epoch :57, Batch : 10/16, discrim_real_loss=0.549, discrim_fake_loss=0.564 gan_loss=1.591\n",
            ">Epoch :57, Batch : 11/16, discrim_real_loss=0.752, discrim_fake_loss=0.570 gan_loss=1.270\n",
            ">Epoch :57, Batch : 12/16, discrim_real_loss=0.676, discrim_fake_loss=0.638 gan_loss=1.167\n",
            ">Epoch :57, Batch : 13/16, discrim_real_loss=0.645, discrim_fake_loss=0.558 gan_loss=1.282\n",
            ">Epoch :57, Batch : 14/16, discrim_real_loss=0.531, discrim_fake_loss=0.498 gan_loss=1.375\n",
            ">Epoch :57, Batch : 15/16, discrim_real_loss=0.577, discrim_fake_loss=0.478 gan_loss=1.391\n",
            ">Epoch :57, Batch : 16/16, discrim_real_loss=0.483, discrim_fake_loss=0.554 gan_loss=1.375\n",
            ">Epoch :58, Batch : 1/16, discrim_real_loss=0.505, discrim_fake_loss=0.544 gan_loss=1.259\n",
            ">Epoch :58, Batch : 2/16, discrim_real_loss=0.594, discrim_fake_loss=0.646 gan_loss=1.164\n",
            ">Epoch :58, Batch : 3/16, discrim_real_loss=0.588, discrim_fake_loss=0.631 gan_loss=1.163\n",
            ">Epoch :58, Batch : 4/16, discrim_real_loss=0.536, discrim_fake_loss=0.557 gan_loss=1.259\n",
            ">Epoch :58, Batch : 5/16, discrim_real_loss=0.493, discrim_fake_loss=0.465 gan_loss=1.304\n",
            ">Epoch :58, Batch : 6/16, discrim_real_loss=0.517, discrim_fake_loss=0.561 gan_loss=1.304\n",
            ">Epoch :58, Batch : 7/16, discrim_real_loss=0.517, discrim_fake_loss=0.601 gan_loss=1.359\n",
            ">Epoch :58, Batch : 8/16, discrim_real_loss=0.489, discrim_fake_loss=0.596 gan_loss=1.413\n",
            ">Epoch :58, Batch : 9/16, discrim_real_loss=0.714, discrim_fake_loss=0.676 gan_loss=1.342\n",
            ">Epoch :58, Batch : 10/16, discrim_real_loss=0.874, discrim_fake_loss=0.673 gan_loss=1.307\n",
            ">Epoch :58, Batch : 11/16, discrim_real_loss=0.860, discrim_fake_loss=0.615 gan_loss=1.407\n",
            ">Epoch :58, Batch : 12/16, discrim_real_loss=0.886, discrim_fake_loss=0.589 gan_loss=1.502\n",
            ">Epoch :58, Batch : 13/16, discrim_real_loss=0.819, discrim_fake_loss=0.547 gan_loss=1.519\n",
            ">Epoch :58, Batch : 14/16, discrim_real_loss=0.787, discrim_fake_loss=0.469 gan_loss=1.485\n",
            ">Epoch :58, Batch : 15/16, discrim_real_loss=0.718, discrim_fake_loss=0.508 gan_loss=1.399\n",
            ">Epoch :58, Batch : 16/16, discrim_real_loss=0.648, discrim_fake_loss=0.577 gan_loss=1.300\n",
            ">Epoch :59, Batch : 1/16, discrim_real_loss=0.606, discrim_fake_loss=0.649 gan_loss=1.264\n",
            ">Epoch :59, Batch : 2/16, discrim_real_loss=0.630, discrim_fake_loss=0.676 gan_loss=1.270\n",
            ">Epoch :59, Batch : 3/16, discrim_real_loss=0.655, discrim_fake_loss=0.689 gan_loss=1.290\n",
            ">Epoch :59, Batch : 4/16, discrim_real_loss=0.766, discrim_fake_loss=0.668 gan_loss=1.169\n",
            ">Epoch :59, Batch : 5/16, discrim_real_loss=0.771, discrim_fake_loss=0.627 gan_loss=1.115\n",
            ">Epoch :59, Batch : 6/16, discrim_real_loss=0.770, discrim_fake_loss=0.617 gan_loss=1.084\n",
            ">Epoch :59, Batch : 7/16, discrim_real_loss=0.669, discrim_fake_loss=0.592 gan_loss=1.116\n",
            ">Epoch :59, Batch : 8/16, discrim_real_loss=0.638, discrim_fake_loss=0.587 gan_loss=1.140\n",
            ">Epoch :59, Batch : 9/16, discrim_real_loss=0.550, discrim_fake_loss=0.596 gan_loss=1.165\n",
            ">Epoch :59, Batch : 10/16, discrim_real_loss=0.609, discrim_fake_loss=0.625 gan_loss=1.211\n",
            ">Epoch :59, Batch : 11/16, discrim_real_loss=0.642, discrim_fake_loss=0.551 gan_loss=1.307\n",
            ">Epoch :59, Batch : 12/16, discrim_real_loss=0.597, discrim_fake_loss=0.469 gan_loss=1.402\n",
            ">Epoch :59, Batch : 13/16, discrim_real_loss=0.570, discrim_fake_loss=0.458 gan_loss=1.403\n",
            ">Epoch :59, Batch : 14/16, discrim_real_loss=0.533, discrim_fake_loss=0.527 gan_loss=1.296\n",
            ">Epoch :59, Batch : 15/16, discrim_real_loss=0.447, discrim_fake_loss=0.617 gan_loss=1.260\n",
            ">Epoch :59, Batch : 16/16, discrim_real_loss=0.500, discrim_fake_loss=0.714 gan_loss=1.264\n",
            ">Epoch :60, Batch : 1/16, discrim_real_loss=0.702, discrim_fake_loss=0.705 gan_loss=1.180\n",
            ">Epoch :60, Batch : 2/16, discrim_real_loss=0.703, discrim_fake_loss=0.804 gan_loss=1.222\n",
            ">Epoch :60, Batch : 3/16, discrim_real_loss=0.835, discrim_fake_loss=0.630 gan_loss=1.283\n",
            ">Epoch :60, Batch : 4/16, discrim_real_loss=0.815, discrim_fake_loss=0.577 gan_loss=1.321\n",
            ">Epoch :60, Batch : 5/16, discrim_real_loss=0.801, discrim_fake_loss=0.566 gan_loss=1.409\n",
            ">Epoch :60, Batch : 6/16, discrim_real_loss=0.802, discrim_fake_loss=0.504 gan_loss=1.301\n",
            ">Epoch :60, Batch : 7/16, discrim_real_loss=0.663, discrim_fake_loss=0.608 gan_loss=1.256\n",
            ">Epoch :60, Batch : 8/16, discrim_real_loss=0.684, discrim_fake_loss=0.616 gan_loss=1.209\n",
            ">Epoch :60, Batch : 9/16, discrim_real_loss=0.718, discrim_fake_loss=0.584 gan_loss=1.070\n",
            ">Epoch :60, Batch : 10/16, discrim_real_loss=0.678, discrim_fake_loss=0.641 gan_loss=1.039\n",
            ">Epoch :60, Batch : 11/16, discrim_real_loss=0.659, discrim_fake_loss=0.600 gan_loss=1.042\n",
            ">Epoch :60, Batch : 12/16, discrim_real_loss=0.584, discrim_fake_loss=0.557 gan_loss=1.087\n",
            ">Epoch :60, Batch : 13/16, discrim_real_loss=0.593, discrim_fake_loss=0.560 gan_loss=1.104\n",
            ">Epoch :60, Batch : 14/16, discrim_real_loss=0.613, discrim_fake_loss=0.565 gan_loss=1.097\n",
            ">Epoch :60, Batch : 15/16, discrim_real_loss=0.567, discrim_fake_loss=0.567 gan_loss=1.124\n",
            ">Epoch :60, Batch : 16/16, discrim_real_loss=0.585, discrim_fake_loss=0.604 gan_loss=1.205\n",
            ">Accuracy real: 62%, fake: 87%\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "application/javascript": [
              "\n",
              "    async function download(id, filename, size) {\n",
              "      if (!google.colab.kernel.accessAllowed) {\n",
              "        return;\n",
              "      }\n",
              "      const div = document.createElement('div');\n",
              "      const label = document.createElement('label');\n",
              "      label.textContent = `Downloading \"${filename}\": `;\n",
              "      div.appendChild(label);\n",
              "      const progress = document.createElement('progress');\n",
              "      progress.max = size;\n",
              "      div.appendChild(progress);\n",
              "      document.body.appendChild(div);\n",
              "\n",
              "      const buffers = [];\n",
              "      let downloaded = 0;\n",
              "\n",
              "      const channel = await google.colab.kernel.comms.open(id);\n",
              "      // Send a message to notify the kernel that we're ready.\n",
              "      channel.send({})\n",
              "\n",
              "      for await (const message of channel.messages) {\n",
              "        // Send a message to notify the kernel that we're ready.\n",
              "        channel.send({})\n",
              "        if (message.buffers) {\n",
              "          for (const buffer of message.buffers) {\n",
              "            buffers.push(buffer);\n",
              "            downloaded += buffer.byteLength;\n",
              "            progress.value = downloaded;\n",
              "          }\n",
              "        }\n",
              "      }\n",
              "      const blob = new Blob(buffers, {type: 'application/binary'});\n",
              "      const a = document.createElement('a');\n",
              "      a.href = window.URL.createObjectURL(blob);\n",
              "      a.download = filename;\n",
              "      div.appendChild(a);\n",
              "      a.click();\n",
              "      div.remove();\n",
              "    }\n",
              "  "
            ],
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "application/javascript": [
              "download(\"download_9365962a-37c2-4b4c-bd08-a946c37239b3\", \"generated_plot_e060.png\", 5880829)"
            ],
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "application/javascript": [
              "\n",
              "    async function download(id, filename, size) {\n",
              "      if (!google.colab.kernel.accessAllowed) {\n",
              "        return;\n",
              "      }\n",
              "      const div = document.createElement('div');\n",
              "      const label = document.createElement('label');\n",
              "      label.textContent = `Downloading \"${filename}\": `;\n",
              "      div.appendChild(label);\n",
              "      const progress = document.createElement('progress');\n",
              "      progress.max = size;\n",
              "      div.appendChild(progress);\n",
              "      document.body.appendChild(div);\n",
              "\n",
              "      const buffers = [];\n",
              "      let downloaded = 0;\n",
              "\n",
              "      const channel = await google.colab.kernel.comms.open(id);\n",
              "      // Send a message to notify the kernel that we're ready.\n",
              "      channel.send({})\n",
              "\n",
              "      for await (const message of channel.messages) {\n",
              "        // Send a message to notify the kernel that we're ready.\n",
              "        channel.send({})\n",
              "        if (message.buffers) {\n",
              "          for (const buffer of message.buffers) {\n",
              "            buffers.push(buffer);\n",
              "            downloaded += buffer.byteLength;\n",
              "            progress.value = downloaded;\n",
              "          }\n",
              "        }\n",
              "      }\n",
              "      const blob = new Blob(buffers, {type: 'application/binary'});\n",
              "      const a = document.createElement('a');\n",
              "      a.href = window.URL.createObjectURL(blob);\n",
              "      a.download = filename;\n",
              "      div.appendChild(a);\n",
              "      a.click();\n",
              "      div.remove();\n",
              "    }\n",
              "  "
            ],
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "application/javascript": [
              "download(\"download_8f034dc1-e79a-4bbe-b980-46e04d153968\", \"generator_model_060.h5\", 11913368)"
            ],
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            ">Epoch :61, Batch : 1/16, discrim_real_loss=0.545, discrim_fake_loss=0.584 gan_loss=1.194\n",
            ">Epoch :61, Batch : 2/16, discrim_real_loss=0.640, discrim_fake_loss=0.553 gan_loss=1.181\n",
            ">Epoch :61, Batch : 3/16, discrim_real_loss=0.664, discrim_fake_loss=0.614 gan_loss=1.179\n",
            ">Epoch :61, Batch : 4/16, discrim_real_loss=0.639, discrim_fake_loss=0.560 gan_loss=1.181\n",
            ">Epoch :61, Batch : 5/16, discrim_real_loss=0.648, discrim_fake_loss=0.591 gan_loss=1.145\n",
            ">Epoch :61, Batch : 6/16, discrim_real_loss=0.688, discrim_fake_loss=0.574 gan_loss=1.157\n",
            ">Epoch :61, Batch : 7/16, discrim_real_loss=0.654, discrim_fake_loss=0.571 gan_loss=1.190\n",
            ">Epoch :61, Batch : 8/16, discrim_real_loss=0.623, discrim_fake_loss=0.558 gan_loss=1.208\n",
            ">Epoch :61, Batch : 9/16, discrim_real_loss=0.591, discrim_fake_loss=0.665 gan_loss=1.212\n",
            ">Epoch :61, Batch : 10/16, discrim_real_loss=0.620, discrim_fake_loss=0.672 gan_loss=1.224\n",
            ">Epoch :61, Batch : 11/16, discrim_real_loss=0.695, discrim_fake_loss=0.658 gan_loss=1.133\n",
            ">Epoch :61, Batch : 12/16, discrim_real_loss=0.689, discrim_fake_loss=0.660 gan_loss=1.082\n",
            ">Epoch :61, Batch : 13/16, discrim_real_loss=0.715, discrim_fake_loss=0.599 gan_loss=1.088\n",
            ">Epoch :61, Batch : 14/16, discrim_real_loss=0.702, discrim_fake_loss=0.634 gan_loss=1.043\n",
            ">Epoch :61, Batch : 15/16, discrim_real_loss=0.652, discrim_fake_loss=0.610 gan_loss=1.092\n",
            ">Epoch :61, Batch : 16/16, discrim_real_loss=0.537, discrim_fake_loss=0.628 gan_loss=1.163\n",
            ">Epoch :62, Batch : 1/16, discrim_real_loss=0.566, discrim_fake_loss=0.583 gan_loss=1.184\n",
            ">Epoch :62, Batch : 2/16, discrim_real_loss=0.616, discrim_fake_loss=0.601 gan_loss=1.214\n",
            ">Epoch :62, Batch : 3/16, discrim_real_loss=0.700, discrim_fake_loss=0.601 gan_loss=1.187\n",
            ">Epoch :62, Batch : 4/16, discrim_real_loss=0.695, discrim_fake_loss=0.569 gan_loss=1.200\n",
            ">Epoch :62, Batch : 5/16, discrim_real_loss=0.637, discrim_fake_loss=0.541 gan_loss=1.224\n",
            ">Epoch :62, Batch : 6/16, discrim_real_loss=0.627, discrim_fake_loss=0.534 gan_loss=1.137\n",
            ">Epoch :62, Batch : 7/16, discrim_real_loss=0.569, discrim_fake_loss=0.586 gan_loss=1.134\n",
            ">Epoch :62, Batch : 8/16, discrim_real_loss=0.587, discrim_fake_loss=0.568 gan_loss=1.140\n",
            ">Epoch :62, Batch : 9/16, discrim_real_loss=0.592, discrim_fake_loss=0.582 gan_loss=1.157\n",
            ">Epoch :62, Batch : 10/16, discrim_real_loss=0.612, discrim_fake_loss=0.551 gan_loss=1.180\n",
            ">Epoch :62, Batch : 11/16, discrim_real_loss=0.539, discrim_fake_loss=0.523 gan_loss=1.218\n",
            ">Epoch :62, Batch : 12/16, discrim_real_loss=0.616, discrim_fake_loss=0.540 gan_loss=1.189\n",
            ">Epoch :62, Batch : 13/16, discrim_real_loss=0.544, discrim_fake_loss=0.597 gan_loss=1.246\n",
            ">Epoch :62, Batch : 14/16, discrim_real_loss=0.592, discrim_fake_loss=0.536 gan_loss=1.224\n",
            ">Epoch :62, Batch : 15/16, discrim_real_loss=0.540, discrim_fake_loss=0.565 gan_loss=1.288\n",
            ">Epoch :62, Batch : 16/16, discrim_real_loss=0.733, discrim_fake_loss=0.550 gan_loss=1.305\n",
            ">Epoch :63, Batch : 1/16, discrim_real_loss=0.654, discrim_fake_loss=0.562 gan_loss=1.322\n",
            ">Epoch :63, Batch : 2/16, discrim_real_loss=0.691, discrim_fake_loss=0.494 gan_loss=1.419\n",
            ">Epoch :63, Batch : 3/16, discrim_real_loss=0.667, discrim_fake_loss=0.481 gan_loss=1.400\n",
            ">Epoch :63, Batch : 4/16, discrim_real_loss=0.594, discrim_fake_loss=0.530 gan_loss=1.374\n",
            ">Epoch :63, Batch : 5/16, discrim_real_loss=0.596, discrim_fake_loss=0.623 gan_loss=1.203\n",
            ">Epoch :63, Batch : 6/16, discrim_real_loss=0.639, discrim_fake_loss=0.620 gan_loss=1.201\n",
            ">Epoch :63, Batch : 7/16, discrim_real_loss=0.598, discrim_fake_loss=0.609 gan_loss=1.153\n",
            ">Epoch :63, Batch : 8/16, discrim_real_loss=0.639, discrim_fake_loss=0.629 gan_loss=1.083\n",
            ">Epoch :63, Batch : 9/16, discrim_real_loss=0.562, discrim_fake_loss=0.643 gan_loss=1.117\n",
            ">Epoch :63, Batch : 10/16, discrim_real_loss=0.561, discrim_fake_loss=0.582 gan_loss=1.154\n",
            ">Epoch :63, Batch : 11/16, discrim_real_loss=0.569, discrim_fake_loss=0.612 gan_loss=1.196\n",
            ">Epoch :63, Batch : 12/16, discrim_real_loss=0.611, discrim_fake_loss=0.577 gan_loss=1.119\n",
            ">Epoch :63, Batch : 13/16, discrim_real_loss=0.581, discrim_fake_loss=0.623 gan_loss=1.059\n",
            ">Epoch :63, Batch : 14/16, discrim_real_loss=0.577, discrim_fake_loss=0.644 gan_loss=1.088\n",
            ">Epoch :63, Batch : 15/16, discrim_real_loss=0.570, discrim_fake_loss=0.610 gan_loss=1.196\n",
            ">Epoch :63, Batch : 16/16, discrim_real_loss=0.538, discrim_fake_loss=0.507 gan_loss=1.309\n",
            ">Epoch :64, Batch : 1/16, discrim_real_loss=0.550, discrim_fake_loss=0.489 gan_loss=1.439\n",
            ">Epoch :64, Batch : 2/16, discrim_real_loss=0.541, discrim_fake_loss=0.481 gan_loss=1.519\n",
            ">Epoch :64, Batch : 3/16, discrim_real_loss=0.506, discrim_fake_loss=0.516 gan_loss=1.441\n",
            ">Epoch :64, Batch : 4/16, discrim_real_loss=0.529, discrim_fake_loss=0.605 gan_loss=1.304\n",
            ">Epoch :64, Batch : 5/16, discrim_real_loss=0.592, discrim_fake_loss=0.815 gan_loss=1.393\n",
            ">Epoch :64, Batch : 6/16, discrim_real_loss=0.717, discrim_fake_loss=0.549 gan_loss=1.461\n",
            ">Epoch :64, Batch : 7/16, discrim_real_loss=0.645, discrim_fake_loss=0.520 gan_loss=1.470\n",
            ">Epoch :64, Batch : 8/16, discrim_real_loss=0.668, discrim_fake_loss=0.528 gan_loss=1.408\n",
            ">Epoch :64, Batch : 9/16, discrim_real_loss=0.583, discrim_fake_loss=0.620 gan_loss=1.319\n",
            ">Epoch :64, Batch : 10/16, discrim_real_loss=0.576, discrim_fake_loss=0.655 gan_loss=1.317\n",
            ">Epoch :64, Batch : 11/16, discrim_real_loss=0.655, discrim_fake_loss=0.597 gan_loss=1.313\n",
            ">Epoch :64, Batch : 12/16, discrim_real_loss=0.620, discrim_fake_loss=0.670 gan_loss=1.415\n",
            ">Epoch :64, Batch : 13/16, discrim_real_loss=0.686, discrim_fake_loss=0.501 gan_loss=1.688\n",
            ">Epoch :64, Batch : 14/16, discrim_real_loss=0.587, discrim_fake_loss=0.432 gan_loss=1.922\n",
            ">Epoch :64, Batch : 15/16, discrim_real_loss=0.582, discrim_fake_loss=0.397 gan_loss=1.735\n",
            ">Epoch :64, Batch : 16/16, discrim_real_loss=0.505, discrim_fake_loss=0.591 gan_loss=1.488\n",
            ">Epoch :65, Batch : 1/16, discrim_real_loss=0.531, discrim_fake_loss=0.501 gan_loss=1.392\n",
            ">Epoch :65, Batch : 2/16, discrim_real_loss=0.622, discrim_fake_loss=0.645 gan_loss=1.413\n",
            ">Epoch :65, Batch : 3/16, discrim_real_loss=0.598, discrim_fake_loss=0.557 gan_loss=1.514\n",
            ">Epoch :65, Batch : 4/16, discrim_real_loss=0.685, discrim_fake_loss=0.576 gan_loss=1.591\n",
            ">Epoch :65, Batch : 5/16, discrim_real_loss=0.578, discrim_fake_loss=0.564 gan_loss=1.673\n",
            ">Epoch :65, Batch : 6/16, discrim_real_loss=0.652, discrim_fake_loss=0.517 gan_loss=1.610\n",
            ">Epoch :65, Batch : 7/16, discrim_real_loss=0.590, discrim_fake_loss=0.569 gan_loss=1.620\n",
            ">Epoch :65, Batch : 8/16, discrim_real_loss=0.612, discrim_fake_loss=0.552 gan_loss=1.428\n",
            ">Epoch :65, Batch : 9/16, discrim_real_loss=0.585, discrim_fake_loss=0.819 gan_loss=1.386\n",
            ">Epoch :65, Batch : 10/16, discrim_real_loss=0.620, discrim_fake_loss=0.838 gan_loss=1.392\n",
            ">Epoch :65, Batch : 11/16, discrim_real_loss=0.829, discrim_fake_loss=0.812 gan_loss=1.318\n",
            ">Epoch :65, Batch : 12/16, discrim_real_loss=0.832, discrim_fake_loss=0.592 gan_loss=1.542\n",
            ">Epoch :65, Batch : 13/16, discrim_real_loss=0.667, discrim_fake_loss=0.593 gan_loss=1.594\n",
            ">Epoch :65, Batch : 14/16, discrim_real_loss=0.576, discrim_fake_loss=0.633 gan_loss=1.469\n",
            ">Epoch :65, Batch : 15/16, discrim_real_loss=0.634, discrim_fake_loss=0.888 gan_loss=1.548\n",
            ">Epoch :65, Batch : 16/16, discrim_real_loss=0.930, discrim_fake_loss=0.659 gan_loss=1.346\n",
            ">Epoch :66, Batch : 1/16, discrim_real_loss=0.883, discrim_fake_loss=0.601 gan_loss=1.258\n",
            ">Epoch :66, Batch : 2/16, discrim_real_loss=0.634, discrim_fake_loss=0.571 gan_loss=1.374\n",
            ">Epoch :66, Batch : 3/16, discrim_real_loss=0.667, discrim_fake_loss=0.484 gan_loss=1.550\n",
            ">Epoch :66, Batch : 4/16, discrim_real_loss=0.630, discrim_fake_loss=0.479 gan_loss=1.508\n",
            ">Epoch :66, Batch : 5/16, discrim_real_loss=0.559, discrim_fake_loss=0.534 gan_loss=1.367\n",
            ">Epoch :66, Batch : 6/16, discrim_real_loss=0.601, discrim_fake_loss=0.602 gan_loss=1.324\n",
            ">Epoch :66, Batch : 7/16, discrim_real_loss=0.696, discrim_fake_loss=0.578 gan_loss=1.271\n",
            ">Epoch :66, Batch : 8/16, discrim_real_loss=0.729, discrim_fake_loss=0.578 gan_loss=1.281\n",
            ">Epoch :66, Batch : 9/16, discrim_real_loss=0.726, discrim_fake_loss=0.568 gan_loss=1.303\n",
            ">Epoch :66, Batch : 10/16, discrim_real_loss=0.726, discrim_fake_loss=0.554 gan_loss=1.296\n",
            ">Epoch :66, Batch : 11/16, discrim_real_loss=0.711, discrim_fake_loss=0.570 gan_loss=1.300\n",
            ">Epoch :66, Batch : 12/16, discrim_real_loss=0.645, discrim_fake_loss=0.558 gan_loss=1.237\n",
            ">Epoch :66, Batch : 13/16, discrim_real_loss=0.624, discrim_fake_loss=0.631 gan_loss=1.126\n",
            ">Epoch :66, Batch : 14/16, discrim_real_loss=0.608, discrim_fake_loss=0.661 gan_loss=1.063\n",
            ">Epoch :66, Batch : 15/16, discrim_real_loss=0.622, discrim_fake_loss=0.677 gan_loss=1.055\n",
            ">Epoch :66, Batch : 16/16, discrim_real_loss=0.566, discrim_fake_loss=0.612 gan_loss=1.047\n",
            ">Epoch :67, Batch : 1/16, discrim_real_loss=0.574, discrim_fake_loss=0.634 gan_loss=1.110\n",
            ">Epoch :67, Batch : 2/16, discrim_real_loss=0.542, discrim_fake_loss=0.603 gan_loss=1.133\n",
            ">Epoch :67, Batch : 3/16, discrim_real_loss=0.594, discrim_fake_loss=0.529 gan_loss=1.177\n",
            ">Epoch :67, Batch : 4/16, discrim_real_loss=0.589, discrim_fake_loss=0.546 gan_loss=1.220\n",
            ">Epoch :67, Batch : 5/16, discrim_real_loss=0.523, discrim_fake_loss=0.544 gan_loss=1.276\n",
            ">Epoch :67, Batch : 6/16, discrim_real_loss=0.591, discrim_fake_loss=0.483 gan_loss=1.313\n",
            ">Epoch :67, Batch : 7/16, discrim_real_loss=0.580, discrim_fake_loss=0.501 gan_loss=1.304\n",
            ">Epoch :67, Batch : 8/16, discrim_real_loss=0.538, discrim_fake_loss=0.516 gan_loss=1.341\n",
            ">Epoch :67, Batch : 9/16, discrim_real_loss=0.542, discrim_fake_loss=0.475 gan_loss=1.364\n",
            ">Epoch :67, Batch : 10/16, discrim_real_loss=0.515, discrim_fake_loss=0.519 gan_loss=1.406\n",
            ">Epoch :67, Batch : 11/16, discrim_real_loss=0.569, discrim_fake_loss=0.566 gan_loss=1.423\n",
            ">Epoch :67, Batch : 12/16, discrim_real_loss=0.629, discrim_fake_loss=0.552 gan_loss=1.282\n",
            ">Epoch :67, Batch : 13/16, discrim_real_loss=0.575, discrim_fake_loss=0.702 gan_loss=1.235\n",
            ">Epoch :67, Batch : 14/16, discrim_real_loss=0.615, discrim_fake_loss=0.654 gan_loss=1.214\n",
            ">Epoch :67, Batch : 15/16, discrim_real_loss=0.676, discrim_fake_loss=0.724 gan_loss=1.179\n",
            ">Epoch :67, Batch : 16/16, discrim_real_loss=0.710, discrim_fake_loss=0.690 gan_loss=1.213\n",
            ">Epoch :68, Batch : 1/16, discrim_real_loss=0.788, discrim_fake_loss=0.686 gan_loss=1.302\n",
            ">Epoch :68, Batch : 2/16, discrim_real_loss=0.725, discrim_fake_loss=0.583 gan_loss=1.405\n",
            ">Epoch :68, Batch : 3/16, discrim_real_loss=0.704, discrim_fake_loss=0.502 gan_loss=1.392\n",
            ">Epoch :68, Batch : 4/16, discrim_real_loss=0.614, discrim_fake_loss=0.551 gan_loss=1.374\n",
            ">Epoch :68, Batch : 5/16, discrim_real_loss=0.559, discrim_fake_loss=0.537 gan_loss=1.315\n",
            ">Epoch :68, Batch : 6/16, discrim_real_loss=0.551, discrim_fake_loss=0.632 gan_loss=1.344\n",
            ">Epoch :68, Batch : 7/16, discrim_real_loss=0.652, discrim_fake_loss=0.602 gan_loss=1.310\n",
            ">Epoch :68, Batch : 8/16, discrim_real_loss=0.663, discrim_fake_loss=0.501 gan_loss=1.307\n",
            ">Epoch :68, Batch : 9/16, discrim_real_loss=0.698, discrim_fake_loss=0.529 gan_loss=1.273\n",
            ">Epoch :68, Batch : 10/16, discrim_real_loss=0.542, discrim_fake_loss=0.564 gan_loss=1.326\n",
            ">Epoch :68, Batch : 11/16, discrim_real_loss=0.536, discrim_fake_loss=0.533 gan_loss=1.365\n",
            ">Epoch :68, Batch : 12/16, discrim_real_loss=0.620, discrim_fake_loss=0.565 gan_loss=1.354\n",
            ">Epoch :68, Batch : 13/16, discrim_real_loss=0.645, discrim_fake_loss=0.710 gan_loss=1.420\n",
            ">Epoch :68, Batch : 14/16, discrim_real_loss=0.763, discrim_fake_loss=0.555 gan_loss=1.461\n",
            ">Epoch :68, Batch : 15/16, discrim_real_loss=0.844, discrim_fake_loss=0.561 gan_loss=1.435\n",
            ">Epoch :68, Batch : 16/16, discrim_real_loss=0.694, discrim_fake_loss=0.434 gan_loss=1.489\n",
            ">Epoch :69, Batch : 1/16, discrim_real_loss=0.636, discrim_fake_loss=0.449 gan_loss=1.415\n",
            ">Epoch :69, Batch : 2/16, discrim_real_loss=0.597, discrim_fake_loss=0.536 gan_loss=1.205\n",
            ">Epoch :69, Batch : 3/16, discrim_real_loss=0.492, discrim_fake_loss=0.627 gan_loss=1.168\n",
            ">Epoch :69, Batch : 4/16, discrim_real_loss=0.524, discrim_fake_loss=0.639 gan_loss=1.140\n",
            ">Epoch :69, Batch : 5/16, discrim_real_loss=0.544, discrim_fake_loss=0.667 gan_loss=1.136\n",
            ">Epoch :69, Batch : 6/16, discrim_real_loss=0.666, discrim_fake_loss=0.612 gan_loss=1.110\n",
            ">Epoch :69, Batch : 7/16, discrim_real_loss=0.651, discrim_fake_loss=0.671 gan_loss=1.093\n",
            ">Epoch :69, Batch : 8/16, discrim_real_loss=0.674, discrim_fake_loss=0.616 gan_loss=1.169\n",
            ">Epoch :69, Batch : 9/16, discrim_real_loss=0.705, discrim_fake_loss=0.619 gan_loss=1.194\n",
            ">Epoch :69, Batch : 10/16, discrim_real_loss=0.643, discrim_fake_loss=0.536 gan_loss=1.245\n",
            ">Epoch :69, Batch : 11/16, discrim_real_loss=0.636, discrim_fake_loss=0.552 gan_loss=1.279\n",
            ">Epoch :69, Batch : 12/16, discrim_real_loss=0.595, discrim_fake_loss=0.524 gan_loss=1.250\n",
            ">Epoch :69, Batch : 13/16, discrim_real_loss=0.575, discrim_fake_loss=0.571 gan_loss=1.256\n",
            ">Epoch :69, Batch : 14/16, discrim_real_loss=0.576, discrim_fake_loss=0.604 gan_loss=1.258\n",
            ">Epoch :69, Batch : 15/16, discrim_real_loss=0.576, discrim_fake_loss=0.559 gan_loss=1.288\n",
            ">Epoch :69, Batch : 16/16, discrim_real_loss=0.634, discrim_fake_loss=0.520 gan_loss=1.341\n",
            ">Epoch :70, Batch : 1/16, discrim_real_loss=0.680, discrim_fake_loss=0.517 gan_loss=1.290\n",
            ">Epoch :70, Batch : 2/16, discrim_real_loss=0.687, discrim_fake_loss=0.607 gan_loss=1.295\n",
            ">Epoch :70, Batch : 3/16, discrim_real_loss=0.623, discrim_fake_loss=0.548 gan_loss=1.363\n",
            ">Epoch :70, Batch : 4/16, discrim_real_loss=0.685, discrim_fake_loss=0.537 gan_loss=1.416\n",
            ">Epoch :70, Batch : 5/16, discrim_real_loss=0.614, discrim_fake_loss=0.521 gan_loss=1.684\n",
            ">Epoch :70, Batch : 6/16, discrim_real_loss=0.647, discrim_fake_loss=0.437 gan_loss=1.613\n",
            ">Epoch :70, Batch : 7/16, discrim_real_loss=0.522, discrim_fake_loss=0.547 gan_loss=1.489\n",
            ">Epoch :70, Batch : 8/16, discrim_real_loss=0.577, discrim_fake_loss=0.632 gan_loss=1.438\n",
            ">Epoch :70, Batch : 9/16, discrim_real_loss=0.585, discrim_fake_loss=0.588 gan_loss=1.427\n",
            ">Epoch :70, Batch : 10/16, discrim_real_loss=0.678, discrim_fake_loss=0.558 gan_loss=1.486\n",
            ">Epoch :70, Batch : 11/16, discrim_real_loss=0.614, discrim_fake_loss=0.538 gan_loss=1.433\n",
            ">Epoch :70, Batch : 12/16, discrim_real_loss=0.582, discrim_fake_loss=0.737 gan_loss=1.585\n",
            ">Epoch :70, Batch : 13/16, discrim_real_loss=0.710, discrim_fake_loss=0.603 gan_loss=1.499\n",
            ">Epoch :70, Batch : 14/16, discrim_real_loss=0.690, discrim_fake_loss=1.110 gan_loss=1.367\n",
            ">Epoch :70, Batch : 15/16, discrim_real_loss=0.875, discrim_fake_loss=1.418 gan_loss=1.935\n",
            ">Epoch :70, Batch : 16/16, discrim_real_loss=1.243, discrim_fake_loss=0.260 gan_loss=1.568\n",
            ">Accuracy real: 44%, fake: 98%\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "application/javascript": [
              "\n",
              "    async function download(id, filename, size) {\n",
              "      if (!google.colab.kernel.accessAllowed) {\n",
              "        return;\n",
              "      }\n",
              "      const div = document.createElement('div');\n",
              "      const label = document.createElement('label');\n",
              "      label.textContent = `Downloading \"${filename}\": `;\n",
              "      div.appendChild(label);\n",
              "      const progress = document.createElement('progress');\n",
              "      progress.max = size;\n",
              "      div.appendChild(progress);\n",
              "      document.body.appendChild(div);\n",
              "\n",
              "      const buffers = [];\n",
              "      let downloaded = 0;\n",
              "\n",
              "      const channel = await google.colab.kernel.comms.open(id);\n",
              "      // Send a message to notify the kernel that we're ready.\n",
              "      channel.send({})\n",
              "\n",
              "      for await (const message of channel.messages) {\n",
              "        // Send a message to notify the kernel that we're ready.\n",
              "        channel.send({})\n",
              "        if (message.buffers) {\n",
              "          for (const buffer of message.buffers) {\n",
              "            buffers.push(buffer);\n",
              "            downloaded += buffer.byteLength;\n",
              "            progress.value = downloaded;\n",
              "          }\n",
              "        }\n",
              "      }\n",
              "      const blob = new Blob(buffers, {type: 'application/binary'});\n",
              "      const a = document.createElement('a');\n",
              "      a.href = window.URL.createObjectURL(blob);\n",
              "      a.download = filename;\n",
              "      div.appendChild(a);\n",
              "      a.click();\n",
              "      div.remove();\n",
              "    }\n",
              "  "
            ],
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "application/javascript": [
              "download(\"download_05ee6034-809c-4115-8df7-dbef7afcdb95\", \"generated_plot_e070.png\", 5437381)"
            ],
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "application/javascript": [
              "\n",
              "    async function download(id, filename, size) {\n",
              "      if (!google.colab.kernel.accessAllowed) {\n",
              "        return;\n",
              "      }\n",
              "      const div = document.createElement('div');\n",
              "      const label = document.createElement('label');\n",
              "      label.textContent = `Downloading \"${filename}\": `;\n",
              "      div.appendChild(label);\n",
              "      const progress = document.createElement('progress');\n",
              "      progress.max = size;\n",
              "      div.appendChild(progress);\n",
              "      document.body.appendChild(div);\n",
              "\n",
              "      const buffers = [];\n",
              "      let downloaded = 0;\n",
              "\n",
              "      const channel = await google.colab.kernel.comms.open(id);\n",
              "      // Send a message to notify the kernel that we're ready.\n",
              "      channel.send({})\n",
              "\n",
              "      for await (const message of channel.messages) {\n",
              "        // Send a message to notify the kernel that we're ready.\n",
              "        channel.send({})\n",
              "        if (message.buffers) {\n",
              "          for (const buffer of message.buffers) {\n",
              "            buffers.push(buffer);\n",
              "            downloaded += buffer.byteLength;\n",
              "            progress.value = downloaded;\n",
              "          }\n",
              "        }\n",
              "      }\n",
              "      const blob = new Blob(buffers, {type: 'application/binary'});\n",
              "      const a = document.createElement('a');\n",
              "      a.href = window.URL.createObjectURL(blob);\n",
              "      a.download = filename;\n",
              "      div.appendChild(a);\n",
              "      a.click();\n",
              "      div.remove();\n",
              "    }\n",
              "  "
            ],
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "application/javascript": [
              "download(\"download_a06c6492-0808-4ab3-872e-4cc7c69d2b18\", \"generator_model_070.h5\", 11913368)"
            ],
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            ">Epoch :71, Batch : 1/16, discrim_real_loss=0.514, discrim_fake_loss=0.576 gan_loss=1.232\n",
            ">Epoch :71, Batch : 2/16, discrim_real_loss=0.617, discrim_fake_loss=0.613 gan_loss=1.323\n",
            ">Epoch :71, Batch : 3/16, discrim_real_loss=0.648, discrim_fake_loss=0.514 gan_loss=1.351\n",
            ">Epoch :71, Batch : 4/16, discrim_real_loss=0.605, discrim_fake_loss=0.490 gan_loss=1.332\n",
            ">Epoch :71, Batch : 5/16, discrim_real_loss=0.707, discrim_fake_loss=0.539 gan_loss=1.338\n",
            ">Epoch :71, Batch : 6/16, discrim_real_loss=0.693, discrim_fake_loss=0.539 gan_loss=1.269\n",
            ">Epoch :71, Batch : 7/16, discrim_real_loss=0.616, discrim_fake_loss=0.547 gan_loss=1.269\n",
            ">Epoch :71, Batch : 8/16, discrim_real_loss=0.581, discrim_fake_loss=0.585 gan_loss=1.212\n",
            ">Epoch :71, Batch : 9/16, discrim_real_loss=0.564, discrim_fake_loss=0.543 gan_loss=1.250\n",
            ">Epoch :71, Batch : 10/16, discrim_real_loss=0.583, discrim_fake_loss=0.556 gan_loss=1.286\n",
            ">Epoch :71, Batch : 11/16, discrim_real_loss=0.616, discrim_fake_loss=0.483 gan_loss=1.304\n",
            ">Epoch :71, Batch : 12/16, discrim_real_loss=0.596, discrim_fake_loss=0.509 gan_loss=1.293\n",
            ">Epoch :71, Batch : 13/16, discrim_real_loss=0.575, discrim_fake_loss=0.495 gan_loss=1.304\n",
            ">Epoch :71, Batch : 14/16, discrim_real_loss=0.589, discrim_fake_loss=0.448 gan_loss=1.318\n",
            ">Epoch :71, Batch : 15/16, discrim_real_loss=0.541, discrim_fake_loss=0.503 gan_loss=1.302\n",
            ">Epoch :71, Batch : 16/16, discrim_real_loss=0.514, discrim_fake_loss=0.507 gan_loss=1.317\n",
            ">Epoch :72, Batch : 1/16, discrim_real_loss=0.530, discrim_fake_loss=0.465 gan_loss=1.332\n",
            ">Epoch :72, Batch : 2/16, discrim_real_loss=0.525, discrim_fake_loss=0.497 gan_loss=1.325\n",
            ">Epoch :72, Batch : 3/16, discrim_real_loss=0.562, discrim_fake_loss=0.540 gan_loss=1.351\n",
            ">Epoch :72, Batch : 4/16, discrim_real_loss=0.532, discrim_fake_loss=0.486 gan_loss=1.317\n",
            ">Epoch :72, Batch : 5/16, discrim_real_loss=0.635, discrim_fake_loss=0.538 gan_loss=1.318\n",
            ">Epoch :72, Batch : 6/16, discrim_real_loss=0.615, discrim_fake_loss=0.620 gan_loss=1.403\n",
            ">Epoch :72, Batch : 7/16, discrim_real_loss=0.677, discrim_fake_loss=0.494 gan_loss=1.437\n",
            ">Epoch :72, Batch : 8/16, discrim_real_loss=0.681, discrim_fake_loss=0.520 gan_loss=1.379\n",
            ">Epoch :72, Batch : 9/16, discrim_real_loss=0.661, discrim_fake_loss=0.544 gan_loss=1.329\n",
            ">Epoch :72, Batch : 10/16, discrim_real_loss=0.606, discrim_fake_loss=0.615 gan_loss=1.207\n",
            ">Epoch :72, Batch : 11/16, discrim_real_loss=0.611, discrim_fake_loss=0.651 gan_loss=1.148\n",
            ">Epoch :72, Batch : 12/16, discrim_real_loss=0.553, discrim_fake_loss=0.729 gan_loss=1.080\n",
            ">Epoch :72, Batch : 13/16, discrim_real_loss=0.569, discrim_fake_loss=0.766 gan_loss=1.132\n",
            ">Epoch :72, Batch : 14/16, discrim_real_loss=0.646, discrim_fake_loss=0.678 gan_loss=1.149\n",
            ">Epoch :72, Batch : 15/16, discrim_real_loss=0.667, discrim_fake_loss=0.650 gan_loss=1.212\n",
            ">Epoch :72, Batch : 16/16, discrim_real_loss=0.586, discrim_fake_loss=0.621 gan_loss=1.361\n",
            ">Epoch :73, Batch : 1/16, discrim_real_loss=0.609, discrim_fake_loss=0.531 gan_loss=1.447\n",
            ">Epoch :73, Batch : 2/16, discrim_real_loss=0.585, discrim_fake_loss=0.509 gan_loss=1.406\n",
            ">Epoch :73, Batch : 3/16, discrim_real_loss=0.570, discrim_fake_loss=0.578 gan_loss=1.333\n",
            ">Epoch :73, Batch : 4/16, discrim_real_loss=0.595, discrim_fake_loss=0.580 gan_loss=1.244\n",
            ">Epoch :73, Batch : 5/16, discrim_real_loss=0.584, discrim_fake_loss=0.609 gan_loss=1.201\n",
            ">Epoch :73, Batch : 6/16, discrim_real_loss=0.625, discrim_fake_loss=0.588 gan_loss=1.201\n",
            ">Epoch :73, Batch : 7/16, discrim_real_loss=0.629, discrim_fake_loss=0.590 gan_loss=1.171\n",
            ">Epoch :73, Batch : 8/16, discrim_real_loss=0.601, discrim_fake_loss=0.605 gan_loss=1.242\n",
            ">Epoch :73, Batch : 9/16, discrim_real_loss=0.609, discrim_fake_loss=0.535 gan_loss=1.241\n",
            ">Epoch :73, Batch : 10/16, discrim_real_loss=0.536, discrim_fake_loss=0.524 gan_loss=1.238\n",
            ">Epoch :73, Batch : 11/16, discrim_real_loss=0.557, discrim_fake_loss=0.574 gan_loss=1.246\n",
            ">Epoch :73, Batch : 12/16, discrim_real_loss=0.543, discrim_fake_loss=0.530 gan_loss=1.242\n",
            ">Epoch :73, Batch : 13/16, discrim_real_loss=0.549, discrim_fake_loss=0.550 gan_loss=1.317\n",
            ">Epoch :73, Batch : 14/16, discrim_real_loss=0.498, discrim_fake_loss=0.465 gan_loss=1.417\n",
            ">Epoch :73, Batch : 15/16, discrim_real_loss=0.532, discrim_fake_loss=0.456 gan_loss=1.463\n",
            ">Epoch :73, Batch : 16/16, discrim_real_loss=0.490, discrim_fake_loss=0.470 gan_loss=1.457\n",
            ">Epoch :74, Batch : 1/16, discrim_real_loss=0.481, discrim_fake_loss=0.472 gan_loss=1.502\n",
            ">Epoch :74, Batch : 2/16, discrim_real_loss=0.474, discrim_fake_loss=0.504 gan_loss=1.497\n",
            ">Epoch :74, Batch : 3/16, discrim_real_loss=0.460, discrim_fake_loss=0.519 gan_loss=1.438\n",
            ">Epoch :74, Batch : 4/16, discrim_real_loss=0.570, discrim_fake_loss=0.617 gan_loss=1.414\n",
            ">Epoch :74, Batch : 5/16, discrim_real_loss=0.597, discrim_fake_loss=0.597 gan_loss=1.394\n",
            ">Epoch :74, Batch : 6/16, discrim_real_loss=0.733, discrim_fake_loss=0.581 gan_loss=1.387\n",
            ">Epoch :74, Batch : 7/16, discrim_real_loss=0.727, discrim_fake_loss=0.517 gan_loss=1.335\n",
            ">Epoch :74, Batch : 8/16, discrim_real_loss=0.561, discrim_fake_loss=0.496 gan_loss=1.365\n",
            ">Epoch :74, Batch : 9/16, discrim_real_loss=0.684, discrim_fake_loss=0.541 gan_loss=1.368\n",
            ">Epoch :74, Batch : 10/16, discrim_real_loss=0.549, discrim_fake_loss=0.482 gan_loss=1.476\n",
            ">Epoch :74, Batch : 11/16, discrim_real_loss=0.535, discrim_fake_loss=0.540 gan_loss=1.546\n",
            ">Epoch :74, Batch : 12/16, discrim_real_loss=0.595, discrim_fake_loss=0.632 gan_loss=1.530\n",
            ">Epoch :74, Batch : 13/16, discrim_real_loss=0.646, discrim_fake_loss=0.646 gan_loss=1.437\n",
            ">Epoch :74, Batch : 14/16, discrim_real_loss=0.842, discrim_fake_loss=0.584 gan_loss=1.312\n",
            ">Epoch :74, Batch : 15/16, discrim_real_loss=0.767, discrim_fake_loss=0.545 gan_loss=1.366\n",
            ">Epoch :74, Batch : 16/16, discrim_real_loss=0.665, discrim_fake_loss=0.430 gan_loss=1.454\n",
            ">Epoch :75, Batch : 1/16, discrim_real_loss=0.541, discrim_fake_loss=0.463 gan_loss=1.524\n",
            ">Epoch :75, Batch : 2/16, discrim_real_loss=0.447, discrim_fake_loss=0.485 gan_loss=1.545\n",
            ">Epoch :75, Batch : 3/16, discrim_real_loss=0.554, discrim_fake_loss=0.574 gan_loss=1.582\n",
            ">Epoch :75, Batch : 4/16, discrim_real_loss=0.499, discrim_fake_loss=0.532 gan_loss=1.656\n",
            ">Epoch :75, Batch : 5/16, discrim_real_loss=0.520, discrim_fake_loss=0.481 gan_loss=1.589\n",
            ">Epoch :75, Batch : 6/16, discrim_real_loss=0.579, discrim_fake_loss=0.544 gan_loss=1.541\n",
            ">Epoch :75, Batch : 7/16, discrim_real_loss=0.556, discrim_fake_loss=0.471 gan_loss=1.464\n",
            ">Epoch :75, Batch : 8/16, discrim_real_loss=0.591, discrim_fake_loss=0.455 gan_loss=1.396\n",
            ">Epoch :75, Batch : 9/16, discrim_real_loss=0.588, discrim_fake_loss=0.489 gan_loss=1.346\n",
            ">Epoch :75, Batch : 10/16, discrim_real_loss=0.535, discrim_fake_loss=0.570 gan_loss=1.444\n",
            ">Epoch :75, Batch : 11/16, discrim_real_loss=0.573, discrim_fake_loss=0.462 gan_loss=1.463\n",
            ">Epoch :75, Batch : 12/16, discrim_real_loss=0.625, discrim_fake_loss=0.574 gan_loss=1.501\n",
            ">Epoch :75, Batch : 13/16, discrim_real_loss=0.532, discrim_fake_loss=0.515 gan_loss=1.596\n",
            ">Epoch :75, Batch : 14/16, discrim_real_loss=0.572, discrim_fake_loss=0.470 gan_loss=1.599\n",
            ">Epoch :75, Batch : 15/16, discrim_real_loss=0.604, discrim_fake_loss=0.559 gan_loss=1.633\n",
            ">Epoch :75, Batch : 16/16, discrim_real_loss=0.608, discrim_fake_loss=0.561 gan_loss=1.575\n",
            ">Epoch :76, Batch : 1/16, discrim_real_loss=0.585, discrim_fake_loss=0.512 gan_loss=1.498\n",
            ">Epoch :76, Batch : 2/16, discrim_real_loss=0.577, discrim_fake_loss=0.586 gan_loss=1.459\n",
            ">Epoch :76, Batch : 3/16, discrim_real_loss=0.565, discrim_fake_loss=0.585 gan_loss=1.402\n",
            ">Epoch :76, Batch : 4/16, discrim_real_loss=0.620, discrim_fake_loss=0.658 gan_loss=1.337\n",
            ">Epoch :76, Batch : 5/16, discrim_real_loss=0.584, discrim_fake_loss=0.625 gan_loss=1.352\n",
            ">Epoch :76, Batch : 6/16, discrim_real_loss=0.691, discrim_fake_loss=0.686 gan_loss=1.228\n",
            ">Epoch :76, Batch : 7/16, discrim_real_loss=0.641, discrim_fake_loss=0.655 gan_loss=1.189\n",
            ">Epoch :76, Batch : 8/16, discrim_real_loss=0.666, discrim_fake_loss=0.832 gan_loss=1.169\n",
            ">Epoch :76, Batch : 9/16, discrim_real_loss=0.717, discrim_fake_loss=0.753 gan_loss=1.267\n",
            ">Epoch :76, Batch : 10/16, discrim_real_loss=0.763, discrim_fake_loss=0.592 gan_loss=1.309\n",
            ">Epoch :76, Batch : 11/16, discrim_real_loss=0.696, discrim_fake_loss=0.617 gan_loss=1.417\n",
            ">Epoch :76, Batch : 12/16, discrim_real_loss=0.729, discrim_fake_loss=0.547 gan_loss=1.490\n",
            ">Epoch :76, Batch : 13/16, discrim_real_loss=0.599, discrim_fake_loss=0.562 gan_loss=1.304\n",
            ">Epoch :76, Batch : 14/16, discrim_real_loss=0.562, discrim_fake_loss=0.606 gan_loss=1.206\n",
            ">Epoch :76, Batch : 15/16, discrim_real_loss=0.534, discrim_fake_loss=0.566 gan_loss=1.194\n",
            ">Epoch :76, Batch : 16/16, discrim_real_loss=0.565, discrim_fake_loss=0.614 gan_loss=1.201\n",
            ">Epoch :77, Batch : 1/16, discrim_real_loss=0.481, discrim_fake_loss=0.573 gan_loss=1.213\n",
            ">Epoch :77, Batch : 2/16, discrim_real_loss=0.529, discrim_fake_loss=0.612 gan_loss=1.168\n",
            ">Epoch :77, Batch : 3/16, discrim_real_loss=0.535, discrim_fake_loss=0.586 gan_loss=1.086\n",
            ">Epoch :77, Batch : 4/16, discrim_real_loss=0.557, discrim_fake_loss=0.765 gan_loss=1.095\n",
            ">Epoch :77, Batch : 5/16, discrim_real_loss=0.575, discrim_fake_loss=0.742 gan_loss=1.151\n",
            ">Epoch :77, Batch : 6/16, discrim_real_loss=0.669, discrim_fake_loss=0.760 gan_loss=1.278\n",
            ">Epoch :77, Batch : 7/16, discrim_real_loss=0.710, discrim_fake_loss=0.655 gan_loss=1.298\n",
            ">Epoch :77, Batch : 8/16, discrim_real_loss=0.777, discrim_fake_loss=0.661 gan_loss=1.318\n",
            ">Epoch :77, Batch : 9/16, discrim_real_loss=0.718, discrim_fake_loss=0.531 gan_loss=1.338\n",
            ">Epoch :77, Batch : 10/16, discrim_real_loss=0.684, discrim_fake_loss=0.566 gan_loss=1.382\n",
            ">Epoch :77, Batch : 11/16, discrim_real_loss=0.605, discrim_fake_loss=0.478 gan_loss=1.459\n",
            ">Epoch :77, Batch : 12/16, discrim_real_loss=0.542, discrim_fake_loss=0.500 gan_loss=1.462\n",
            ">Epoch :77, Batch : 13/16, discrim_real_loss=0.429, discrim_fake_loss=0.701 gan_loss=1.465\n",
            ">Epoch :77, Batch : 14/16, discrim_real_loss=0.580, discrim_fake_loss=0.674 gan_loss=1.286\n",
            ">Epoch :77, Batch : 15/16, discrim_real_loss=0.706, discrim_fake_loss=0.689 gan_loss=1.292\n",
            ">Epoch :77, Batch : 16/16, discrim_real_loss=0.714, discrim_fake_loss=0.520 gan_loss=1.394\n",
            ">Epoch :78, Batch : 1/16, discrim_real_loss=0.677, discrim_fake_loss=0.477 gan_loss=1.430\n",
            ">Epoch :78, Batch : 2/16, discrim_real_loss=0.570, discrim_fake_loss=0.535 gan_loss=1.563\n",
            ">Epoch :78, Batch : 3/16, discrim_real_loss=0.594, discrim_fake_loss=0.441 gan_loss=1.595\n",
            ">Epoch :78, Batch : 4/16, discrim_real_loss=0.696, discrim_fake_loss=0.462 gan_loss=1.494\n",
            ">Epoch :78, Batch : 5/16, discrim_real_loss=0.617, discrim_fake_loss=0.467 gan_loss=1.373\n",
            ">Epoch :78, Batch : 6/16, discrim_real_loss=0.609, discrim_fake_loss=0.566 gan_loss=1.229\n",
            ">Epoch :78, Batch : 7/16, discrim_real_loss=0.566, discrim_fake_loss=0.607 gan_loss=1.277\n",
            ">Epoch :78, Batch : 8/16, discrim_real_loss=0.633, discrim_fake_loss=0.553 gan_loss=1.232\n",
            ">Epoch :78, Batch : 9/16, discrim_real_loss=0.728, discrim_fake_loss=0.575 gan_loss=1.192\n",
            ">Epoch :78, Batch : 10/16, discrim_real_loss=0.601, discrim_fake_loss=0.574 gan_loss=1.205\n",
            ">Epoch :78, Batch : 11/16, discrim_real_loss=0.601, discrim_fake_loss=0.555 gan_loss=1.255\n",
            ">Epoch :78, Batch : 12/16, discrim_real_loss=0.603, discrim_fake_loss=0.526 gan_loss=1.341\n",
            ">Epoch :78, Batch : 13/16, discrim_real_loss=0.614, discrim_fake_loss=0.479 gan_loss=1.379\n",
            ">Epoch :78, Batch : 14/16, discrim_real_loss=0.589, discrim_fake_loss=0.514 gan_loss=1.313\n",
            ">Epoch :78, Batch : 15/16, discrim_real_loss=0.540, discrim_fake_loss=0.514 gan_loss=1.269\n",
            ">Epoch :78, Batch : 16/16, discrim_real_loss=0.535, discrim_fake_loss=0.592 gan_loss=1.231\n",
            ">Epoch :79, Batch : 1/16, discrim_real_loss=0.584, discrim_fake_loss=0.647 gan_loss=1.211\n",
            ">Epoch :79, Batch : 2/16, discrim_real_loss=0.579, discrim_fake_loss=0.614 gan_loss=1.207\n",
            ">Epoch :79, Batch : 3/16, discrim_real_loss=0.686, discrim_fake_loss=0.631 gan_loss=1.199\n",
            ">Epoch :79, Batch : 4/16, discrim_real_loss=0.640, discrim_fake_loss=0.604 gan_loss=1.219\n",
            ">Epoch :79, Batch : 5/16, discrim_real_loss=0.681, discrim_fake_loss=0.588 gan_loss=1.272\n",
            ">Epoch :79, Batch : 6/16, discrim_real_loss=0.589, discrim_fake_loss=0.496 gan_loss=1.334\n",
            ">Epoch :79, Batch : 7/16, discrim_real_loss=0.630, discrim_fake_loss=0.517 gan_loss=1.317\n",
            ">Epoch :79, Batch : 8/16, discrim_real_loss=0.578, discrim_fake_loss=0.523 gan_loss=1.317\n",
            ">Epoch :79, Batch : 9/16, discrim_real_loss=0.587, discrim_fake_loss=0.534 gan_loss=1.305\n",
            ">Epoch :79, Batch : 10/16, discrim_real_loss=0.549, discrim_fake_loss=0.563 gan_loss=1.300\n",
            ">Epoch :79, Batch : 11/16, discrim_real_loss=0.609, discrim_fake_loss=0.582 gan_loss=1.268\n",
            ">Epoch :79, Batch : 12/16, discrim_real_loss=0.583, discrim_fake_loss=0.552 gan_loss=1.251\n",
            ">Epoch :79, Batch : 13/16, discrim_real_loss=0.550, discrim_fake_loss=0.648 gan_loss=1.267\n",
            ">Epoch :79, Batch : 14/16, discrim_real_loss=0.610, discrim_fake_loss=0.571 gan_loss=1.383\n",
            ">Epoch :79, Batch : 15/16, discrim_real_loss=0.655, discrim_fake_loss=0.571 gan_loss=1.366\n",
            ">Epoch :79, Batch : 16/16, discrim_real_loss=0.615, discrim_fake_loss=0.549 gan_loss=1.360\n",
            ">Epoch :80, Batch : 1/16, discrim_real_loss=0.557, discrim_fake_loss=0.501 gan_loss=1.388\n",
            ">Epoch :80, Batch : 2/16, discrim_real_loss=0.560, discrim_fake_loss=0.509 gan_loss=1.368\n",
            ">Epoch :80, Batch : 3/16, discrim_real_loss=0.452, discrim_fake_loss=0.475 gan_loss=1.363\n",
            ">Epoch :80, Batch : 4/16, discrim_real_loss=0.486, discrim_fake_loss=0.514 gan_loss=1.350\n",
            ">Epoch :80, Batch : 5/16, discrim_real_loss=0.445, discrim_fake_loss=0.481 gan_loss=1.318\n",
            ">Epoch :80, Batch : 6/16, discrim_real_loss=0.509, discrim_fake_loss=0.597 gan_loss=1.236\n",
            ">Epoch :80, Batch : 7/16, discrim_real_loss=0.551, discrim_fake_loss=0.578 gan_loss=1.252\n",
            ">Epoch :80, Batch : 8/16, discrim_real_loss=0.567, discrim_fake_loss=0.654 gan_loss=1.523\n",
            ">Epoch :80, Batch : 9/16, discrim_real_loss=0.613, discrim_fake_loss=0.445 gan_loss=1.749\n",
            ">Epoch :80, Batch : 10/16, discrim_real_loss=0.612, discrim_fake_loss=0.400 gan_loss=1.787\n",
            ">Epoch :80, Batch : 11/16, discrim_real_loss=0.552, discrim_fake_loss=0.411 gan_loss=1.552\n",
            ">Epoch :80, Batch : 12/16, discrim_real_loss=0.459, discrim_fake_loss=0.561 gan_loss=1.510\n",
            ">Epoch :80, Batch : 13/16, discrim_real_loss=0.543, discrim_fake_loss=0.533 gan_loss=1.486\n",
            ">Epoch :80, Batch : 14/16, discrim_real_loss=0.513, discrim_fake_loss=0.496 gan_loss=1.564\n",
            ">Epoch :80, Batch : 15/16, discrim_real_loss=0.586, discrim_fake_loss=0.510 gan_loss=1.662\n",
            ">Epoch :80, Batch : 16/16, discrim_real_loss=0.628, discrim_fake_loss=0.499 gan_loss=1.637\n",
            ">Accuracy real: 60%, fake: 80%\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "application/javascript": [
              "\n",
              "    async function download(id, filename, size) {\n",
              "      if (!google.colab.kernel.accessAllowed) {\n",
              "        return;\n",
              "      }\n",
              "      const div = document.createElement('div');\n",
              "      const label = document.createElement('label');\n",
              "      label.textContent = `Downloading \"${filename}\": `;\n",
              "      div.appendChild(label);\n",
              "      const progress = document.createElement('progress');\n",
              "      progress.max = size;\n",
              "      div.appendChild(progress);\n",
              "      document.body.appendChild(div);\n",
              "\n",
              "      const buffers = [];\n",
              "      let downloaded = 0;\n",
              "\n",
              "      const channel = await google.colab.kernel.comms.open(id);\n",
              "      // Send a message to notify the kernel that we're ready.\n",
              "      channel.send({})\n",
              "\n",
              "      for await (const message of channel.messages) {\n",
              "        // Send a message to notify the kernel that we're ready.\n",
              "        channel.send({})\n",
              "        if (message.buffers) {\n",
              "          for (const buffer of message.buffers) {\n",
              "            buffers.push(buffer);\n",
              "            downloaded += buffer.byteLength;\n",
              "            progress.value = downloaded;\n",
              "          }\n",
              "        }\n",
              "      }\n",
              "      const blob = new Blob(buffers, {type: 'application/binary'});\n",
              "      const a = document.createElement('a');\n",
              "      a.href = window.URL.createObjectURL(blob);\n",
              "      a.download = filename;\n",
              "      div.appendChild(a);\n",
              "      a.click();\n",
              "      div.remove();\n",
              "    }\n",
              "  "
            ],
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "application/javascript": [
              "download(\"download_d0161c40-e469-40a4-add1-e96528ec38df\", \"generated_plot_e080.png\", 5784048)"
            ],
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "application/javascript": [
              "\n",
              "    async function download(id, filename, size) {\n",
              "      if (!google.colab.kernel.accessAllowed) {\n",
              "        return;\n",
              "      }\n",
              "      const div = document.createElement('div');\n",
              "      const label = document.createElement('label');\n",
              "      label.textContent = `Downloading \"${filename}\": `;\n",
              "      div.appendChild(label);\n",
              "      const progress = document.createElement('progress');\n",
              "      progress.max = size;\n",
              "      div.appendChild(progress);\n",
              "      document.body.appendChild(div);\n",
              "\n",
              "      const buffers = [];\n",
              "      let downloaded = 0;\n",
              "\n",
              "      const channel = await google.colab.kernel.comms.open(id);\n",
              "      // Send a message to notify the kernel that we're ready.\n",
              "      channel.send({})\n",
              "\n",
              "      for await (const message of channel.messages) {\n",
              "        // Send a message to notify the kernel that we're ready.\n",
              "        channel.send({})\n",
              "        if (message.buffers) {\n",
              "          for (const buffer of message.buffers) {\n",
              "            buffers.push(buffer);\n",
              "            downloaded += buffer.byteLength;\n",
              "            progress.value = downloaded;\n",
              "          }\n",
              "        }\n",
              "      }\n",
              "      const blob = new Blob(buffers, {type: 'application/binary'});\n",
              "      const a = document.createElement('a');\n",
              "      a.href = window.URL.createObjectURL(blob);\n",
              "      a.download = filename;\n",
              "      div.appendChild(a);\n",
              "      a.click();\n",
              "      div.remove();\n",
              "    }\n",
              "  "
            ],
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "application/javascript": [
              "download(\"download_a74650f3-9e9d-4f82-8578-894be9842d05\", \"generator_model_080.h5\", 11913368)"
            ],
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            ">Epoch :81, Batch : 1/16, discrim_real_loss=0.536, discrim_fake_loss=0.553 gan_loss=1.491\n",
            ">Epoch :81, Batch : 2/16, discrim_real_loss=0.598, discrim_fake_loss=0.630 gan_loss=1.630\n",
            ">Epoch :81, Batch : 3/16, discrim_real_loss=0.643, discrim_fake_loss=0.518 gan_loss=1.591\n",
            ">Epoch :81, Batch : 4/16, discrim_real_loss=0.656, discrim_fake_loss=0.545 gan_loss=1.509\n",
            ">Epoch :81, Batch : 5/16, discrim_real_loss=0.628, discrim_fake_loss=0.523 gan_loss=1.485\n",
            ">Epoch :81, Batch : 6/16, discrim_real_loss=0.531, discrim_fake_loss=0.489 gan_loss=1.504\n",
            ">Epoch :81, Batch : 7/16, discrim_real_loss=0.613, discrim_fake_loss=0.500 gan_loss=1.422\n",
            ">Epoch :81, Batch : 8/16, discrim_real_loss=0.581, discrim_fake_loss=0.574 gan_loss=1.324\n",
            ">Epoch :81, Batch : 9/16, discrim_real_loss=0.506, discrim_fake_loss=0.606 gan_loss=1.282\n",
            ">Epoch :81, Batch : 10/16, discrim_real_loss=0.629, discrim_fake_loss=0.584 gan_loss=1.267\n",
            ">Epoch :81, Batch : 11/16, discrim_real_loss=0.575, discrim_fake_loss=0.631 gan_loss=1.362\n",
            ">Epoch :81, Batch : 12/16, discrim_real_loss=0.605, discrim_fake_loss=0.544 gan_loss=1.557\n",
            ">Epoch :81, Batch : 13/16, discrim_real_loss=0.683, discrim_fake_loss=0.494 gan_loss=1.646\n",
            ">Epoch :81, Batch : 14/16, discrim_real_loss=0.547, discrim_fake_loss=0.461 gan_loss=1.672\n",
            ">Epoch :81, Batch : 15/16, discrim_real_loss=0.603, discrim_fake_loss=0.517 gan_loss=1.578\n",
            ">Epoch :81, Batch : 16/16, discrim_real_loss=0.633, discrim_fake_loss=0.596 gan_loss=1.474\n",
            ">Epoch :82, Batch : 1/16, discrim_real_loss=0.544, discrim_fake_loss=0.488 gan_loss=1.456\n",
            ">Epoch :82, Batch : 2/16, discrim_real_loss=0.561, discrim_fake_loss=0.630 gan_loss=1.395\n",
            ">Epoch :82, Batch : 3/16, discrim_real_loss=0.621, discrim_fake_loss=0.635 gan_loss=1.364\n",
            ">Epoch :82, Batch : 4/16, discrim_real_loss=0.570, discrim_fake_loss=0.609 gan_loss=1.346\n",
            ">Epoch :82, Batch : 5/16, discrim_real_loss=0.598, discrim_fake_loss=0.671 gan_loss=1.363\n",
            ">Epoch :82, Batch : 6/16, discrim_real_loss=0.569, discrim_fake_loss=0.643 gan_loss=1.477\n",
            ">Epoch :82, Batch : 7/16, discrim_real_loss=0.631, discrim_fake_loss=0.606 gan_loss=1.618\n",
            ">Epoch :82, Batch : 8/16, discrim_real_loss=0.634, discrim_fake_loss=0.528 gan_loss=1.498\n",
            ">Epoch :82, Batch : 9/16, discrim_real_loss=0.564, discrim_fake_loss=0.775 gan_loss=1.487\n",
            ">Epoch :82, Batch : 10/16, discrim_real_loss=0.620, discrim_fake_loss=1.057 gan_loss=1.758\n",
            ">Epoch :82, Batch : 11/16, discrim_real_loss=0.595, discrim_fake_loss=0.442 gan_loss=1.508\n",
            ">Epoch :82, Batch : 12/16, discrim_real_loss=0.445, discrim_fake_loss=0.559 gan_loss=1.397\n",
            ">Epoch :82, Batch : 13/16, discrim_real_loss=0.414, discrim_fake_loss=0.565 gan_loss=1.423\n",
            ">Epoch :82, Batch : 14/16, discrim_real_loss=0.621, discrim_fake_loss=0.603 gan_loss=1.502\n",
            ">Epoch :82, Batch : 15/16, discrim_real_loss=0.599, discrim_fake_loss=0.505 gan_loss=1.585\n",
            ">Epoch :82, Batch : 16/16, discrim_real_loss=0.585, discrim_fake_loss=0.536 gan_loss=1.708\n",
            ">Epoch :83, Batch : 1/16, discrim_real_loss=0.585, discrim_fake_loss=0.565 gan_loss=1.923\n",
            ">Epoch :83, Batch : 2/16, discrim_real_loss=0.748, discrim_fake_loss=0.447 gan_loss=1.881\n",
            ">Epoch :83, Batch : 3/16, discrim_real_loss=0.785, discrim_fake_loss=0.501 gan_loss=1.807\n",
            ">Epoch :83, Batch : 4/16, discrim_real_loss=0.668, discrim_fake_loss=0.463 gan_loss=1.683\n",
            ">Epoch :83, Batch : 5/16, discrim_real_loss=0.676, discrim_fake_loss=0.434 gan_loss=1.454\n",
            ">Epoch :83, Batch : 6/16, discrim_real_loss=0.609, discrim_fake_loss=0.507 gan_loss=1.264\n",
            ">Epoch :83, Batch : 7/16, discrim_real_loss=0.456, discrim_fake_loss=0.526 gan_loss=1.258\n",
            ">Epoch :83, Batch : 8/16, discrim_real_loss=0.452, discrim_fake_loss=0.499 gan_loss=1.311\n",
            ">Epoch :83, Batch : 9/16, discrim_real_loss=0.430, discrim_fake_loss=0.499 gan_loss=1.347\n",
            ">Epoch :83, Batch : 10/16, discrim_real_loss=0.446, discrim_fake_loss=0.488 gan_loss=1.384\n",
            ">Epoch :83, Batch : 11/16, discrim_real_loss=0.442, discrim_fake_loss=0.500 gan_loss=1.410\n",
            ">Epoch :83, Batch : 12/16, discrim_real_loss=0.391, discrim_fake_loss=0.481 gan_loss=1.515\n",
            ">Epoch :83, Batch : 13/16, discrim_real_loss=0.466, discrim_fake_loss=0.495 gan_loss=1.542\n",
            ">Epoch :83, Batch : 14/16, discrim_real_loss=0.513, discrim_fake_loss=0.454 gan_loss=1.501\n",
            ">Epoch :83, Batch : 15/16, discrim_real_loss=0.552, discrim_fake_loss=0.589 gan_loss=1.463\n",
            ">Epoch :83, Batch : 16/16, discrim_real_loss=0.561, discrim_fake_loss=0.542 gan_loss=1.391\n",
            ">Epoch :84, Batch : 1/16, discrim_real_loss=0.607, discrim_fake_loss=0.575 gan_loss=1.356\n",
            ">Epoch :84, Batch : 2/16, discrim_real_loss=0.570, discrim_fake_loss=0.578 gan_loss=1.305\n",
            ">Epoch :84, Batch : 3/16, discrim_real_loss=0.604, discrim_fake_loss=0.576 gan_loss=1.370\n",
            ">Epoch :84, Batch : 4/16, discrim_real_loss=0.607, discrim_fake_loss=0.539 gan_loss=1.383\n",
            ">Epoch :84, Batch : 5/16, discrim_real_loss=0.630, discrim_fake_loss=0.536 gan_loss=1.392\n",
            ">Epoch :84, Batch : 6/16, discrim_real_loss=0.575, discrim_fake_loss=0.532 gan_loss=1.396\n",
            ">Epoch :84, Batch : 7/16, discrim_real_loss=0.562, discrim_fake_loss=0.558 gan_loss=1.527\n",
            ">Epoch :84, Batch : 8/16, discrim_real_loss=0.566, discrim_fake_loss=0.552 gan_loss=1.647\n",
            ">Epoch :84, Batch : 9/16, discrim_real_loss=0.542, discrim_fake_loss=0.423 gan_loss=1.617\n",
            ">Epoch :84, Batch : 10/16, discrim_real_loss=0.538, discrim_fake_loss=0.466 gan_loss=1.528\n",
            ">Epoch :84, Batch : 11/16, discrim_real_loss=0.481, discrim_fake_loss=0.464 gan_loss=1.616\n",
            ">Epoch :84, Batch : 12/16, discrim_real_loss=0.583, discrim_fake_loss=0.473 gan_loss=1.568\n",
            ">Epoch :84, Batch : 13/16, discrim_real_loss=0.589, discrim_fake_loss=0.536 gan_loss=1.697\n",
            ">Epoch :84, Batch : 14/16, discrim_real_loss=0.553, discrim_fake_loss=0.412 gan_loss=1.766\n",
            ">Epoch :84, Batch : 15/16, discrim_real_loss=0.645, discrim_fake_loss=0.486 gan_loss=1.619\n",
            ">Epoch :84, Batch : 16/16, discrim_real_loss=0.571, discrim_fake_loss=0.634 gan_loss=1.780\n",
            ">Epoch :85, Batch : 1/16, discrim_real_loss=0.702, discrim_fake_loss=0.517 gan_loss=1.617\n",
            ">Epoch :85, Batch : 2/16, discrim_real_loss=0.559, discrim_fake_loss=0.662 gan_loss=1.724\n",
            ">Epoch :85, Batch : 3/16, discrim_real_loss=0.699, discrim_fake_loss=0.492 gan_loss=1.610\n",
            ">Epoch :85, Batch : 4/16, discrim_real_loss=0.591, discrim_fake_loss=0.577 gan_loss=1.677\n",
            ">Epoch :85, Batch : 5/16, discrim_real_loss=0.755, discrim_fake_loss=0.536 gan_loss=1.596\n",
            ">Epoch :85, Batch : 6/16, discrim_real_loss=0.677, discrim_fake_loss=0.693 gan_loss=1.707\n",
            ">Epoch :85, Batch : 7/16, discrim_real_loss=0.703, discrim_fake_loss=0.646 gan_loss=1.696\n",
            ">Epoch :85, Batch : 8/16, discrim_real_loss=0.597, discrim_fake_loss=0.608 gan_loss=1.645\n",
            ">Epoch :85, Batch : 9/16, discrim_real_loss=0.683, discrim_fake_loss=0.572 gan_loss=1.455\n",
            ">Epoch :85, Batch : 10/16, discrim_real_loss=0.523, discrim_fake_loss=0.623 gan_loss=1.379\n",
            ">Epoch :85, Batch : 11/16, discrim_real_loss=0.454, discrim_fake_loss=0.589 gan_loss=1.476\n",
            ">Epoch :85, Batch : 12/16, discrim_real_loss=0.543, discrim_fake_loss=0.545 gan_loss=1.515\n",
            ">Epoch :85, Batch : 13/16, discrim_real_loss=0.521, discrim_fake_loss=0.445 gan_loss=1.556\n",
            ">Epoch :85, Batch : 14/16, discrim_real_loss=0.471, discrim_fake_loss=0.516 gan_loss=1.720\n",
            ">Epoch :85, Batch : 15/16, discrim_real_loss=0.357, discrim_fake_loss=0.435 gan_loss=1.870\n",
            ">Epoch :85, Batch : 16/16, discrim_real_loss=0.388, discrim_fake_loss=0.502 gan_loss=1.897\n",
            ">Epoch :86, Batch : 1/16, discrim_real_loss=0.559, discrim_fake_loss=0.436 gan_loss=1.711\n",
            ">Epoch :86, Batch : 2/16, discrim_real_loss=0.545, discrim_fake_loss=0.534 gan_loss=1.557\n",
            ">Epoch :86, Batch : 3/16, discrim_real_loss=0.557, discrim_fake_loss=0.679 gan_loss=1.645\n",
            ">Epoch :86, Batch : 4/16, discrim_real_loss=0.512, discrim_fake_loss=0.495 gan_loss=1.727\n",
            ">Epoch :86, Batch : 5/16, discrim_real_loss=0.538, discrim_fake_loss=0.633 gan_loss=1.778\n",
            ">Epoch :86, Batch : 6/16, discrim_real_loss=0.518, discrim_fake_loss=0.604 gan_loss=1.912\n",
            ">Epoch :86, Batch : 7/16, discrim_real_loss=0.785, discrim_fake_loss=0.818 gan_loss=1.910\n",
            ">Epoch :86, Batch : 8/16, discrim_real_loss=0.997, discrim_fake_loss=0.467 gan_loss=1.685\n",
            ">Epoch :86, Batch : 9/16, discrim_real_loss=0.861, discrim_fake_loss=0.505 gan_loss=1.472\n",
            ">Epoch :86, Batch : 10/16, discrim_real_loss=0.729, discrim_fake_loss=0.629 gan_loss=1.524\n",
            ">Epoch :86, Batch : 11/16, discrim_real_loss=0.687, discrim_fake_loss=0.483 gan_loss=1.597\n",
            ">Epoch :86, Batch : 12/16, discrim_real_loss=0.609, discrim_fake_loss=0.535 gan_loss=1.668\n",
            ">Epoch :86, Batch : 13/16, discrim_real_loss=0.626, discrim_fake_loss=0.522 gan_loss=1.767\n",
            ">Epoch :86, Batch : 14/16, discrim_real_loss=0.730, discrim_fake_loss=0.423 gan_loss=1.716\n",
            ">Epoch :86, Batch : 15/16, discrim_real_loss=0.627, discrim_fake_loss=0.469 gan_loss=1.644\n",
            ">Epoch :86, Batch : 16/16, discrim_real_loss=0.642, discrim_fake_loss=0.577 gan_loss=1.595\n",
            ">Epoch :87, Batch : 1/16, discrim_real_loss=0.659, discrim_fake_loss=0.567 gan_loss=1.489\n",
            ">Epoch :87, Batch : 2/16, discrim_real_loss=0.696, discrim_fake_loss=0.539 gan_loss=1.366\n",
            ">Epoch :87, Batch : 3/16, discrim_real_loss=0.518, discrim_fake_loss=0.523 gan_loss=1.248\n",
            ">Epoch :87, Batch : 4/16, discrim_real_loss=0.526, discrim_fake_loss=0.562 gan_loss=1.246\n",
            ">Epoch :87, Batch : 5/16, discrim_real_loss=0.462, discrim_fake_loss=0.667 gan_loss=1.301\n",
            ">Epoch :87, Batch : 6/16, discrim_real_loss=0.570, discrim_fake_loss=0.632 gan_loss=1.291\n",
            ">Epoch :87, Batch : 7/16, discrim_real_loss=0.617, discrim_fake_loss=0.564 gan_loss=1.323\n",
            ">Epoch :87, Batch : 8/16, discrim_real_loss=0.649, discrim_fake_loss=0.615 gan_loss=1.447\n",
            ">Epoch :87, Batch : 9/16, discrim_real_loss=0.613, discrim_fake_loss=0.501 gan_loss=1.533\n",
            ">Epoch :87, Batch : 10/16, discrim_real_loss=0.569, discrim_fake_loss=0.509 gan_loss=1.598\n",
            ">Epoch :87, Batch : 11/16, discrim_real_loss=0.571, discrim_fake_loss=0.477 gan_loss=1.724\n",
            ">Epoch :87, Batch : 12/16, discrim_real_loss=0.595, discrim_fake_loss=0.456 gan_loss=1.653\n",
            ">Epoch :87, Batch : 13/16, discrim_real_loss=0.492, discrim_fake_loss=0.874 gan_loss=2.023\n",
            ">Epoch :87, Batch : 14/16, discrim_real_loss=0.777, discrim_fake_loss=0.329 gan_loss=1.830\n",
            ">Epoch :87, Batch : 15/16, discrim_real_loss=0.645, discrim_fake_loss=0.526 gan_loss=1.542\n",
            ">Epoch :87, Batch : 16/16, discrim_real_loss=0.445, discrim_fake_loss=0.799 gan_loss=1.907\n",
            ">Epoch :88, Batch : 1/16, discrim_real_loss=0.864, discrim_fake_loss=0.337 gan_loss=1.553\n",
            ">Epoch :88, Batch : 2/16, discrim_real_loss=0.655, discrim_fake_loss=0.520 gan_loss=1.295\n",
            ">Epoch :88, Batch : 3/16, discrim_real_loss=0.426, discrim_fake_loss=0.589 gan_loss=1.356\n",
            ">Epoch :88, Batch : 4/16, discrim_real_loss=0.466, discrim_fake_loss=0.570 gan_loss=1.368\n",
            ">Epoch :88, Batch : 5/16, discrim_real_loss=0.509, discrim_fake_loss=0.581 gan_loss=1.428\n",
            ">Epoch :88, Batch : 6/16, discrim_real_loss=0.571, discrim_fake_loss=0.590 gan_loss=1.400\n",
            ">Epoch :88, Batch : 7/16, discrim_real_loss=0.597, discrim_fake_loss=0.606 gan_loss=1.419\n",
            ">Epoch :88, Batch : 8/16, discrim_real_loss=0.595, discrim_fake_loss=0.532 gan_loss=1.417\n",
            ">Epoch :88, Batch : 9/16, discrim_real_loss=0.511, discrim_fake_loss=0.591 gan_loss=1.531\n",
            ">Epoch :88, Batch : 10/16, discrim_real_loss=0.500, discrim_fake_loss=0.532 gan_loss=1.639\n",
            ">Epoch :88, Batch : 11/16, discrim_real_loss=0.519, discrim_fake_loss=0.535 gan_loss=1.723\n",
            ">Epoch :88, Batch : 12/16, discrim_real_loss=0.578, discrim_fake_loss=0.580 gan_loss=1.880\n",
            ">Epoch :88, Batch : 13/16, discrim_real_loss=0.845, discrim_fake_loss=0.515 gan_loss=1.685\n",
            ">Epoch :88, Batch : 14/16, discrim_real_loss=0.773, discrim_fake_loss=0.756 gan_loss=1.866\n",
            ">Epoch :88, Batch : 15/16, discrim_real_loss=0.849, discrim_fake_loss=0.424 gan_loss=1.742\n",
            ">Epoch :88, Batch : 16/16, discrim_real_loss=0.852, discrim_fake_loss=0.554 gan_loss=1.619\n",
            ">Epoch :89, Batch : 1/16, discrim_real_loss=0.640, discrim_fake_loss=0.568 gan_loss=1.678\n",
            ">Epoch :89, Batch : 2/16, discrim_real_loss=0.577, discrim_fake_loss=0.472 gan_loss=1.734\n",
            ">Epoch :89, Batch : 3/16, discrim_real_loss=0.436, discrim_fake_loss=0.611 gan_loss=1.966\n",
            ">Epoch :89, Batch : 4/16, discrim_real_loss=0.705, discrim_fake_loss=0.344 gan_loss=1.578\n",
            ">Epoch :89, Batch : 5/16, discrim_real_loss=0.571, discrim_fake_loss=1.240 gan_loss=1.743\n",
            ">Epoch :89, Batch : 6/16, discrim_real_loss=0.997, discrim_fake_loss=0.410 gan_loss=1.446\n",
            ">Epoch :89, Batch : 7/16, discrim_real_loss=1.002, discrim_fake_loss=0.702 gan_loss=1.193\n",
            ">Epoch :89, Batch : 8/16, discrim_real_loss=0.638, discrim_fake_loss=0.574 gan_loss=1.261\n",
            ">Epoch :89, Batch : 9/16, discrim_real_loss=0.652, discrim_fake_loss=0.514 gan_loss=1.300\n",
            ">Epoch :89, Batch : 10/16, discrim_real_loss=0.601, discrim_fake_loss=0.506 gan_loss=1.319\n",
            ">Epoch :89, Batch : 11/16, discrim_real_loss=0.502, discrim_fake_loss=0.512 gan_loss=1.386\n",
            ">Epoch :89, Batch : 12/16, discrim_real_loss=0.552, discrim_fake_loss=0.515 gan_loss=1.406\n",
            ">Epoch :89, Batch : 13/16, discrim_real_loss=0.515, discrim_fake_loss=0.522 gan_loss=1.497\n",
            ">Epoch :89, Batch : 14/16, discrim_real_loss=0.495, discrim_fake_loss=0.523 gan_loss=1.466\n",
            ">Epoch :89, Batch : 15/16, discrim_real_loss=0.613, discrim_fake_loss=0.578 gan_loss=1.488\n",
            ">Epoch :89, Batch : 16/16, discrim_real_loss=0.614, discrim_fake_loss=0.604 gan_loss=1.529\n",
            ">Epoch :90, Batch : 1/16, discrim_real_loss=0.690, discrim_fake_loss=0.683 gan_loss=1.553\n",
            ">Epoch :90, Batch : 2/16, discrim_real_loss=0.801, discrim_fake_loss=0.669 gan_loss=1.603\n",
            ">Epoch :90, Batch : 3/16, discrim_real_loss=0.800, discrim_fake_loss=0.561 gan_loss=1.659\n",
            ">Epoch :90, Batch : 4/16, discrim_real_loss=0.781, discrim_fake_loss=0.536 gan_loss=1.787\n",
            ">Epoch :90, Batch : 5/16, discrim_real_loss=0.720, discrim_fake_loss=0.507 gan_loss=1.502\n",
            ">Epoch :90, Batch : 6/16, discrim_real_loss=0.590, discrim_fake_loss=0.663 gan_loss=1.460\n",
            ">Epoch :90, Batch : 7/16, discrim_real_loss=0.672, discrim_fake_loss=0.610 gan_loss=1.297\n",
            ">Epoch :90, Batch : 8/16, discrim_real_loss=0.654, discrim_fake_loss=0.584 gan_loss=1.288\n",
            ">Epoch :90, Batch : 9/16, discrim_real_loss=0.559, discrim_fake_loss=0.507 gan_loss=1.347\n",
            ">Epoch :90, Batch : 10/16, discrim_real_loss=0.520, discrim_fake_loss=0.423 gan_loss=1.375\n",
            ">Epoch :90, Batch : 11/16, discrim_real_loss=0.551, discrim_fake_loss=0.459 gan_loss=1.421\n",
            ">Epoch :90, Batch : 12/16, discrim_real_loss=0.450, discrim_fake_loss=0.397 gan_loss=1.439\n",
            ">Epoch :90, Batch : 13/16, discrim_real_loss=0.483, discrim_fake_loss=0.512 gan_loss=1.540\n",
            ">Epoch :90, Batch : 14/16, discrim_real_loss=0.559, discrim_fake_loss=0.442 gan_loss=1.516\n",
            ">Epoch :90, Batch : 15/16, discrim_real_loss=0.516, discrim_fake_loss=0.553 gan_loss=1.469\n",
            ">Epoch :90, Batch : 16/16, discrim_real_loss=0.511, discrim_fake_loss=0.604 gan_loss=1.739\n",
            ">Accuracy real: 54%, fake: 94%\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "application/javascript": [
              "\n",
              "    async function download(id, filename, size) {\n",
              "      if (!google.colab.kernel.accessAllowed) {\n",
              "        return;\n",
              "      }\n",
              "      const div = document.createElement('div');\n",
              "      const label = document.createElement('label');\n",
              "      label.textContent = `Downloading \"${filename}\": `;\n",
              "      div.appendChild(label);\n",
              "      const progress = document.createElement('progress');\n",
              "      progress.max = size;\n",
              "      div.appendChild(progress);\n",
              "      document.body.appendChild(div);\n",
              "\n",
              "      const buffers = [];\n",
              "      let downloaded = 0;\n",
              "\n",
              "      const channel = await google.colab.kernel.comms.open(id);\n",
              "      // Send a message to notify the kernel that we're ready.\n",
              "      channel.send({})\n",
              "\n",
              "      for await (const message of channel.messages) {\n",
              "        // Send a message to notify the kernel that we're ready.\n",
              "        channel.send({})\n",
              "        if (message.buffers) {\n",
              "          for (const buffer of message.buffers) {\n",
              "            buffers.push(buffer);\n",
              "            downloaded += buffer.byteLength;\n",
              "            progress.value = downloaded;\n",
              "          }\n",
              "        }\n",
              "      }\n",
              "      const blob = new Blob(buffers, {type: 'application/binary'});\n",
              "      const a = document.createElement('a');\n",
              "      a.href = window.URL.createObjectURL(blob);\n",
              "      a.download = filename;\n",
              "      div.appendChild(a);\n",
              "      a.click();\n",
              "      div.remove();\n",
              "    }\n",
              "  "
            ],
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "application/javascript": [
              "download(\"download_2d596b3d-1362-4094-a910-920ba343d466\", \"generated_plot_e090.png\", 5989284)"
            ],
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "application/javascript": [
              "\n",
              "    async function download(id, filename, size) {\n",
              "      if (!google.colab.kernel.accessAllowed) {\n",
              "        return;\n",
              "      }\n",
              "      const div = document.createElement('div');\n",
              "      const label = document.createElement('label');\n",
              "      label.textContent = `Downloading \"${filename}\": `;\n",
              "      div.appendChild(label);\n",
              "      const progress = document.createElement('progress');\n",
              "      progress.max = size;\n",
              "      div.appendChild(progress);\n",
              "      document.body.appendChild(div);\n",
              "\n",
              "      const buffers = [];\n",
              "      let downloaded = 0;\n",
              "\n",
              "      const channel = await google.colab.kernel.comms.open(id);\n",
              "      // Send a message to notify the kernel that we're ready.\n",
              "      channel.send({})\n",
              "\n",
              "      for await (const message of channel.messages) {\n",
              "        // Send a message to notify the kernel that we're ready.\n",
              "        channel.send({})\n",
              "        if (message.buffers) {\n",
              "          for (const buffer of message.buffers) {\n",
              "            buffers.push(buffer);\n",
              "            downloaded += buffer.byteLength;\n",
              "            progress.value = downloaded;\n",
              "          }\n",
              "        }\n",
              "      }\n",
              "      const blob = new Blob(buffers, {type: 'application/binary'});\n",
              "      const a = document.createElement('a');\n",
              "      a.href = window.URL.createObjectURL(blob);\n",
              "      a.download = filename;\n",
              "      div.appendChild(a);\n",
              "      a.click();\n",
              "      div.remove();\n",
              "    }\n",
              "  "
            ],
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "application/javascript": [
              "download(\"download_9064d515-8994-401f-8671-99c335f3efe2\", \"generator_model_090.h5\", 11913368)"
            ],
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            ">Epoch :91, Batch : 1/16, discrim_real_loss=0.506, discrim_fake_loss=0.499 gan_loss=1.896\n",
            ">Epoch :91, Batch : 2/16, discrim_real_loss=0.686, discrim_fake_loss=0.623 gan_loss=1.776\n",
            ">Epoch :91, Batch : 3/16, discrim_real_loss=0.674, discrim_fake_loss=0.492 gan_loss=1.772\n",
            ">Epoch :91, Batch : 4/16, discrim_real_loss=0.648, discrim_fake_loss=0.483 gan_loss=1.561\n",
            ">Epoch :91, Batch : 5/16, discrim_real_loss=0.572, discrim_fake_loss=0.525 gan_loss=1.420\n",
            ">Epoch :91, Batch : 6/16, discrim_real_loss=0.474, discrim_fake_loss=0.597 gan_loss=1.537\n",
            ">Epoch :91, Batch : 7/16, discrim_real_loss=0.509, discrim_fake_loss=0.455 gan_loss=1.562\n",
            ">Epoch :91, Batch : 8/16, discrim_real_loss=0.490, discrim_fake_loss=0.586 gan_loss=1.649\n",
            ">Epoch :91, Batch : 9/16, discrim_real_loss=0.529, discrim_fake_loss=0.412 gan_loss=1.757\n",
            ">Epoch :91, Batch : 10/16, discrim_real_loss=0.596, discrim_fake_loss=0.570 gan_loss=1.894\n",
            ">Epoch :91, Batch : 11/16, discrim_real_loss=0.612, discrim_fake_loss=0.472 gan_loss=1.948\n",
            ">Epoch :91, Batch : 12/16, discrim_real_loss=0.650, discrim_fake_loss=0.565 gan_loss=1.628\n",
            ">Epoch :91, Batch : 13/16, discrim_real_loss=0.574, discrim_fake_loss=0.698 gan_loss=1.695\n",
            ">Epoch :91, Batch : 14/16, discrim_real_loss=0.748, discrim_fake_loss=0.616 gan_loss=1.491\n",
            ">Epoch :91, Batch : 15/16, discrim_real_loss=0.714, discrim_fake_loss=0.641 gan_loss=1.443\n",
            ">Epoch :91, Batch : 16/16, discrim_real_loss=0.657, discrim_fake_loss=0.580 gan_loss=1.455\n",
            ">Epoch :92, Batch : 1/16, discrim_real_loss=0.558, discrim_fake_loss=0.522 gan_loss=1.485\n",
            ">Epoch :92, Batch : 2/16, discrim_real_loss=0.462, discrim_fake_loss=0.500 gan_loss=1.507\n",
            ">Epoch :92, Batch : 3/16, discrim_real_loss=0.522, discrim_fake_loss=0.568 gan_loss=1.398\n",
            ">Epoch :92, Batch : 4/16, discrim_real_loss=0.515, discrim_fake_loss=0.585 gan_loss=1.295\n",
            ">Epoch :92, Batch : 5/16, discrim_real_loss=0.519, discrim_fake_loss=0.566 gan_loss=1.336\n",
            ">Epoch :92, Batch : 6/16, discrim_real_loss=0.552, discrim_fake_loss=0.551 gan_loss=1.413\n",
            ">Epoch :92, Batch : 7/16, discrim_real_loss=0.557, discrim_fake_loss=0.511 gan_loss=1.436\n",
            ">Epoch :92, Batch : 8/16, discrim_real_loss=0.521, discrim_fake_loss=0.523 gan_loss=1.543\n",
            ">Epoch :92, Batch : 9/16, discrim_real_loss=0.568, discrim_fake_loss=0.540 gan_loss=1.626\n",
            ">Epoch :92, Batch : 10/16, discrim_real_loss=0.580, discrim_fake_loss=0.481 gan_loss=1.781\n",
            ">Epoch :92, Batch : 11/16, discrim_real_loss=0.631, discrim_fake_loss=0.401 gan_loss=1.701\n",
            ">Epoch :92, Batch : 12/16, discrim_real_loss=0.574, discrim_fake_loss=0.511 gan_loss=1.711\n",
            ">Epoch :92, Batch : 13/16, discrim_real_loss=0.534, discrim_fake_loss=0.493 gan_loss=1.677\n",
            ">Epoch :92, Batch : 14/16, discrim_real_loss=0.611, discrim_fake_loss=0.531 gan_loss=1.498\n",
            ">Epoch :92, Batch : 15/16, discrim_real_loss=0.653, discrim_fake_loss=0.751 gan_loss=1.565\n",
            ">Epoch :92, Batch : 16/16, discrim_real_loss=0.681, discrim_fake_loss=0.547 gan_loss=1.709\n",
            ">Epoch :93, Batch : 1/16, discrim_real_loss=0.632, discrim_fake_loss=0.459 gan_loss=1.713\n",
            ">Epoch :93, Batch : 2/16, discrim_real_loss=0.600, discrim_fake_loss=0.467 gan_loss=1.730\n",
            ">Epoch :93, Batch : 3/16, discrim_real_loss=0.538, discrim_fake_loss=0.477 gan_loss=1.744\n",
            ">Epoch :93, Batch : 4/16, discrim_real_loss=0.577, discrim_fake_loss=0.522 gan_loss=1.548\n",
            ">Epoch :93, Batch : 5/16, discrim_real_loss=0.555, discrim_fake_loss=0.565 gan_loss=1.318\n",
            ">Epoch :93, Batch : 6/16, discrim_real_loss=0.508, discrim_fake_loss=0.626 gan_loss=1.400\n",
            ">Epoch :93, Batch : 7/16, discrim_real_loss=0.585, discrim_fake_loss=0.598 gan_loss=1.379\n",
            ">Epoch :93, Batch : 8/16, discrim_real_loss=0.560, discrim_fake_loss=0.549 gan_loss=1.420\n",
            ">Epoch :93, Batch : 9/16, discrim_real_loss=0.592, discrim_fake_loss=0.561 gan_loss=1.393\n",
            ">Epoch :93, Batch : 10/16, discrim_real_loss=0.531, discrim_fake_loss=0.549 gan_loss=1.416\n",
            ">Epoch :93, Batch : 11/16, discrim_real_loss=0.577, discrim_fake_loss=0.577 gan_loss=1.559\n",
            ">Epoch :93, Batch : 12/16, discrim_real_loss=0.515, discrim_fake_loss=0.490 gan_loss=1.766\n",
            ">Epoch :93, Batch : 13/16, discrim_real_loss=0.550, discrim_fake_loss=0.429 gan_loss=1.727\n",
            ">Epoch :93, Batch : 14/16, discrim_real_loss=0.528, discrim_fake_loss=0.481 gan_loss=1.711\n",
            ">Epoch :93, Batch : 15/16, discrim_real_loss=0.618, discrim_fake_loss=0.519 gan_loss=1.742\n",
            ">Epoch :93, Batch : 16/16, discrim_real_loss=0.622, discrim_fake_loss=0.646 gan_loss=1.855\n",
            ">Epoch :94, Batch : 1/16, discrim_real_loss=0.801, discrim_fake_loss=0.492 gan_loss=1.749\n",
            ">Epoch :94, Batch : 2/16, discrim_real_loss=0.785, discrim_fake_loss=0.502 gan_loss=1.719\n",
            ">Epoch :94, Batch : 3/16, discrim_real_loss=0.666, discrim_fake_loss=0.442 gan_loss=1.701\n",
            ">Epoch :94, Batch : 4/16, discrim_real_loss=0.513, discrim_fake_loss=0.477 gan_loss=1.738\n",
            ">Epoch :94, Batch : 5/16, discrim_real_loss=0.430, discrim_fake_loss=0.478 gan_loss=1.662\n",
            ">Epoch :94, Batch : 6/16, discrim_real_loss=0.381, discrim_fake_loss=0.741 gan_loss=1.823\n",
            ">Epoch :94, Batch : 7/16, discrim_real_loss=0.593, discrim_fake_loss=0.526 gan_loss=2.125\n",
            ">Epoch :94, Batch : 8/16, discrim_real_loss=0.688, discrim_fake_loss=0.576 gan_loss=1.997\n",
            ">Epoch :94, Batch : 9/16, discrim_real_loss=0.724, discrim_fake_loss=0.634 gan_loss=2.054\n",
            ">Epoch :94, Batch : 10/16, discrim_real_loss=0.800, discrim_fake_loss=0.521 gan_loss=1.887\n",
            ">Epoch :94, Batch : 11/16, discrim_real_loss=0.767, discrim_fake_loss=0.565 gan_loss=1.736\n",
            ">Epoch :94, Batch : 12/16, discrim_real_loss=0.756, discrim_fake_loss=0.600 gan_loss=1.528\n",
            ">Epoch :94, Batch : 13/16, discrim_real_loss=0.688, discrim_fake_loss=0.596 gan_loss=1.326\n",
            ">Epoch :94, Batch : 14/16, discrim_real_loss=0.517, discrim_fake_loss=0.678 gan_loss=1.511\n",
            ">Epoch :94, Batch : 15/16, discrim_real_loss=0.486, discrim_fake_loss=0.531 gan_loss=1.558\n",
            ">Epoch :94, Batch : 16/16, discrim_real_loss=0.616, discrim_fake_loss=0.573 gan_loss=1.392\n",
            ">Epoch :95, Batch : 1/16, discrim_real_loss=0.520, discrim_fake_loss=0.632 gan_loss=1.403\n",
            ">Epoch :95, Batch : 2/16, discrim_real_loss=0.539, discrim_fake_loss=0.596 gan_loss=1.462\n",
            ">Epoch :95, Batch : 3/16, discrim_real_loss=0.650, discrim_fake_loss=0.707 gan_loss=1.582\n",
            ">Epoch :95, Batch : 4/16, discrim_real_loss=0.686, discrim_fake_loss=0.521 gan_loss=1.566\n",
            ">Epoch :95, Batch : 5/16, discrim_real_loss=0.711, discrim_fake_loss=0.632 gan_loss=1.659\n",
            ">Epoch :95, Batch : 6/16, discrim_real_loss=0.688, discrim_fake_loss=0.434 gan_loss=1.605\n",
            ">Epoch :95, Batch : 7/16, discrim_real_loss=0.647, discrim_fake_loss=0.490 gan_loss=1.556\n",
            ">Epoch :95, Batch : 8/16, discrim_real_loss=0.560, discrim_fake_loss=0.515 gan_loss=1.517\n",
            ">Epoch :95, Batch : 9/16, discrim_real_loss=0.579, discrim_fake_loss=0.509 gan_loss=1.477\n",
            ">Epoch :95, Batch : 10/16, discrim_real_loss=0.503, discrim_fake_loss=0.486 gan_loss=1.473\n",
            ">Epoch :95, Batch : 11/16, discrim_real_loss=0.475, discrim_fake_loss=0.571 gan_loss=1.526\n",
            ">Epoch :95, Batch : 12/16, discrim_real_loss=0.511, discrim_fake_loss=0.634 gan_loss=1.759\n",
            ">Epoch :95, Batch : 13/16, discrim_real_loss=0.604, discrim_fake_loss=0.396 gan_loss=1.708\n",
            ">Epoch :95, Batch : 14/16, discrim_real_loss=0.554, discrim_fake_loss=0.585 gan_loss=1.724\n",
            ">Epoch :95, Batch : 15/16, discrim_real_loss=0.590, discrim_fake_loss=0.568 gan_loss=1.873\n",
            ">Epoch :95, Batch : 16/16, discrim_real_loss=0.596, discrim_fake_loss=0.449 gan_loss=1.711\n",
            ">Epoch :96, Batch : 1/16, discrim_real_loss=0.643, discrim_fake_loss=0.522 gan_loss=1.570\n",
            ">Epoch :96, Batch : 2/16, discrim_real_loss=0.436, discrim_fake_loss=0.492 gan_loss=1.629\n",
            ">Epoch :96, Batch : 3/16, discrim_real_loss=0.382, discrim_fake_loss=0.439 gan_loss=1.653\n",
            ">Epoch :96, Batch : 4/16, discrim_real_loss=0.366, discrim_fake_loss=0.494 gan_loss=1.777\n",
            ">Epoch :96, Batch : 5/16, discrim_real_loss=0.493, discrim_fake_loss=0.570 gan_loss=1.845\n",
            ">Epoch :96, Batch : 6/16, discrim_real_loss=0.656, discrim_fake_loss=0.459 gan_loss=1.599\n",
            ">Epoch :96, Batch : 7/16, discrim_real_loss=0.583, discrim_fake_loss=0.755 gan_loss=1.648\n",
            ">Epoch :96, Batch : 8/16, discrim_real_loss=0.633, discrim_fake_loss=0.391 gan_loss=1.610\n",
            ">Epoch :96, Batch : 9/16, discrim_real_loss=0.620, discrim_fake_loss=0.472 gan_loss=1.400\n",
            ">Epoch :96, Batch : 10/16, discrim_real_loss=0.440, discrim_fake_loss=0.728 gan_loss=1.778\n",
            ">Epoch :96, Batch : 11/16, discrim_real_loss=0.512, discrim_fake_loss=0.573 gan_loss=2.270\n",
            ">Epoch :96, Batch : 12/16, discrim_real_loss=0.696, discrim_fake_loss=0.700 gan_loss=2.225\n",
            ">Epoch :96, Batch : 13/16, discrim_real_loss=0.703, discrim_fake_loss=0.438 gan_loss=1.764\n",
            ">Epoch :96, Batch : 14/16, discrim_real_loss=0.509, discrim_fake_loss=0.529 gan_loss=1.845\n",
            ">Epoch :96, Batch : 15/16, discrim_real_loss=0.439, discrim_fake_loss=0.356 gan_loss=1.933\n",
            ">Epoch :96, Batch : 16/16, discrim_real_loss=0.496, discrim_fake_loss=0.493 gan_loss=2.114\n",
            ">Epoch :97, Batch : 1/16, discrim_real_loss=0.462, discrim_fake_loss=0.436 gan_loss=2.137\n",
            ">Epoch :97, Batch : 2/16, discrim_real_loss=0.492, discrim_fake_loss=0.458 gan_loss=2.037\n",
            ">Epoch :97, Batch : 3/16, discrim_real_loss=0.606, discrim_fake_loss=0.652 gan_loss=2.303\n",
            ">Epoch :97, Batch : 4/16, discrim_real_loss=0.747, discrim_fake_loss=0.295 gan_loss=2.055\n",
            ">Epoch :97, Batch : 5/16, discrim_real_loss=0.683, discrim_fake_loss=0.535 gan_loss=1.758\n",
            ">Epoch :97, Batch : 6/16, discrim_real_loss=0.544, discrim_fake_loss=0.477 gan_loss=1.674\n",
            ">Epoch :97, Batch : 7/16, discrim_real_loss=0.548, discrim_fake_loss=0.481 gan_loss=1.525\n",
            ">Epoch :97, Batch : 8/16, discrim_real_loss=0.538, discrim_fake_loss=0.533 gan_loss=1.504\n",
            ">Epoch :97, Batch : 9/16, discrim_real_loss=0.585, discrim_fake_loss=0.515 gan_loss=1.468\n",
            ">Epoch :97, Batch : 10/16, discrim_real_loss=0.491, discrim_fake_loss=0.556 gan_loss=1.466\n",
            ">Epoch :97, Batch : 11/16, discrim_real_loss=0.525, discrim_fake_loss=0.578 gan_loss=1.462\n",
            ">Epoch :97, Batch : 12/16, discrim_real_loss=0.608, discrim_fake_loss=0.646 gan_loss=1.597\n",
            ">Epoch :97, Batch : 13/16, discrim_real_loss=0.767, discrim_fake_loss=0.534 gan_loss=1.572\n",
            ">Epoch :97, Batch : 14/16, discrim_real_loss=0.716, discrim_fake_loss=0.542 gan_loss=1.549\n",
            ">Epoch :97, Batch : 15/16, discrim_real_loss=0.640, discrim_fake_loss=0.448 gan_loss=1.669\n",
            ">Epoch :97, Batch : 16/16, discrim_real_loss=0.615, discrim_fake_loss=0.454 gan_loss=1.673\n",
            ">Epoch :98, Batch : 1/16, discrim_real_loss=0.566, discrim_fake_loss=0.446 gan_loss=1.634\n",
            ">Epoch :98, Batch : 2/16, discrim_real_loss=0.554, discrim_fake_loss=0.486 gan_loss=1.543\n",
            ">Epoch :98, Batch : 3/16, discrim_real_loss=0.533, discrim_fake_loss=0.533 gan_loss=1.514\n",
            ">Epoch :98, Batch : 4/16, discrim_real_loss=0.582, discrim_fake_loss=0.601 gan_loss=1.619\n",
            ">Epoch :98, Batch : 5/16, discrim_real_loss=0.719, discrim_fake_loss=0.533 gan_loss=1.610\n",
            ">Epoch :98, Batch : 6/16, discrim_real_loss=0.728, discrim_fake_loss=0.532 gan_loss=1.572\n",
            ">Epoch :98, Batch : 7/16, discrim_real_loss=0.619, discrim_fake_loss=0.507 gan_loss=1.798\n",
            ">Epoch :98, Batch : 8/16, discrim_real_loss=0.639, discrim_fake_loss=0.505 gan_loss=1.866\n",
            ">Epoch :98, Batch : 9/16, discrim_real_loss=0.577, discrim_fake_loss=0.485 gan_loss=1.739\n",
            ">Epoch :98, Batch : 10/16, discrim_real_loss=0.539, discrim_fake_loss=0.574 gan_loss=1.787\n",
            ">Epoch :98, Batch : 11/16, discrim_real_loss=0.516, discrim_fake_loss=0.456 gan_loss=1.784\n",
            ">Epoch :98, Batch : 12/16, discrim_real_loss=0.490, discrim_fake_loss=0.660 gan_loss=1.750\n",
            ">Epoch :98, Batch : 13/16, discrim_real_loss=0.658, discrim_fake_loss=0.549 gan_loss=1.533\n",
            ">Epoch :98, Batch : 14/16, discrim_real_loss=0.524, discrim_fake_loss=0.700 gan_loss=1.479\n",
            ">Epoch :98, Batch : 15/16, discrim_real_loss=0.670, discrim_fake_loss=0.658 gan_loss=1.535\n",
            ">Epoch :98, Batch : 16/16, discrim_real_loss=0.693, discrim_fake_loss=0.581 gan_loss=1.513\n",
            ">Epoch :99, Batch : 1/16, discrim_real_loss=0.592, discrim_fake_loss=0.578 gan_loss=1.511\n",
            ">Epoch :99, Batch : 2/16, discrim_real_loss=0.444, discrim_fake_loss=0.597 gan_loss=1.693\n",
            ">Epoch :99, Batch : 3/16, discrim_real_loss=0.435, discrim_fake_loss=0.575 gan_loss=1.850\n",
            ">Epoch :99, Batch : 4/16, discrim_real_loss=0.530, discrim_fake_loss=0.459 gan_loss=1.891\n",
            ">Epoch :99, Batch : 5/16, discrim_real_loss=0.451, discrim_fake_loss=0.702 gan_loss=2.157\n",
            ">Epoch :99, Batch : 6/16, discrim_real_loss=0.629, discrim_fake_loss=0.480 gan_loss=1.948\n",
            ">Epoch :99, Batch : 7/16, discrim_real_loss=0.534, discrim_fake_loss=0.647 gan_loss=1.869\n",
            ">Epoch :99, Batch : 8/16, discrim_real_loss=0.747, discrim_fake_loss=0.425 gan_loss=1.687\n",
            ">Epoch :99, Batch : 9/16, discrim_real_loss=0.589, discrim_fake_loss=0.589 gan_loss=1.669\n",
            ">Epoch :99, Batch : 10/16, discrim_real_loss=0.530, discrim_fake_loss=0.483 gan_loss=1.643\n",
            ">Epoch :99, Batch : 11/16, discrim_real_loss=0.449, discrim_fake_loss=0.496 gan_loss=1.567\n",
            ">Epoch :99, Batch : 12/16, discrim_real_loss=0.567, discrim_fake_loss=0.724 gan_loss=1.540\n",
            ">Epoch :99, Batch : 13/16, discrim_real_loss=0.642, discrim_fake_loss=0.525 gan_loss=1.516\n",
            ">Epoch :99, Batch : 14/16, discrim_real_loss=0.713, discrim_fake_loss=0.635 gan_loss=1.529\n",
            ">Epoch :99, Batch : 15/16, discrim_real_loss=0.780, discrim_fake_loss=0.523 gan_loss=1.661\n",
            ">Epoch :99, Batch : 16/16, discrim_real_loss=0.688, discrim_fake_loss=0.483 gan_loss=1.793\n",
            ">Epoch :100, Batch : 1/16, discrim_real_loss=0.747, discrim_fake_loss=0.594 gan_loss=1.905\n",
            ">Epoch :100, Batch : 2/16, discrim_real_loss=0.657, discrim_fake_loss=0.493 gan_loss=2.075\n",
            ">Epoch :100, Batch : 3/16, discrim_real_loss=0.731, discrim_fake_loss=0.513 gan_loss=2.058\n",
            ">Epoch :100, Batch : 4/16, discrim_real_loss=0.696, discrim_fake_loss=0.454 gan_loss=1.932\n",
            ">Epoch :100, Batch : 5/16, discrim_real_loss=0.766, discrim_fake_loss=0.518 gan_loss=1.735\n",
            ">Epoch :100, Batch : 6/16, discrim_real_loss=0.627, discrim_fake_loss=0.489 gan_loss=1.620\n",
            ">Epoch :100, Batch : 7/16, discrim_real_loss=0.617, discrim_fake_loss=0.545 gan_loss=1.570\n",
            ">Epoch :100, Batch : 8/16, discrim_real_loss=0.603, discrim_fake_loss=0.433 gan_loss=1.570\n",
            ">Epoch :100, Batch : 9/16, discrim_real_loss=0.621, discrim_fake_loss=0.455 gan_loss=1.501\n",
            ">Epoch :100, Batch : 10/16, discrim_real_loss=0.509, discrim_fake_loss=0.434 gan_loss=1.546\n",
            ">Epoch :100, Batch : 11/16, discrim_real_loss=0.513, discrim_fake_loss=0.442 gan_loss=1.635\n",
            ">Epoch :100, Batch : 12/16, discrim_real_loss=0.520, discrim_fake_loss=0.476 gan_loss=1.588\n",
            ">Epoch :100, Batch : 13/16, discrim_real_loss=0.475, discrim_fake_loss=0.459 gan_loss=1.679\n",
            ">Epoch :100, Batch : 14/16, discrim_real_loss=0.537, discrim_fake_loss=0.504 gan_loss=1.906\n",
            ">Epoch :100, Batch : 15/16, discrim_real_loss=0.529, discrim_fake_loss=0.429 gan_loss=1.751\n",
            ">Epoch :100, Batch : 16/16, discrim_real_loss=0.541, discrim_fake_loss=0.495 gan_loss=1.675\n",
            ">Accuracy real: 61%, fake: 95%\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "application/javascript": [
              "\n",
              "    async function download(id, filename, size) {\n",
              "      if (!google.colab.kernel.accessAllowed) {\n",
              "        return;\n",
              "      }\n",
              "      const div = document.createElement('div');\n",
              "      const label = document.createElement('label');\n",
              "      label.textContent = `Downloading \"${filename}\": `;\n",
              "      div.appendChild(label);\n",
              "      const progress = document.createElement('progress');\n",
              "      progress.max = size;\n",
              "      div.appendChild(progress);\n",
              "      document.body.appendChild(div);\n",
              "\n",
              "      const buffers = [];\n",
              "      let downloaded = 0;\n",
              "\n",
              "      const channel = await google.colab.kernel.comms.open(id);\n",
              "      // Send a message to notify the kernel that we're ready.\n",
              "      channel.send({})\n",
              "\n",
              "      for await (const message of channel.messages) {\n",
              "        // Send a message to notify the kernel that we're ready.\n",
              "        channel.send({})\n",
              "        if (message.buffers) {\n",
              "          for (const buffer of message.buffers) {\n",
              "            buffers.push(buffer);\n",
              "            downloaded += buffer.byteLength;\n",
              "            progress.value = downloaded;\n",
              "          }\n",
              "        }\n",
              "      }\n",
              "      const blob = new Blob(buffers, {type: 'application/binary'});\n",
              "      const a = document.createElement('a');\n",
              "      a.href = window.URL.createObjectURL(blob);\n",
              "      a.download = filename;\n",
              "      div.appendChild(a);\n",
              "      a.click();\n",
              "      div.remove();\n",
              "    }\n",
              "  "
            ],
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "application/javascript": [
              "download(\"download_e00daa8c-1c98-43d5-b508-9035055f537e\", \"generated_plot_e100.png\", 5250619)"
            ],
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "application/javascript": [
              "\n",
              "    async function download(id, filename, size) {\n",
              "      if (!google.colab.kernel.accessAllowed) {\n",
              "        return;\n",
              "      }\n",
              "      const div = document.createElement('div');\n",
              "      const label = document.createElement('label');\n",
              "      label.textContent = `Downloading \"${filename}\": `;\n",
              "      div.appendChild(label);\n",
              "      const progress = document.createElement('progress');\n",
              "      progress.max = size;\n",
              "      div.appendChild(progress);\n",
              "      document.body.appendChild(div);\n",
              "\n",
              "      const buffers = [];\n",
              "      let downloaded = 0;\n",
              "\n",
              "      const channel = await google.colab.kernel.comms.open(id);\n",
              "      // Send a message to notify the kernel that we're ready.\n",
              "      channel.send({})\n",
              "\n",
              "      for await (const message of channel.messages) {\n",
              "        // Send a message to notify the kernel that we're ready.\n",
              "        channel.send({})\n",
              "        if (message.buffers) {\n",
              "          for (const buffer of message.buffers) {\n",
              "            buffers.push(buffer);\n",
              "            downloaded += buffer.byteLength;\n",
              "            progress.value = downloaded;\n",
              "          }\n",
              "        }\n",
              "      }\n",
              "      const blob = new Blob(buffers, {type: 'application/binary'});\n",
              "      const a = document.createElement('a');\n",
              "      a.href = window.URL.createObjectURL(blob);\n",
              "      a.download = filename;\n",
              "      div.appendChild(a);\n",
              "      a.click();\n",
              "      div.remove();\n",
              "    }\n",
              "  "
            ],
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "application/javascript": [
              "download(\"download_27646d85-c2c8-47e7-aafb-134db418f2ae\", \"generator_model_100.h5\", 11913368)"
            ],
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    }
  ]
}